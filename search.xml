<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Alpine镜像内的Java时区问题</title>
    <url>/2020/09/04/Alpine%E9%95%9C%E5%83%8F%E5%86%85%E7%9A%84Java%E6%97%B6%E5%8C%BA%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>docker的精简镜像alpine内没有时区信息，在基于该镜像制作应用镜像时，需要配置时区信息，之前的做法是在其他容器时将宿主机的时区配置挂载到容器，如下所示：</p>
<p>docker run -itd -v /etc/localtime:/etc/localtime alpine bash<br>进入到容器内，时间确实已经是东八区时间:</p>
<p>bash-4.3# date<br>Tue Aug  7 09:32:21 CST 2018<br>但是对于Java应用来说，读取到的时间依然不是东八区时间，还需要挂载下面的时区文件才可以</p>
<p>docker run -itd -v /etc/localtime:/etc/localtime -v /etc/timezone:/etc/timezone alpine bash<br>附 Java读取系统时区配置</p>
<p>方法一</p>
<p>在 tomcat的jvm 运行参数加上 -Duser.timezone=GMT+8，使用该配置，应用程序就会忽略系统设置的时区</p>
<p>方法二</p>
<p>配置文件/etc/sysconfig/clock，在文件内增加以下信息</p>
<p>ZONE=”Asia/Shanghai”<br>UTC=false<br>ARC=false<br>方法三</p>
<p>配置时区:</p>
<p>cp /usr/share/zoneinfo/Asia/Shanghai  /etc/localtime<br>echo “Asia/Shanghai”&gt;&gt;/etc/timezone</p>
]]></content>
  </entry>
  <entry>
    <title>100 行代码创建一个容器</title>
    <url>/2020/12/23/100-%E8%A1%8C%E4%BB%A3%E7%A0%81%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%AE%B9%E5%99%A8/</url>
    <content><![CDATA[<p>容器占用资源监控和故障隔离，训练性能不一致</p>
<h3 id="关键技术一：命名空间"><a href="#关键技术一：命名空间" class="headerlink" title="关键技术一：命名空间"></a>关键技术一：命名空间</h3><ol>
<li>PID：PID命名空间为某个进程及其子进程提供了系统中进程的一个子集的视图。你可以将其想象为一个映射表。当PID命名空间中的某个进程向kernel请求一个进程列表时，kernel将会检查这个映射表。如果该进程已经存在于表中，那么kernel就会返回其映射ID，而不是真实的ID。而如果该进程不存在于映射表中，那么kernel会假设该进程完全不存在。在PID命名空间中创建的第一个进程的pid为1（因此其主机ID的映射值为1），该命名空间在容器中会表现为一个隔离的进程树。</li>
<li>MNT：在某种意义上说，mount命名空间是最重要的一个命名空间，它为其中所包含的进程提供了一个独有的mount表。这也意味着当这些进程对目录进行挂载或取消挂载时不会影响其他命名空间（包括主机命名空间）。更重要的是，我们将看到，<font size="8">通过与pivot_root这个系统调用的结合，它让某个进程能够拥有一个独有的文件系统</font>。因此，只需交换容器的文件系统，进程就会认为它正运行在某个Ubuntu、BusyBox或Alpine中。</li>
<li>NET：network命名空间为使用它的进程赋予了独立的网络栈。通常来说，只有在主network命名空间（也就是当机器启动时会自动启动的进程所在的命名空间）中才会被分配真实的物理网卡。但我们可以创建虚拟的网络设备对，即互联的网卡，其中一端属于某个network命名空间，而另一端则属于另一个network命名空间，通过这种方式在两个network命名空间之间创建了一个虚拟的连接。这种方式有些类似于在同一台主机中让多个IP栈进行通信。通过一定的路由逻辑，每个容器就能够保持自己独立的网络栈，同时能够与外界进行通信。</li>
<li>UTS：UTS（UNIX Time-sharing System）命名空间为其中的进程提供了系统主机名与域名的独有视图。当进入某个UTS命名空间之后，对于主机名与域名的修改不会影响其他进程。</li>
<li>IPC：IPC（Interprocess Communication）命名空间能够隔离各种进程间的通信机制，例如消息队列等等。可参考命名空间的相关文档，以了解更多细节。</li>
<li>USER：user命名空间最近刚刚得到支持，从安全性的角度来看，它可能是最强大的一种命名空间了。user命名空间能够将某个进程所看到的uid映射为主机中一个不同的uid（以及gid）集合。这一特性非常实用，通过使用user命名空间，我们就能够将容器的root user ID（比如0）映射为主机中一个任意的（并且未赋予特权的）uid。这就意味着我们可以让某个容器认为它具有对root的访问权，而同时又无需为其赋予任何root命名空间中的权限（我们甚至可以为其访问特定于容器的资源赋予类似于root的权限）。容器可随意以uid 0运行进程（这通常意味着该用户具备root权限），而kernel会在内部将该uid映射为某个未赋予特权的真实uid。大多数容器系统都不会将容器中的任何一个uid映射为调用命名空间中的uid 0，换句话说，在容器中不存在任何一个具有root权限的uid。</li>
</ol>
<h3 id="关键技术二：-cgroups"><a href="#关键技术二：-cgroups" class="headerlink" title="关键技术二： cgroups"></a>关键技术二： cgroups</h3><p>Cgroups全称Control Groups，是Linux内核提供的物理资源隔离机制，通过这种机制，可以实现对Linux进程或者进程组的资源限制、隔离和统计功能。比如可以通过cgroup限制特定进程的资源使用，比如使用特定数目的cpu核数和特定大小的内存，如果资源超限的情况下，会被暂停或者杀掉。Cgroup是于2.6内核由Google公司主导引入的，它是Linux内核实现资源虚拟化的技术基石，LXC(Linux Containers)和docker容器所用到的资源隔离技术，正是Cgroup。</p>
<p>cgroup 内容很多，具体可以参见<a href="https://zhuanlan.zhihu.com/p/81668069" target="_blank" rel="noopener">这里</a></p>
<h3 id="关键技术三：-分层文件系统"><a href="#关键技术三：-分层文件系统" class="headerlink" title="关键技术三： 分层文件系统"></a>关键技术三： 分层文件系统</h3><p>命名空间与CGroups负责容器化的隔离与资源共享，他们实现了容器的主体功能以及安全保障。而分层文件系统使我们能够高效地移动完整的机器镜像，它保证了容器的持续运作。从本质上来看，分层文件系统的作用是使为每个容器创建一份root文件系统的拷贝的调用过程进行优化。有多种不同的方式可以实现这一目标。Btrfs在文件系统层使用了写时拷贝（copy-on-write）技术，而Aufs则使用了“union mounts”这种挂载机制。由于可以通过多种方式实现这一步骤，因此本文选择了一种非常简单的方式：我们将真正地创建一个拷贝。虽然这种方式很慢，但确实能够完成任务。</p>
<h3 id="code"><a href="#code" class="headerlink" title="code"></a>code</h3><figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">"fmt"</span></span><br><span class="line">    <span class="string">"os"</span></span><br><span class="line">    <span class="string">"os/exec"</span></span><br><span class="line">    <span class="string">"syscall"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">switch</span> os.Args[<span class="number">1</span>] &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">"run"</span>:</span><br><span class="line">        parent()</span><br><span class="line">    <span class="keyword">case</span> <span class="string">"child"</span>:</span><br><span class="line">        child()</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">        <span class="built_in">panic</span>(<span class="string">"wat should I do"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"># step <span class="number">1</span> ‘/proc/self/exe’，这是一个特殊文件，它包含了当前可执行文件的一个内存镜像。换句话说，我们将重新调用这个程序本身，将‘child’作为第一个参数进行传递</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">parent</span><span class="params">()</span></span> &#123;</span><br><span class="line">    cmd := exec.Command(<span class="string">"/proc/self/exe"</span>, <span class="built_in">append</span>([]<span class="keyword">string</span>&#123;<span class="string">"child"</span>&#125;, os.Args[<span class="number">2</span>:]...)...)</span><br><span class="line">    # step <span class="number">2</span> 在程序中添加命名空间</span><br><span class="line">    cmd.SysProcAttr = &amp;syscall.SysProcAttr&#123;</span><br><span class="line">        Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWPID | syscall.CLONE_NEWNS,</span><br><span class="line">    &#125;</span><br><span class="line">    cmd.Stdin = os.Stdin</span><br><span class="line">    cmd.Stdout = os.Stdout</span><br><span class="line">    cmd.Stderr = os.Stderr</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> err := cmd.Run(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">        fmt.Println(<span class="string">"ERROR"</span>, err)</span><br><span class="line">        os.Exit(<span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">child</span><span class="params">()</span></span> &#123;</span><br><span class="line">    # step3 第<span class="number">2</span>步中已经将该进程运行在了新的mnt命名空间，此处进行rootfs 的切换</span><br><span class="line">    must(syscall.Mount(<span class="string">"rootfs"</span>, <span class="string">"rootfs"</span>, <span class="string">""</span>, syscall.MS_BIND, <span class="string">""</span>))</span><br><span class="line">    must(os.MkdirAll(<span class="string">"rootfs/oldrootfs"</span>, <span class="number">0700</span>))</span><br><span class="line">    must(syscall.PivotRoot(<span class="string">"rootfs"</span>, <span class="string">"rootfs/oldrootfs"</span>))</span><br><span class="line">    </span><br><span class="line">    # 当‘pivotroot’调用 结束之后，容器中的‘/’目录将指向rootfs目录</span><br><span class="line">    must(os.Chdir(<span class="string">"/"</span>))</span><br><span class="line"></span><br><span class="line">    cmd := exec.Command(os.Args[<span class="number">2</span>], os.Args[<span class="number">3</span>:]...)</span><br><span class="line">    cmd.Stdin = os.Stdin</span><br><span class="line">    cmd.Stdout = os.Stdout</span><br><span class="line">    cmd.Stderr = os.Stderr</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> err := cmd.Run(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">        fmt.Println(<span class="string">"ERROR"</span>, err)</span><br><span class="line">        os.Exit(<span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">must</span><span class="params">(err error)</span></span> &#123;</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="built_in">panic</span>(err)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>docker与主机关系</title>
    <url>/2020/09/03/Docker%E4%B8%8E%E4%B8%BB%E6%9C%BA%E5%85%B3%E7%B3%BB/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>docker Volume Plugin 开发及Golang实现</title>
    <url>/2020/09/21/Docker-Volume-Plugin-%E5%BC%80%E5%8F%91%E5%8F%8AGolang%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<p>      该项目要用于生产环境了，完善加固了一下代码，顺便更新一下文章。</p>
<p>     在加固项目的代码时候 ，调整了卷创建的顺序，调用docker volume create的时候，就把lv创建出来，并挂载到了本地目录，中间遇到了一个很奇怪的问题，挂载lv代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">err &#x3D; syscall.Mount(lvdiskname, mountPoint, &quot;xfs&quot;, syscall.MS\_NOSUID|syscall.MS\_STRICTATIME, &quot;&quot;)</span><br><span class="line"></span><br><span class="line">	if err !&#x3D; nil &#123;</span><br><span class="line">		log.Error(&quot;mount lv failed&quot;, err)</span><br><span class="line">			return volume.Response&#123;Err: &quot;mount lv failed&quot;&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>



<p>      使用该代码挂载完成后，在命令行执行df -h 命令是无法查看到挂载信息的，代码也没有报错，尝试把lv删除时，会出现 Device busy的错误。数据并没有丢失，可以在容器内正常使用。</p>
<p>google到了 mount namespace的概念。</p>
<p>``<br>     mnt namespace为进程提供独立的文件系统视图。当clone（）函数中带有CLONE_NEWNS标志时，新的mnt ns在子进程中被创建，新的mnt ns是一份父mnt ns的拷贝，<br>但是在子进程中调用mount安装的文件系统，将独立于父进程的mnt ns，只出现在新的mnt ns上<br>使用syscall.Mount 函数应该是在另一个namespace 中进行了挂载，因此我是无法查看到。</p>
<p>    前期的项目需求，需要合理利用宿主机的存储，利用在宿主机部署Agent的方式，实现了基于LVM分配docker数据卷的方式，随着开发的进行，项目想要集成docker compose 完成应用的自动编排，需要在docker compose中为容器创建数据卷并且指定卷大小，之前的采用agent的模式已经无法满足目前的需求。参考<a href="https://docs.docker.com/engine/extend/plugins_volume/" target="_blank" rel="noopener">docker 官方文档</a> 和 <a href="https://github.com/CWSpear/local-persist" target="_blank" rel="noopener">Local-Persist</a>项目，实现了一个基于LVM的volume 插件 <a href="https://github.com/davidstack/docker-volume-plugin-lvm" target="_blank" rel="noopener">docker-volume-plugin-lvm</a>。</p>
<p>      docker Volume Plugin 提供了标准的卷管理API，第三方只需要实现这些API就可以了。</p>
<p>     插件加载方式，将自己实现的Driver注册，启动main函数，实际上是启动了一个监听端口，sock文件：/var/run/docker/plugins/LVM.sock</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func main() &#123;</span><br><span class="line">	driver :&#x3D; NewLvmPersistDriver()</span><br><span class="line"></span><br><span class="line">	handler :&#x3D; volume.NewHandler(driver)</span><br><span class="line">	fmt.Println(handler.ServeUnix(&quot;root&quot;, driver.Name))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p> 查询卷API：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func (driver \*LvmPersistDriver) Get(req volume.Request) volume.Response</span><br></pre></td></tr></table></figure>





<p>       创建卷API：根据入参获取卷名称和卷大小，在LVM的VG中分配LV，并将卷的元数据保存到内存并持久化，若没有设置卷大小，可以设置默认值（目前只能通过代码修改） PS：在使用docker create 命令创建容器时，无法指定卷大小比较坑，还好docker compose支持</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func (driver \*LvmPersistDriver) Create(req volume.Request) volume.Response</span><br><span class="line">&#96;&#96;&#96;    挂载卷API：根据入参获取卷名称，校验该卷是否已经存在，若存在，将该LV格式化，并挂载到宿主机的目录（宿主机目录由卷插件指定）（若宿主机目录已经被挂载，则不执行该步骤），将挂载点，也就是宿主机目录以volume.Response的方式返回，PS：支持多个容器挂载同一个数据卷，但是读写控制目前没有实现，需要Container自己控制。</span><br></pre></td></tr></table></figure>
<p>func (driver *LvmPersistDriver) Mount(req volume.Request) volume.Response</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  卸载卷API：</span><br></pre></td></tr></table></figure>
<p>func (driver *LvmPersistDriver) Unmount(req volume.Request) volume.Response</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">删除卷API：</span><br></pre></td></tr></table></figure>
<p>func (driver *LvmPersistDriver) Remove(req volume.Request) volume.Response</p>
<p>```<br>具体实现可以参考代码实现。<a href="https://github.com/davidstack/docker-volume-plugin-lvm" target="_blank" rel="noopener">docker-volume-plugin-lvm</a></p>
<p>代码目前不是很完善，测试代码，部署运行代码 还没有实现。我比较懒。。。</p>
]]></content>
      <tags>
        <tag>docker</tag>
        <tag>golang</tag>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title>docker以网络插件方式实现Pipework</title>
    <url>/2020/09/21/Docker%E4%BB%A5%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6%E6%96%B9%E5%BC%8F%E5%AE%9E%E7%8E%B0Pipework/</url>
    <content><![CDATA[<p>  docker目前提供了多种网络模式，但是相信大部分运维人员还是比较相信物理网络，所以就想着将容器的网络配置成物理网络。可以看到开源项目<a href="https://github.com/jpetazzo/pipework" target="_blank" rel="noopener">Pipework</a>，当然 Pipework的功能比较强大，这里我只关注容器使用物理网络的实现，如果你手动去配置容器的IP，可以只需要以下几个步骤：</p>
<p>1、创建网桥并配置，将eth0绑定到网桥br0，docker Daemon 监听br0</p>
<p>2、启动容器</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -d --net&#x3D;none --name web  10.110.17.138:5000&#x2F;library&#x2F;tomcat:7.0.67-jre7</span><br></pre></td></tr></table></figure>
<p>3、创建Container对应的网络命名空间</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir -p &#x2F;var&#x2F;run&#x2F;netns</span><br><span class="line">ln -s &#x2F;proc&#x2F;1381&#x2F;ns&#x2F;net &#x2F;var&#x2F;run&#x2F;netns&#x2F;1381</span><br></pre></td></tr></table></figure>
<p>4、容器配置网卡</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ip link add veth-a type veth peer name veth-b</span><br><span class="line">brctl addif br0 veth-a</span><br><span class="line">ip link set veth-a up</span><br><span class="line">ip link set veth-b netns 1381</span><br><span class="line">ip netns exec 1381 ip link set dev veth-b name eth0 </span><br><span class="line">ip netns exec 1381 ip link set eth0 up</span><br><span class="line">ip netns exec 1381 ip addr add 10.110.17.94&#x2F;24 dev eth0 </span><br><span class="line">ip netns exec 1381 ip route del default</span><br><span class="line">ip netns exec 1381 ip route add default via 10.110.17.254</span><br></pre></td></tr></table></figure>
<p>    不是很复杂，业务系统可以定义一个脚本执行就OK，但是我们再开发使用过程中发现，当我们想着将这种网络模式运用到Compose时，却发现用不了，但是Compose支持docker 的网络插件机制，所以就需要考虑使用<a href="https://github.com/docker/libnetwork/blob/master/docs/remote.md" target="_blank" rel="noopener">docker的网络插件机制</a>实现。参考了<a href="https://github.com/weaveworks/weave" target="_blank" rel="noopener">Weave</a>和<a href="https://github.com/gopher-net/docker-ovs-plugin" target="_blank" rel="noopener">ovs-plugin</a>的实现方式，整理出了docker使用物理网络的插件<a href="https://github.com/davidstack/docker-network-plugin-local.git" target="_blank" rel="noopener">docker-network-plugin-local</a>，当然github上开源的仅仅是网络配置OK，和我们生产环境上的肯定有所区别，不过大家可以参考，在这里说一下几处关键代码。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func (driver \*PipeNetworkDriver) CreateNetwork(createNetworkRequest \*network.CreateNetworkRequest) error &#123;</span><br><span class="line">	GlobalEndPointCache.Mutex.Lock()</span><br><span class="line">	defer func() &#123;</span><br><span class="line">		GlobalEndPointCache.Mutex.Unlock()</span><br><span class="line">	&#125;()</span><br><span class="line">	gateway, mask, \_ :&#x3D; getGatewayIP(createNetworkRequest)</span><br><span class="line">	networkInfo :&#x3D; NetworkInfo&#123;BridgeName: &quot;br0&quot;,</span><br><span class="line">		Gateway:            gateway,</span><br><span class="line">		GatewayMask:        mask,</span><br><span class="line">		ContainerInterface: &quot;eth1&quot;,</span><br><span class="line">		MTU:                1500,</span><br><span class="line">		NetWorkId:          createNetworkRequest.NetworkID,</span><br><span class="line">	&#125;</span><br><span class="line">	GlobalEndPointCache.EndPoints &#x3D; make(map\[string\]\*EndPoint)</span><br><span class="line">	GlobalEndPointCache.Network &#x3D; &amp;networkInfo</span><br><span class="line">	driver.UpdateCacheFile()</span><br><span class="line">	return nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p> 此处是命令行执行docker network create 时调用的API，这个插件是将网络信息缓存到了本地，其他什么也没有做（如果你想在集群环境中使用，可以修改此处，将网络信息保存到Etcd数据库）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func (driver \*PipeNetworkDriver) CreateEndpoint(createEndpointRequest \*network.CreateEndpointRequest) (\*network.CreateEndpointResponse, error) &#123;</span><br><span class="line">	fmt.Println(&quot;create endpoint&quot;)</span><br><span class="line">	GlobalEndPointCache.Mutex.Lock()</span><br><span class="line">	defer func() &#123;</span><br><span class="line">		GlobalEndPointCache.Mutex.Unlock()</span><br><span class="line">	&#125;()</span><br><span class="line">	endPointId :&#x3D; createEndpointRequest.EndpointID</span><br><span class="line">	ipaddress :&#x3D; createEndpointRequest.Interface.Address</span><br><span class="line">	vethPairTag :&#x3D; truncateID(endPointId)</span><br><span class="line">	vethPariA :&#x3D; vethPairTag + &quot;-a&quot;</span><br><span class="line">	vethPariB :&#x3D; vethPairTag + &quot;-b&quot;</span><br><span class="line">	endPoint :&#x3D; EndPoint&#123;EndpointID: endPointId,</span><br><span class="line">		Address:      ipaddress,</span><br><span class="line">		VethName:     vethPariA,</span><br><span class="line">		VethPeerName: vethPariB&#125;</span><br><span class="line">	GlobalEndPointCache.EndPoints\[endPointId\] &#x3D; &amp;endPoint</span><br><span class="line">	driver.UpdateCacheFile()</span><br><span class="line">	return nil, nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>此处是在创建容器时，指定driver时调用的API，该插件只是定义了需要创建的link 对（veth pair），然后缓存起来</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func (driver \*PipeNetworkDriver) Join(joinRequest \*network.JoinRequest) (\*network.JoinResponse, error) &#123;</span><br><span class="line">	fmt.Println(&quot;joing....&quot;)</span><br><span class="line">	fmt.Println(&quot;NetworkID is &quot;, joinRequest.NetworkID)</span><br><span class="line">	fmt.Println(&quot;SandboxKey is &quot;, joinRequest.SandboxKey)</span><br><span class="line"></span><br><span class="line">	GlobalEndPointCache.Mutex.Lock()</span><br><span class="line">	defer func() &#123;</span><br><span class="line">		GlobalEndPointCache.Mutex.Unlock()</span><br><span class="line">	&#125;()</span><br><span class="line">	&#x2F;&#x2F;query from cache</span><br><span class="line">	endPointInfo :&#x3D; GlobalEndPointCache.EndPoints\[joinRequest.EndpointID\]</span><br><span class="line">	fmt.Println(&quot;vethPairA is &quot;, endPointInfo.VethName)</span><br><span class="line">	fmt.Println(&quot;vethPairB is &quot;, endPointInfo.VethPeerName)</span><br><span class="line"></span><br><span class="line">	localVethPair :&#x3D; vethPair(endPointInfo.VethName, endPointInfo.VethPeerName)</span><br><span class="line">	if err :&#x3D; netlink.LinkAdd(localVethPair); err !&#x3D; nil &#123;</span><br><span class="line">		fmt.Println(&quot;failed to create the veth pair named: \[ %v \] error: \[ %s \] &quot;, localVethPair, err)</span><br><span class="line">		return nil, err</span><br><span class="line">	&#125;</span><br><span class="line">	fmt.Println(&quot;localVethPair.Name is &quot;, localVethPair.Name)</span><br><span class="line">	&#x2F;&#x2F; 2. add vethPariA to bridge and set up</span><br><span class="line">	createdLink, linkErr :&#x3D; netlink.LinkByName(localVethPair.Name)</span><br><span class="line">	if linkErr !&#x3D; nil &#123;</span><br><span class="line">		fmt.Println(&quot;find link failed&quot;, linkErr)</span><br><span class="line">		return nil, linkErr</span><br><span class="line">	&#125;</span><br><span class="line">	netinterface :&#x3D; net.Interface&#123;Index: createdLink.Attrs().Index,</span><br><span class="line">		Name:         createdLink.Attrs().Name,</span><br><span class="line">		MTU:          createdLink.Attrs().MTU,</span><br><span class="line">		Flags:        createdLink.Attrs().Flags,</span><br><span class="line">		HardwareAddr: createdLink.Attrs().HardwareAddr&#125;</span><br><span class="line"></span><br><span class="line">	br, err :&#x3D; tenus.BridgeFromName(GlobalEndPointCache.Network.BridgeName)</span><br><span class="line">	if err !&#x3D; nil &#123;</span><br><span class="line">		fmt.Println(&quot;use exist bridge failed&quot;, err)</span><br><span class="line">		return nil, err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if err &#x3D; br.AddSlaveIfc(&amp;netinterface); err !&#x3D; nil &#123;</span><br><span class="line">		fmt.Println(&quot;add interface to bridge failed&quot;, err)</span><br><span class="line">	&#125;</span><br><span class="line">	err &#x3D; netlink.LinkSetUp(createdLink)</span><br><span class="line">	if err !&#x3D; nil &#123;</span><br><span class="line">		fmt.Println(&quot;Error enabling  Veth local iface: \[ %v \]&quot;, localVethPair)</span><br><span class="line">		return nil, err</span><br><span class="line">	&#125;</span><br><span class="line">	response :&#x3D; network.JoinResponse&#123;InterfaceName: network.InterfaceName&#123;SrcName: endPointInfo.VethPeerName,</span><br><span class="line">		DstPrefix: &quot;eth&quot;&#125;,</span><br><span class="line">		Gateway: GlobalEndPointCache.Network.Gateway,</span><br><span class="line">	&#125;</span><br><span class="line">	GlobalEndPointCache.EndPoints\[joinRequest.EndpointID\].SandboxKey &#x3D; joinRequest.SandboxKey</span><br><span class="line">	driver.UpdateCacheFile()</span><br><span class="line">	return &amp;response, nil</span><br><span class="line">&#125;</span><br><span class="line">&#96;</span><br></pre></td></tr></table></figure>
<p>        <br>此处代码也是在docker 创建/启动容器时调用的API，该API完成link对的创建，并未改link（在容器内部的部分）配置IP，定义网卡名称，此处最重要的是返回值中将正确的vethpari那么返回，docker daemon会将veth pair加入到容器的网络空间 （PS：开始验证的时候，一直尝试自己将这个veth pair加入到命名空间，总是不成功，后来才发现，docker Daemon 已经把这件事干了）</p>
]]></content>
  </entry>
  <entry>
    <title>docker几个不常用的命令</title>
    <url>/2020/09/21/Docker%E5%87%A0%E4%B8%AA%E4%B8%8D%E5%B8%B8%E7%94%A8%E7%9A%84%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h2 id="docker不太常用的命令"><a href="#docker不太常用的命令" class="headerlink" title="docker不太常用的命令"></a>docker不太常用的命令</h2><ul>
<li>docker ps -s #查看容器所占的磁盘大小</li>
<li>docker rm ${docker ps -q -a} # 删除全部非运行态的容器</li>
<li>docker system df #查看docker存储的使用情况</li>
<li>docker system prun #清理无用的容器、网络、数据集</li>
<li>docker rmi $(docker images | awk ‘/^<none>/ { print $3 }’) #删除的镜像repositry为none的镜像</none></li>
</ul>
<h2 id="docker配置参数"><a href="#docker配置参数" class="headerlink" title="docker配置参数"></a>docker配置参数</h2><ol>
<li>--iptables ,该参数用于控制是否允许docker去管理iptables，当设置为true时，允许docker去管理iptbales表<ul>
<li>通常在docker单独使用时，需要这样配置，如果配置为false，iptables被清空后，是无法自动创建的</li>
<li>在基于Kubernetes等管理docker时，可以配置iptables=false</li>
</ul>
</li>
<li>--ip-forward，该参数用于控主机容器与外部网络之间的相互通信，当设置为true时，允许容器被外部访问，当设置为false时，外部是无法访问到容器<ul>
<li>当宿主机设置了ip_forward参数为1时，会以宿主机的配置为准，docker的改配置参数无效</li>
</ul>
</li>
</ol>
<h2 id="迁移docker存储方式一"><a href="#迁移docker存储方式一" class="headerlink" title="迁移docker存储方式一"></a>迁移docker存储方式一</h2><p>若docker已经运行一段时间，并存在运行的容器，可以采用以下方法进行容器存储的迁移</p>
<ol>
<li>停止全部容器</li>
<li>停止docker：systemctl stop docker</li>
<li>mkdir -p /sl/docker/</li>
<li>移动docker存储：mv /var/lib/docker/* /sl/docker/</li>
<li>建立软连接：ln -s /sl/docker /var/lib/</li>
<li>systemctl start docker</li>
</ol>
<p>注意删除软连接是 rm /var/lib/docker 后面不能有斜杠，否则是删除整个目录)</p>
<h2 id="迁移docker存储方式二"><a href="#迁移docker存储方式二" class="headerlink" title="迁移docker存储方式二"></a>迁移docker存储方式二</h2><ol>
<li>停止全部容器</li>
<li>停止docker：systemctl stop docker</li>
<li>cd /sl</li>
<li>mkdir dockerdaemon</li>
<li>cd /sl/dockerdaemon</li>
<li>tar -czvpf docker.tar.gz /var/lib/docker</li>
<li>tar zxvf docker.tar.gz -C /sl/dockerdaemon</li>
<li>cd /sl/dockerdaemon/var/lib/</li>
<li>mv docker/ ../../</li>
<li>mv /var/lib/docker /sl/backup</li>
<li>ln -s /sl/dockerdaemon/docker /var/lib/</li>
</ol>
]]></content>
      <tags>
        <tag>docker</tag>
        <tag>云计算</tag>
        <tag>Container</tag>
      </tags>
  </entry>
  <entry>
    <title>docker匿名卷</title>
    <url>/2020/09/04/Docker%E5%8C%BF%E5%90%8D%E5%8D%B7/</url>
    <content><![CDATA[<p>问题</p>
<p>  在使用dockerhub中的镜像时，我通常会去查看一下该镜像的dockerfile是如何编写的，看看有没有什么好的借鉴思路,经常会发现在dockerfile里面定义Volume，如下面的dockerfile</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM davidcaste&#x2F;alpine-java-unlimited-jce:jdk8</span><br><span class="line"></span><br><span class="line">MAINTAINER David Castellanos &lt;davidcaste@gmail.com&gt;</span><br><span class="line"></span><br><span class="line">ENV TOMCAT_MAJOR&#x3D;8 \</span><br><span class="line">    TOMCAT_VERSION&#x3D;8.5.3 \</span><br><span class="line">    TOMCAT_HOME&#x3D;&#x2F;opt&#x2F;tomcat \</span><br><span class="line">    CATALINA_HOME&#x3D;&#x2F;opt&#x2F;tomcat \</span><br><span class="line">    CATALINA_OUT&#x3D;&#x2F;dev&#x2F;null</span><br><span class="line"></span><br><span class="line">RUN apk upgrade --update &amp;&amp; \</span><br><span class="line">    apk add --update curl &amp;&amp; \</span><br><span class="line">    curl -jksSL -o &#x2F;tmp&#x2F;apache-tomcat.tar.gz http:&#x2F;&#x2F;archive.apache.org&#x2F;dist&#x2F;tomcat&#x2F;tomcat-$&#123;TOMCAT_MAJOR&#125;&#x2F;v$&#123;TOMCAT_VERSION&#125;&#x2F;bin&#x2F;apache-tomcat-$&#123;TOMCAT_VERSION&#125;.tar.gz &amp;&amp; \</span><br><span class="line">    gunzip &#x2F;tmp&#x2F;apache-tomcat.tar.gz &amp;&amp; \</span><br><span class="line">    tar -C &#x2F;opt -xf &#x2F;tmp&#x2F;apache-tomcat.tar &amp;&amp; \</span><br><span class="line">    ln -s &#x2F;opt&#x2F;apache-tomcat-$&#123;TOMCAT_VERSION&#125; $&#123;TOMCAT_HOME&#125; &amp;&amp; \</span><br><span class="line">    rm -rf $&#123;TOMCAT_HOME&#125;&#x2F;webapps&#x2F;* &amp;&amp; \</span><br><span class="line">    apk del curl &amp;&amp; \</span><br><span class="line">    rm -rf &#x2F;tmp&#x2F;* &#x2F;var&#x2F;cache&#x2F;apk&#x2F;*</span><br><span class="line"></span><br><span class="line">COPY logging.properties $&#123;TOMCAT_HOME&#125;&#x2F;conf&#x2F;logging.properties</span><br><span class="line">COPY server.xml $&#123;TOMCAT_HOME&#125;&#x2F;conf&#x2F;server.xml</span><br><span class="line"></span><br><span class="line">VOLUME [&quot;&#x2F;logs&quot;]</span><br><span class="line">EXPOSE 8080</span><br></pre></td></tr></table></figure>
<p>   在上面的dockerfile中就定义了 VOLUME [“/logs”],刚开始的时候并没有注意这个，以为就是提示作用而已，直到在自己的环境中出现了存储不足的问题，在环境中我将全部的镜像、容器 都删除了，但是只是释放了一点点的空间，使用下面的命令，进行查看，发现还是占用了很多空间,</p>
<p>du -h –max-depth=1 /var/lib/docker<br>在服务器上执行了</p>
<p>docker volume ls<br>发现存在大量的卷类型为local的卷，进入到这些目录，发现全是原容器内的/logs 目录的内容，虽然容器被删除了，但是/logs 目录以容器卷的方式被持久化下来了，这显示并不是我想要的现象。解释这个现象的就是docker匿名卷了。</p>
<p>docker匿名卷</p>
<p>docker匿名卷的解释可以参考这里docker匿名卷</p>
<p>  匿名卷的目的是为了防止用户忘记将关键数据挂载到宿主机目录，为了防止运行时用户忘记将动态文件所保存目录挂载为卷，在 dockerfile中，我们可以事先指定某些目录挂载为匿名卷，这样在运行时如果用户不指定挂载，其应用也可以正常运行，不会向容器存储层写入大量数据。</p>
<p>VOLUME /data<br>  这里的 /data 目录就会在运行时自动挂载为匿名卷，任何向 /data 中写入的信息都不会记录进容器存储层，从而保证了容器存储层的无状态化。当然，运行时可以覆盖这个挂载设置。比如：</p>
<p>docker run -d -v mydata:/data xxxx</p>
<p>  在这行命令中，就使用了 mydata 这个命名卷挂载到了 /data 这个位置，替代了 dockerfile 中定义的匿名卷的挂载配置。</p>
<p>Summary</p>
<p>docker匿名卷使用还是的慎重，而且需要通知到使用者，不然存储莫名其妙的用光了</p>
]]></content>
  </entry>
  <entry>
    <title>docker使用进阶</title>
    <url>/2020/09/03/Docker%E4%BD%BF%E7%94%A8%E8%BF%9B%E9%98%B6/</url>
    <content><![CDATA[<h2 id="docker不太常用的命令"><a href="#docker不太常用的命令" class="headerlink" title="docker不太常用的命令"></a>docker不太常用的命令</h2><ul>
<li>docker ps -s  #查看容器所占的磁盘大小</li>
<li>docker rm ${docker ps -q -a} # 删除全部非运行态的容器</li>
<li>docker system df  #查看docker存储的使用情况</li>
<li>docker system prun #清理无用的容器、网络、数据集</li>
<li>docker rmi $(docker images | awk ‘/^<none>/ { print $3 }’) #删除的镜像repositry为none的镜像</none></li>
<li>删除 未被使用的镜像 docker rmi $(docker images | awk ‘ { print $3 }’)</li>
</ul>
<h2 id="docker配置参数"><a href="#docker配置参数" class="headerlink" title="docker配置参数"></a>docker配置参数</h2><ol>
<li>–iptables ,该参数用于控制是否允许docker去管理iptables，当设置为true时，允许docker去管理iptbales表<ul>
<li>通常在docker单独使用时，需要这样配置，如果配置为false，iptables被清空后，是无法自动创建的</li>
<li>在基于Kubernetes等管理docker时，可以配置iptables=false</li>
</ul>
</li>
<li>–ip-forward，该参数用于控主机容器与外部网络之间的相互通信，当设置为true时，允许容器被外部访问，当设置为false时，外部是无法访问到容器<ul>
<li>当宿主机设置了ip_forward参数为1时，会以宿主机的配置为准，docker的改配置参数无效</li>
</ul>
</li>
</ol>
<h2 id="迁移docker存储方式一"><a href="#迁移docker存储方式一" class="headerlink" title="迁移docker存储方式一"></a>迁移docker存储方式一</h2><p>若docker已经运行一段时间，并存在运行的容器，可以采用以下方法进行容器存储的迁移</p>
<ol>
<li>停止全部容器</li>
<li>停止docker：systemctl stop docker</li>
<li>mkdir -p /sl/docker/</li>
<li>移动docker存储：mv /var/lib/docker/* /sl/docker/</li>
<li>建立软连接：ln -s /sl/docker /var/lib/</li>
<li>systemctl start docker</li>
</ol>
<p>==注意删除软连接是 rm /var/lib/docker  后面不能有斜杠，否则是删除整个目录)==</p>
<h2 id="迁移docker存储方式二"><a href="#迁移docker存储方式二" class="headerlink" title="迁移docker存储方式二"></a>迁移docker存储方式二</h2><ol>
<li>停止全部容器</li>
<li>停止docker：systemctl stop docker</li>
<li>cd /sl</li>
<li>mkdir dockerdaemon</li>
<li>cd /sl/dockerdaemon</li>
<li>tar  -czvpf docker.tar.gz /var/lib/docker</li>
<li>tar  zxvf docker.tar.gz -C /sl/dockerdaemon</li>
<li>cd /sl/dockerdaemon/var/lib/</li>
<li>mv docker/ ../../</li>
<li>mv /var/lib/docker /sl/backup</li>
<li>ln -s /sl/dockerdaemon/docker /var/lib/</li>
</ol>
<h2 id="基于操作系统制作docker镜像"><a href="#基于操作系统制作docker镜像" class="headerlink" title="基于操作系统制作docker镜像"></a>基于操作系统制作docker镜像</h2><p>执行以下操作</p>
<ol>
<li>tar –exclude=/usr/lib32  -cPvf fedora21-base.tar /home</li>
</ol>
<p>将本机运行的操作系统打成一个fedora21-base.tar包，其中–exclude参数是将不需要的目录排除，可以使用–exclude多个参数排除多个目录。</p>
<ol start="2">
<li>cat fedora21-base.tar | docker import - fedora21-base</li>
</ol>
<p>将tar包使用docker import编译导入镜像</p>
<ol start="3">
<li>docker run -i -t fedora21-base  /bin/bash</li>
</ol>
<p>启动镜像。-i 代表打开标准输入 -t 虚拟一个窗口 /bin/bash启动镜像执行的命令</p>
<h2 id="进入容器命名空间"><a href="#进入容器命名空间" class="headerlink" title="进入容器命名空间"></a>进入容器命名空间</h2><p>获取容器的init pid<br>cat /run/containerd/io.containerd.runtime.v1.linux/moby/7208ab53697925439605bca93718c6158db354909fedbe7a1f96ddcd5d5563db/init.pid<br>18399<br>进入mount 命名空间,可以直接查看容器的目录空间<br>nsenter -t 18399 -m<br>进入</p>
]]></content>
  </entry>
  <entry>
    <title>docker插件机制</title>
    <url>/2020/09/21/Docker%E6%8F%92%E4%BB%B6%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<h2 id="docker-插件是什么"><a href="#docker-插件是什么" class="headerlink" title="docker 插件是什么"></a>docker 插件是什么</h2><p>docker 插件是 docker 提供出来的扩展机制，目前 docker 支持 volume 和 network 两种插件，由于 network 插件比较复杂而且没有好的开源项目，这里主要介绍 volume 插件。</p>
<p>插件是一个独立的进程和 docker daemon 运行在同一台 host 上，通过 Plugin Discovery 的机制进行插件发现，插件有几个要求：</p>
<ul>
<li>插件名要求是小写</li>
<li>插件可以运行在容器内也可以运行在容器外，不过现阶段建议运行在容器外</li>
</ul>
<h2 id="插件发现"><a href="#插件发现" class="headerlink" title="插件发现"></a>插件发现</h2><p>插件发现机制需要插件将自己的地址文件放在固定目录，方便 docker 发现插件进程，有三种文件可以设置：</p>
<ul>
<li>.sock 文件是 UNIX domain sockets</li>
<li>.spec 文本文件内包含了一个 URL，比如：unix:///other.sock</li>
<li>.json 文本文件包含了插件的完整 JSON 描述</li>
</ul>
<p>UNIX domain socket 文件必须放在 /run/docker/plugins 目录，但是 .spec，.json 文件则可以放在/etc/docker/plugins 或者 /usr/lib/docker/plugins 中。</p>
<p>无后缀的文件名决定了插件的名字，比如 /run/docker/plugins/myplugin.sock 的插件名就是myplugin。你可以在子目录中放置地址文件，比如 /run/docker/plugins/myplugin/myplugin.sock。</p>
<p>docker 优先搜索 /run/docker/plugins 目录，如果没有 unix socket 的话才会去搜索/etc/docker/plugins 和 /usr/lib/docker/plugins，如果根据指定插件名搜到了插件就会立马停止搜索。</p>
<h3 id="json"><a href="#json" class="headerlink" title=".json"></a>.json</h3><p>JSON 格式文件示例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;  &quot;Name&quot;: &quot;plugin-example&quot;,  &quot;Addr&quot;: &quot;https:&#x2F;&#x2F;example.com&#x2F;docker&#x2F;plugin&quot;,  &quot;TLSConfig&quot;: &#123;  &quot;InsecureSkipVerify&quot;: false,  &quot;CAFile&quot;: &quot;&#x2F;usr&#x2F;shared&#x2F;docker&#x2F;certs&#x2F;example-ca.pem&quot;,  &quot;CertFile&quot;: &quot;&#x2F;usr&#x2F;shared&#x2F;docker&#x2F;certs&#x2F;example-cert.pem&quot;,  &quot;KeyFile&quot;: &quot;&#x2F;usr&#x2F;shared&#x2F;docker&#x2F;certs&#x2F;example-key.pem&quot;,  &#125; &#125;</span><br></pre></td></tr></table></figure>

<h2 id="插件生命周期"><a href="#插件生命周期" class="headerlink" title="插件生命周期"></a>插件生命周期</h2><ul>
<li>启动插件</li>
<li>启动 docker</li>
<li>停止 docker</li>
<li>停止插件</li>
</ul>
<h2 id="插件激活"><a href="#插件激活" class="headerlink" title="插件激活"></a>插件激活</h2><p>运行命令 docker run –volume-driver=foo 即可以激活名为 foo 的 volume 插件，需要注意的是，插件是按需加载机制，只有被使用到了才会被激活。</p>
<h2 id="volume-插件使用"><a href="#volume-插件使用" class="headerlink" title="volume 插件使用"></a>volume 插件使用</h2><p>示例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ docker run -ti -v volumename:&#x2F;data \--volume-driver&#x3D;flocker busybox sh</span><br></pre></td></tr></table></figure>

<p>上面表示的意思是，使用 flocker 插件将 voluemname 挂载到容器的 /data 目录。</p>
<p>注意：volumename 一定不能以 / 开头。（文档说的，没看 docker 源码，我实现一个以 / 开头好像也没问题，应该是规范吧）</p>
<h2 id="插件-API-设计"><a href="#插件-API-设计" class="headerlink" title="插件 API 设计"></a>插件 API 设计</h2><p>插件是 API 是基于 HTTP 的 JSON POST 请求，所以插件需要实现一个 HTTP 服务器并且将其 bind 到一个 UNIX socket 上。API 的版本设置在了 HTTP<br>头里面，现在这个头的固定值为：application/vnd.docker.plugins.v1+json</p>
<p>不过 docker 的开发人员已经提供了一个比较好的 docker volume 的扩展 API 代码，可以参考：<a href="https://github.com/calavera/dkvolume" target="_blank" rel="noopener">docker-volume-extension-api</a></p>
<h3 id="Plugin-Activate"><a href="#Plugin-Activate" class="headerlink" title="/Plugin.Activate"></a>/Plugin.Activate</h3><p>请求：空</p>
<p>响应：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;  &quot;Implements:&quot; \[&quot;VolumeDriver&quot;\] &#125;</span><br></pre></td></tr></table></figure>

<p>返回插件实现，表示是 volume 插件</p>
<h3 id="VolumeDriver-Create"><a href="#VolumeDriver-Create" class="headerlink" title="/VolumeDriver.Create"></a>/VolumeDriver.Create</h3><p>请求：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;  &quot;Name&quot;: &quot;volume\_name&quot; &#125;</span><br></pre></td></tr></table></figure>

<p>告诉插件用户想要创建一个 volume，并将用户输入的 volume 名传给插件。插件在这个时候可以不用理会这个请求，会有真正挂载的请求。</p>
<p>响应：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;  &quot;Err&quot;: null &#125;</span><br></pre></td></tr></table></figure>

<p>如果出错返回错误字符串。</p>
<h3 id="VolumeDriver-Remove"><a href="#VolumeDriver-Remove" class="headerlink" title="/VolumeDriver.Remove"></a>/VolumeDriver.Remove</h3><p>与 Create 相对应。</p>
<p>请求：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;  &quot;Name&quot;: &quot;volume\_name&quot; &#125;</span><br></pre></td></tr></table></figure>

<p>响应：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;  &quot;Err&quot;: null &#125;</span><br></pre></td></tr></table></figure>

<h3 id="VolumeDriver-Mount"><a href="#VolumeDriver-Mount" class="headerlink" title="/VolumeDriver.Mount"></a>/VolumeDriver.Mount</h3><p>请求：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;  &quot;Name&quot;: &quot;volume\_name&quot; &#125;</span><br></pre></td></tr></table></figure>

<p>用户请求挂载某个文件，这个请求仅会在容器启动时发送一次。</p>
<p>响应：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;  &quot;Mountpoint&quot;: &quot;&#x2F;path&#x2F;to&#x2F;directory&#x2F;on&#x2F;host&quot;,  &quot;Err&quot;: null &#125;</span><br></pre></td></tr></table></figure>

<p>将 volume_name 挂载的真正挂载点返回给 docker，如果出错则返回错误字符串。</p>
<h3 id="VolumeDriver-Path"><a href="#VolumeDriver-Path" class="headerlink" title="/VolumeDriver.Path"></a>/VolumeDriver.Path</h3><p>请求：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;  &quot;Name&quot;: &quot;volume\_name&quot; &#125;</span><br></pre></td></tr></table></figure>

<p>响应：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;  &quot;Mountpoint&quot;: &quot;&#x2F;path&#x2F;to&#x2F;directory&#x2F;on&#x2F;host&quot;,  &quot;Err&quot;: null &#125;</span><br></pre></td></tr></table></figure>

<p>插件需要管理 volume_name 的真正挂载地址，这个请求需要将 volume_name 挂载的真正挂载点返回给 docker，如果出错则返回错误字符串。</p>
<h3 id="VolumeDriver-Unmount"><a href="#VolumeDriver-Unmount" class="headerlink" title="/VolumeDriver.Unmount"></a>/VolumeDriver.Unmount</h3><p>请求：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;  &quot;Name&quot;: &quot;volume\_name&quot; &#125;</span><br></pre></td></tr></table></figure>

<p>表示 docker 已经不需要这个 volume 了，插件需要安全的将这个挂载从挂载点卸载。</p>
<p>响应：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;  &quot;Err&quot;: null &#125;</span><br><span class="line">&#96;&#96;&#96;</span><br></pre></td></tr></table></figure>
<p>（<a href="http://hongweiyi.com/2015/10/docker-volume-plugin/%EF%BC%89" target="_blank" rel="noopener">http://hongweiyi.com/2015/10/docker-volume-plugin/）</a></p>
]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>docker容器内的信号处理</title>
    <url>/2020/09/21/Docker%E5%AE%B9%E5%99%A8%E5%86%85%E7%9A%84%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<p>docker 关闭Container的思路：当我们使用docker stop 命令去关闭Container时，该命令会发送SIGTERM 命令到Container主进程，让主进程处理该信号，关闭Container，如果在10s内，未关闭容器，docker Damon会发送SIGKILL 信号将Container关闭。</p>
<h2 id="Signal"><a href="#Signal" class="headerlink" title="       Signal"></a>       Signal</h2><p>Signal 表示内部进程的一种通信机制，一个信号表示一个从内核发送到进程的消息，该消息表示某个事件已经发生，当进程收到该信号，进程会被打断，一个信号处理句柄会处理该信号，如果没有针对该信号的句柄，会使用默认句柄处理该信号。</p>
<p>进程会将自己可以处理的信号以回调函数的方式注册到系统内核，当你在终端执行一个Kill命令时，实际上你是在通知内核向其他进程发送信号。一个常见的信号时 SIGTERM，该信号时通知进程关闭并终止，当进程收到该信号时，可以执行关闭Socket、数据库连接、删除临时文件等。许多守护进程会处理SIGHUP信号，从而能够重新加载配置文件，SIGUSR1和SIGUSR2是用户自定义的信号，可以在应用中处理该信号。</p>
<p> 举例,在Node.js中处理SIGTERM信号</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">process.on(&#39;SIGTERM&#39;, function() &#123;</span><br><span class="line">  console.log(&#39;shutting down...&#39;);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>



<p>当进程处理SIGTERM信号时，处理该信号的句柄会将程序的执行打断，当该句柄执行完成后，程序才会继续运行，常见的信号如下表所示， 除了SIGKILL 和SIGSTOP信号外，其他信号都可以被进程终止</p>
<p> <img src="/2020/09/21/Docker%E5%AE%B9%E5%99%A8%E5%86%85%E7%9A%84%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/uploads/2016/06/20160630141912_66480.png"></p>
<h2 id="docker中的信号"><a href="#docker中的信号" class="headerlink" title="docker中的信号"></a>docker中的信号</h2><p>docker命令“docker kill”向容器内的主进程发送信号</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Usage: docker kill \[OPTIONS\] CONTAINER \[CONTAINER...\]</span><br><span class="line">Kill a running container using SIGKILL or a specified signal</span><br><span class="line">    -s, --signal&#x3D;&quot;KILL&quot;    Signal to send to the container</span><br></pre></td></tr></table></figure>



<p>发送到容器的信号被容器的主进程（PID为1）处理，主进程可以忽略该信号，让默认的操作执行，或者为该信号提供一个回调函数。</p>
<p>举例，在容器内运行一个应用，检查信号处理句柄。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var http &#x3D; require(&#39;http&#39;);</span><br><span class="line">var server &#x3D; http.createServer(function (req, res) &#123;</span><br><span class="line">  res.writeHead(200, &#123;&#39;Content-Type&#39;: &#39;text&#x2F;plain&#39;&#125;);</span><br><span class="line">  res.end(&#39;Hello World\\n&#39;);</span><br><span class="line">&#125;).listen(3000, &#39;0.0.0.0&#39;);</span><br><span class="line">console.log(&#39;server started&#39;);</span><br><span class="line">var signals &#x3D; &#123; &#39;SIGINT&#39;: 2, &#39;SIGTERM&#39;: 15</span><br><span class="line">&#125;;</span><br><span class="line">function shutdown(signal, value) &#123; server.close(function () &#123; console.log(&#39;server stopped by &#39; + signal);</span><br><span class="line">    process.exit(128 + value);</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br><span class="line">Object.keys(signals).forEach(function (signal) &#123;</span><br><span class="line">  process.on(signal, function () &#123; shutdown(signal, signals\[signal\]);</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>



<p> 我们创建了一个监听3000端口的http server，创建了两个信号处理句柄，分别处理SIGINT和SIGTERM信号，当信号句柄执行时，将会在标准输出打印：</p>
<p>   `server stopped by [SIGNAL]`.</p>
<p>分两种场景描述</p>
<h3 id="该应用是前端应用"><a href="#该应用是前端应用" class="headerlink" title="该应用是前端应用"></a>该应用是前端应用</h3><p>当应用是该容器的主进程时，他能够直接处理信号，以下该应用的dockerfile文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM iojs:onbuild</span><br><span class="line">COPY .&#x2F;program.js .&#x2F;program.js</span><br><span class="line">COPY .&#x2F;package.json .&#x2F;package.json</span><br><span class="line">EXPOSE 3000</span><br><span class="line">ENTRYPOINT \[&quot;node&quot;, &quot;program&quot;\]</span><br></pre></td></tr></table></figure>



<p>当在编写dockerfile文件的时候，启动应用一定要使用ENTRYPOINT或者RUN 命令，否则容器内的主进程将会是/bin/sh –c ，应用只能是主进程的子进程，如果是这样的话，应用是无法收到信号的。</p>
<p>构建镜像:</p>
<p>$ docker build -t signal-fg-app .</p>
<p>运行容器</p>
<p>$ docker run -it –rm -p 3000:3000 –name=”signal-fg-app” signal-fg-app</p>
<p>访问 <a href="http://localhost:3000/" target="_blank" rel="noopener">http://localhost:3000</a> 验证应用正常运行</p>
<p>打开另一个终端执行docker kill 命令</p>
<p>$ docker kill –signal=”SIGTERM” signal-fg-app</p>
<p>或者</p>
<p>$ docker stop signal-fg-app</p>
<p>这两个命令都可以发送SIGTERM信号来停止应用</p>
<p>Both commands can be used to issue SIGTERM signal and stop the application.</p>
<p>在运行应用的终端，可以看到下面的输出日志</p>
<p>server stopped by SIGTERM</p>
<h3 id="当应用是后台应用时"><a href="#当应用是后台应用时" class="headerlink" title="当应用是后台应用时"></a>当应用是后台应用时</h3><p>无法直接将信号发送到该应用，这种场景下的一种解决方法是：以shell脚本的方式启动应用，在这个启动脚本里处理全部的信号，制作该应用的Dokcerfile文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dockerfile:</span><br><span class="line">FROM iojs:onbuild</span><br><span class="line">COPY .&#x2F;program.js .&#x2F;program.js</span><br><span class="line">COPY .&#x2F;program.sh .&#x2F;program.sh</span><br><span class="line">COPY .&#x2F;package.json .&#x2F;package.json</span><br><span class="line">RUN  chmod +x .&#x2F;program.sh</span><br><span class="line">EXPOSE 3000</span><br><span class="line">ENTRYPOINT \[&quot;.&#x2F;program.sh&quot;\]</span><br></pre></td></tr></table></figure>

<p>查看启动脚本program.sh</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;env bash</span><br><span class="line">set -x</span><br><span class="line"></span><br><span class="line">pid&#x3D;0</span><br><span class="line"></span><br><span class="line"># SIGUSR1-handler</span><br><span class="line">my\_handler() &#123;</span><br><span class="line">  echo &quot;my\_handler&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># SIGTERM-handler</span><br><span class="line">term\_handler() &#123;</span><br><span class="line">  if \[ $pid -ne 0 \]; then</span><br><span class="line">    kill -SIGTERM &quot;$pid&quot;</span><br><span class="line">    wait &quot;$pid&quot;</span><br><span class="line">  fi</span><br><span class="line">  exit 143; # 128 + 15 -- SIGTERM</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># setup handlers</span><br><span class="line"># on callback, kill the last background process, which is \&#96;tail -f &#x2F;dev&#x2F;null\&#96; and execute the specified handler</span><br><span class="line">trap &#39;kill $&#123;!&#125;; my\_handler&#39; SIGUSR1</span><br><span class="line">trap &#39;kill $&#123;!&#125;; term\_handler&#39; SIGTERM</span><br><span class="line"></span><br><span class="line"># run application</span><br><span class="line">node program &amp;</span><br><span class="line">pid&#x3D;&quot;$!&quot;</span><br><span class="line"></span><br><span class="line"># wait indefinetely</span><br><span class="line">while true</span><br><span class="line">do</span><br><span class="line">  tail -f &#x2F;dev&#x2F;null &amp; wait $&#123;!&#125;</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<p>这里我们创建了两个信号处理函数，一个是处理用户定义的信号，一个是处理SIGTEM信号，能够优雅的关闭应用。</p>
<p>在这个应用中，我们的应用是后台运行的（&amp;），最后，我们使用“wait”来暂停运行，直到一个子进程退出，“wait”和“waitpid”这两个函数在收到信号时，会终止执行，当收到信号后，我们使用特定的句柄处理信号。</p>
<p>  docker的文档中说明，SIGCHLD, SIGKILL, and SIGSTOP 是无法代管的。</p>
<p>构建镜像：</p>
<p>docker build -t signal-bg-app .</p>
<p>运行容器:</p>
<p>docker run -it –rm -p 3000:3000 –name=”signal-bg-app” signal-bg-app</p>
<p>打开一个新的终端，发送 SIGUSR1 信号 :</p>
<p>docker kill –signal=”SIGUSR1” signal-bg-app</p>
<p>最后停止应用</p>
<p>docker kill –signal=”SIGTERM” signal-bg-app</p>
<p>应用能够打印相应的日志，并能够优雅的关闭</p>
<p>结论</p>
<p>信号提供了一中处理异步事件的方法，容器能运行的应用可以使用信号进行消息交互。使用信号与主机内的应用进行交互、重新加载配置文件、做一些清楚工作或者多进程协作。</p>
<p>英文地址：</p>
<p><a href="https://medium.com/@gchudnov/trapping-signals-in-docker-containers-7a57fdda7d86#.ukb9dqt9k" target="_blank" rel="noopener">https://medium.com/@gchudnov/trapping-signals-in-docker-containers-7a57fdda7d86#.ukb9dqt9k</a></p>
]]></content>
      <tags>
        <tag>docker</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>docker镜像仓库删除历史版本</title>
    <url>/2020/09/21/Docker%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93%E5%88%A0%E9%99%A4%E5%8E%86%E5%8F%B2%E7%89%88%E6%9C%AC/</url>
    <content><![CDATA[<p>DevOps环境使用的镜像仓库，一个产品的版本越来越多，需要能够定时将不再使用的历史版本进行删除，编写乐意一段代码，用于删除历史版本的镜像，如下所示```</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import argparse</span><br><span class="line">import http.client</span><br><span class="line">import urllib.error</span><br><span class="line">import urllib.request</span><br><span class="line">import json</span><br><span class="line">import urllib3</span><br><span class="line">import requests</span><br><span class="line">REGISTRY_URL&#x3D;&quot;http:&#x2F;&#x2F;10.10.70.65&quot;</span><br><span class="line">MOST_TAG_NUMBER&#x3D;3</span><br><span class="line">def getAllRepos(registry_repo_url):</span><br><span class="line">    try:</span><br><span class="line">        resp &#x3D; urllib.request.urlopen(registry_repo_url) # type http.client.HTTPResponse</span><br><span class="line">        response &#x3D; resp.read()</span><br><span class="line">    except urllib.error.HTTPError as error:</span><br><span class="line">        print(&quot;get repo error&quot;,error)</span><br><span class="line">    return json.loads(response)</span><br><span class="line"></span><br><span class="line">def getImageDigest(repoName,tagName):</span><br><span class="line">    #http: &#x2F;&#x2F; 10.10.70.65 &#x2F; v2 &#x2F; arch &#x2F; archdemo &#x2F; manifests &#x2F; 1 - 1881</span><br><span class="line"></span><br><span class="line">    #curl -H &quot;Accept: application&#x2F;vnd.docker.distribution.manifest.v2 + json&quot; -X GET -vvv -k http:&#x2F;&#x2F;10.10.70.65&#x2F;v2&#x2F;good_image&#x2F;manifests&#x2F;latest 100</span><br><span class="line"></span><br><span class="line">    try:</span><br><span class="line">        req &#x3D; urllib.request.Request(REGISTRY_URL + &quot;&#x2F;v2&#x2F;&quot; + repoName + &quot;&#x2F;manifests&#x2F;&quot;+tagName)</span><br><span class="line">        req.add_header(&#39;Accept&#39;, &#39;application&#x2F;vnd.docker.distribution.manifest.v2+json&#39;)</span><br><span class="line">        resp &#x3D; urllib.request.urlopen(req)</span><br><span class="line">      #  content &#x3D; resp.read()</span><br><span class="line">       # print(&quot;all is&quot;, resp)</span><br><span class="line"></span><br><span class="line">        #print(&quot;content is &quot;,content)</span><br><span class="line">        #print(&quot;digest is&quot;,resp.headers[&quot;docker-Content-Digest&quot;])</span><br><span class="line">    except urllib.error.HTTPError as error:</span><br><span class="line">        print(&quot;get repo error&quot;,error)</span><br><span class="line">    return resp.headers[&quot;docker-Content-Digest&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def deleteTagByTag(repoName, tagName):</span><br><span class="line">    imageDigest&#x3D;getImageDigest(repoName, tagName)</span><br><span class="line">    try:</span><br><span class="line">        print(&quot;delete image %s:%s,digest is %s&quot; %(repoName,tagName,imageDigest))</span><br><span class="line">        req &#x3D; urllib.request.Request(REGISTRY_URL + &quot;&#x2F;v2&#x2F;&quot; + repoName + &quot;&#x2F;manifests&#x2F;&quot;+imageDigest)</span><br><span class="line">        req.get_method &#x3D; lambda: &#39;DELETE&#39;</span><br><span class="line">        resp &#x3D; urllib.request.urlopen(req)</span><br><span class="line">        code &#x3D; resp.getcode()</span><br><span class="line">        print(&quot;delet image code is &quot;,code)</span><br><span class="line">    except urllib.error.HTTPError as error:</span><br><span class="line">        print(&quot;delete image error&quot;,error)</span><br><span class="line"></span><br><span class="line">def cleanByRepo(repoName):</span><br><span class="line">    print(&quot;repos is &quot; + repoName)</span><br><span class="line">    tagList &#x3D; getTagsByRepoNames(REGISTRY_URL + &quot;&#x2F;v2&#x2F;&quot; + repoName + &quot;&#x2F;tags&#x2F;list&quot;)# type</span><br><span class="line">    print(&quot;tagList is &quot;, tagList)</span><br><span class="line">    if tagList[&quot;tags&quot;] is None:</span><br><span class="line">       print(&quot;repo not need to clean,tag is None&quot;, repoName)</span><br><span class="line">       return</span><br><span class="line">    if len(tagList[&quot;tags&quot;])&lt;2:</span><br><span class="line">        print(&quot;repo not need to clean&quot;,repoName)</span><br><span class="line">        return</span><br><span class="line">    tagNum&#x3D;0</span><br><span class="line">    tagNameList&#x3D;[]</span><br><span class="line">    for tag in tagList[&quot;tags&quot;]:</span><br><span class="line">        if tag.startswith(&quot;1-&quot;):</span><br><span class="line">            tagNum&#x3D;tagNum+1</span><br><span class="line">            tagNameList.append(tag)</span><br><span class="line"></span><br><span class="line">    if tagNum&lt;MOST_TAG_NUMBER:</span><br><span class="line">        print(&quot;repo %s not need to clean,tag num %s  is less than 4&quot;   % (repoName,tagNum))</span><br><span class="line">        return</span><br><span class="line"></span><br><span class="line">    #print(&quot;repo  %s need to delete some tag,tag num is %s&quot;, % (repoName,tagNum))</span><br><span class="line">    print(&quot;repo  %s need to delete some tag,tag num is %s  &quot; % (repoName,tagNum))</span><br><span class="line">    tagNameList.sort(reverse&#x3D;True)</span><br><span class="line">    for index, _ in enumerate(tagNameList):</span><br><span class="line">        if index&gt;3:</span><br><span class="line">            deleteTagByTag(repoName,tagNameList[index])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def getTagsByRepoNames(registry_repo_url):</span><br><span class="line">    try:</span><br><span class="line">        resp &#x3D; urllib.request.urlopen(registry_repo_url)</span><br><span class="line">        response &#x3D; resp.read()</span><br><span class="line">    except urllib.error.HTTPError as error:</span><br><span class="line">        print(&quot;get repo error&quot;,error)</span><br><span class="line">    return json.loads(response)</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    print(&quot;get all repo&quot;)</span><br><span class="line">    response&#x3D;getAllRepos(REGISTRY_URL + &quot;&#x2F;v2&#x2F;_catalog?n&#x3D;100000&quot;)</span><br><span class="line">    print(&quot;response is &quot;,response)</span><br><span class="line">    print(&quot;repos list is&quot;,response[&quot;repositories&quot;])</span><br><span class="line"></span><br><span class="line">    for repo in response[&quot;repositories&quot;]:</span><br><span class="line">        cleanByRepo(repo)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p>上面的代码能保存最新的几个版本的镜像，我这里的版本镜像是以“1-” 开头为标识，执行完该代码后，还需要在镜像仓库的节点，执行以下命令，进行存储回收：```</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">registry garbage-collect &#x2F;etc&#x2F;docker&#x2F;registry&#x2F;config.yml</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>Container</tag>
      </tags>
  </entry>
  <entry>
    <title>Golang 读取写入Etcd数据库</title>
    <url>/2020/09/21/Golang-%E8%AF%BB%E5%8F%96%E5%86%99%E5%85%A5Etcd%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
    <content><![CDATA[<p>           项目中用到Etcd数据库来存储容器的信息和应用的域名信息，将操作Etcd的golang代码整理了一下</p>
<p>1、将Container信息写入到指定目录</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">c, err :&#x3D; common.GetEtcdClient()</span><br><span class="line">	if err !&#x3D; nil &#123;</span><br><span class="line">		beego.Error(&quot;get etcd client failed&quot;)</span><br><span class="line">		return</span><br><span class="line">	&#125;</span><br><span class="line">	kapi :&#x3D; client.NewKeysAPI(c)</span><br><span class="line">	key :&#x3D; getSkyDnsDomain(domainEtcd.Domain)</span><br><span class="line">	value, \_ :&#x3D; json.Marshal(domainEtcd)</span><br><span class="line">	var etcderr error</span><br><span class="line">	common.HaproxyTemplateCache.Lock.Lock()</span><br><span class="line">	defer common.HaproxyTemplateCache.Lock.Unlock()</span><br><span class="line"></span><br><span class="line">	switch domainEtcd.Action &#123;</span><br><span class="line">	case &quot;add&quot;:</span><br><span class="line">		\_, etcderr &#x3D; kapi.Create(context.Background(), key, string(value))</span><br><span class="line">		common.HaproxyTemplateCache.Data\[domainEtcd.Domain\] &#x3D; &amp;models.HaproxyConfigration&#123;</span><br><span class="line">			DomainEtcd: domainEtcd,</span><br><span class="line">		&#125;</span><br><span class="line">	case &quot;delete&quot;:</span><br><span class="line">		\_, etcderr &#x3D; kapi.Delete(context.Background(), key, &amp;client.DeleteOptions&#123;&#125;)</span><br><span class="line">		delete(common.HaproxyTemplateCache.Data, domainEtcd.Domain)</span><br><span class="line">	&#125;</span><br><span class="line">	if etcderr !&#x3D; nil &#123;</span><br><span class="line">		beego.Error(&quot;updatecontainer event erro&quot;, etcderr)</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>2、读取Etcd的缓存数据 example，只获取其中的非目录信息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func loadHaproxyTemplateCache() &#123;</span><br><span class="line">	HaproxyTemplateCache.Lock.Lock()</span><br><span class="line">	defer HaproxyTemplateCache.Lock.Unlock()</span><br><span class="line">	HaproxyTemplateCache.Data &#x3D; make(map\[string\]\*models.HaproxyConfigration)</span><br><span class="line">	client1, \_ :&#x3D; GetEtcdClient()</span><br><span class="line">	api :&#x3D; client.NewKeysAPI(client1)</span><br><span class="line">	&#x2F;\*set skydns domain info\*&#x2F;</span><br><span class="line">	res, err1 :&#x3D; api.Get(context.Background(), &quot;&#x2F;skydns&#x2F;local&quot;, &amp;client.GetOptions&#123;Recursive: true&#125;)</span><br><span class="line">	if err1 !&#x3D; nil &#123;</span><br><span class="line">		beego.Error(&quot;get &#x2F;dockerstack info failed&quot;)</span><br><span class="line">		return</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	skydnsNodesInfo :&#x3D; make(map\[string\]string)</span><br><span class="line">	getAllNode(res.Node, skydnsNodesInfo)</span><br><span class="line">	var domain models.DomainEtcd</span><br><span class="line">	for \_, domainStr :&#x3D; range skydnsNodesInfo &#123;</span><br><span class="line">		json.Unmarshal(\[\]byte(domainStr), &amp;domain)</span><br><span class="line">		HaproxyTemplateCache.Data\[domain.Domain\].DomainEtcd &#x3D; &amp;domain</span><br><span class="line">	&#125;</span><br><span class="line">	&#x2F;\*set dockerstack container info\*&#x2F;</span><br><span class="line">	res, err1 &#x3D; api.Get(context.Background(), &quot;&#x2F;dockerstack&quot;, &amp;client.GetOptions&#123;Recursive: true&#125;)</span><br><span class="line">	if err1 !&#x3D; nil &#123;</span><br><span class="line">		beego.Error(&quot;get &#x2F;dockerstack info failed&quot;)</span><br><span class="line">		return</span><br><span class="line">	&#125;</span><br><span class="line">	dockerstackNodesInfo :&#x3D; make(map\[string\]string)</span><br><span class="line">	getAllNode(res.Node, dockerstackNodesInfo)</span><br><span class="line">	var container models.ContainerEtcd</span><br><span class="line">	for \_, containerStr :&#x3D; range skydnsNodesInfo &#123;</span><br><span class="line">		json.Unmarshal(\[\]byte(containerStr), &amp;container)</span><br><span class="line">		HaproxyTemplateCache.Data\[domain.Domain\].Containers\[container.ContainerId\] &#x3D; &amp;container</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">func getAllNode(rootNode \*client.Node, nodesInfo map\[string\]string) &#123;</span><br><span class="line">	if !rootNode.Dir &#123;</span><br><span class="line">		nodesInfo\[rootNode.Key\] &#x3D; rootNode.Value</span><br><span class="line">		return</span><br><span class="line">	&#125;</span><br><span class="line">	for node :&#x3D; range rootNode.Nodes &#123;</span><br><span class="line">		getAllNode(rootNode.Nodes\[node\], nodesInfo)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>附 etcd存储的数据结构信息：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;the container info in etcd</span><br><span class="line">type ContainerEtcd struct &#123;</span><br><span class="line">	HostIp        string</span><br><span class="line">	HostPort      int64</span><br><span class="line">	Domain        string</span><br><span class="line">	ContainerId   string</span><br><span class="line">	ContainerIp   string</span><br><span class="line">	ContainerPort int64</span><br><span class="line">	Action        string</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;domain info in etcd</span><br><span class="line">type DomainEtcd struct &#123;</span><br><span class="line">	Port   int64</span><br><span class="line">	Host   string</span><br><span class="line">	Domain string</span><br><span class="line">	Action string</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">type HaproxyConfigration struct &#123;</span><br><span class="line">	DomainEtcd \*DomainEtcd</span><br><span class="line">	Containers map\[string\]\*ContainerEtcd</span><br><span class="line">&#125;</span><br><span class="line">type HaproxyTemplateCache struct &#123;</span><br><span class="line">	Data map\[string\]\*HaproxyConfigration</span><br><span class="line">	Lock sync.RWMutex</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>本文只是想提供一些代码参考，业务内容就不细讲了。。</p>
]]></content>
  </entry>
  <entry>
    <title>DevOps 理解整理</title>
    <url>/2020/09/21/DevOps-%E7%90%86%E8%A7%A3%E6%95%B4%E7%90%86/</url>
    <content><![CDATA[<h1 id="传统的软件开发流程"><a href="#传统的软件开发流程" class="headerlink" title="传统的软件开发流程"></a>传统的软件开发流程</h1><p><img src="/2020/09/21/DevOps-%E7%90%86%E8%A7%A3%E6%95%B4%E7%90%86/uploads/image/20170922/1506070794227148.png" alt="image.png" title="1506070794227148.png"></p>
<p>  存在的问题：</p>
<p>1、 资源获取和环境准备效率低，缺少标准化化、自主的化的服务能力</p>
<p>2、 从代码开发到环境运行的流程不顺畅，开发人员不清楚最终的软件会如何部署和运行，测试人员不了解软件测试的重点和风险点在什么地方，运维人员不清楚软件架构的高可用设计是如何实现的，部门之间基本靠非常零碎、极易过时的文档或者口头沟通来交换信息</p>
<p>在产品研发的起始阶段，忙于需求分析、架构设计、代码实现，以上两个问题被大多数人认为比较容易处理。等到快上线的时候，出现上线失败或者临时方案上线</p>
<h1 id="DevOps"><a href="#DevOps" class="headerlink" title="DevOps"></a>DevOps</h1><p>DevOps理念： 提倡开发、测试、IT运维之间的高度协同，从而完成高频率部署的同时，提高生产环境的可靠性、稳定性、弹性、安全性</p>
<p>开发与IT运维：产品的价值在于业务（定义需求）和客户（交付价值）之间</p>
<p>DevOPs本身不能完全被工具和软件来简单的定义和量化，但工具和软件是实现DevOps的一个重要组成部分 </p>
<p>解决的问题：</p>
<p>1、 一些关于产品改善和创新的想法很难落地，设计到一些遗留系统的配合：调整、部署、扩展。新的服务或者应用构建、很难快速上线，被卡在了生产环境部署阶段</p>
<p>2、 不同种类的应用、服务的部署方式和流程不一致，运维团队很难为大量不同技术栈的团队提供快速响应。</p>
<p>3、 微服务的兴起，交付团队难以做到快速集成和部署。运维团队对微服务的部署方式不理解，不能适配新架构下的交付模式，开发团队大多关注代码和架构，对于产品如何在能在生产环境稳定运行、需要考虑哪些安全性和可持续性的因素并不是很了解。开发阶段，系统的架构和依赖环境都是开发者决定，对生产环境的关注度不高。部署、发布阶段，运维人员会考虑如何构建一套稳定的基础设施，又如何去部署和运维开发的产品。</p>
<h2 id="持续集成"><a href="#持续集成" class="headerlink" title="持续集成"></a>持续集成</h2><p>持续集成是一种软件项目管理方法，依据资产库（源码、类库）等的变更自动完成编译、测试、部署和反馈。持续集成已经广泛用于现代软件开发流程中，能够带来的好处：快速发现错误和促进代码分支的集成。</p>
<p>带来的价值：</p>
<p>   1、提高软件质量：每天或者每周进行多次集成，并进行测试，有利于发现软件缺陷，最终提高软件质量</p>
<p>   2、减少重复劳动：自动化工具编译代码、打包、上传、部署、测试，无需太多人工干预，让开发者更多精力专注于软件逻辑实现</p>
<p>   3、增强项目的预见性：每次操作会记录详细的输入输出结果，为后续产品缺陷是否收敛提供数据支撑。通过这些数据分析增加项目的预见性。</p>
<p>  4、增强团队对产品的信息</p>
<p>如何做到产品的持续集成</p>
<p>1、 统一代码库</p>
<p>2、 自动构建工具</p>
<p>3、 自动测试脚本</p>
<p>4、 开发向代码库主干提交代码</p>
<p>5、 自动触发构建工具</p>
<p>6、 高速构建服务器、快速完成构建作业</p>
<p>7、 上传软件到测试环境触发自动测试脚本</p>
<p>8、 执行结果分析与展示</p>
<p>9、 自动部署到演练环境</p>
<p><img src="/2020/09/21/DevOps-%E7%90%86%E8%A7%A3%E6%95%B4%E7%90%86/uploads/image/20170922/1506070830595640.png" alt="image.png" title="1506070830595640.png"></p>
<p>                                                                                                  持续集成流程</p>
<h2 id="持续交付"><a href="#持续交付" class="headerlink" title="持续交付"></a>持续交付</h2><p>持续交付是指周期性地将新版本软件交给质量运营团队或者用户，测试与评审。如果代码通过评审，代码进入生产阶段，持续交付的核心是不管有多少更新，软件始终可以交付价值</p>
<p>1、 快速发布产品特性：缩短编码、测试、上线、交付的迭代周期，使每个步骤出现的问题得到快速响应，在产品上的体现就是缩短软件功能发布周期，从而可以更好的应对业务需求的变化</p>
<p>2、 高质量的软件发布标准：软件交付过程实现标准化，整个交付过程可重复，过程进度可视化</p>
<p>3、 提供团队协作效率</p>
<p><img src="/2020/09/21/DevOps-%E7%90%86%E8%A7%A3%E6%95%B4%E7%90%86/uploads/image/20170922/1506070853309847.png" alt="image.png" title="1506070853309847.png"></p>
<p>                                                                                               持续交付流程</p>
<h2 id="灰度发布"><a href="#灰度发布" class="headerlink" title="灰度发布"></a>灰度发布</h2><p>1、负载均衡</p>
<p>2、升级回滚</p>
<p>灰度发布本质是选取部分用户或者区域发布产品新特性。A/B测试安一定的策略选定一部分用户继续用A，而另一部分用户开始用B，产品可以通过使用B的用户反馈决策是否扩大发布范围，最终达到产品新特性向所有用户全量发布</p>
<h2 id="应用编排"><a href="#应用编排" class="headerlink" title="应用编排"></a>应用编排</h2><p>应用通常有多个组件或者模块，基于Kubernetes 部署应用</p>
<h2 id="DevOps流水线"><a href="#DevOps流水线" class="headerlink" title="DevOps流水线"></a>DevOps流水线</h2><p> <img src="/2020/09/21/DevOps-%E7%90%86%E8%A7%A3%E6%95%B4%E7%90%86/1506070880431917.png" alt="avatar"><br>  <img src="/2020/09/21/DevOps-%E7%90%86%E8%A7%A3%E6%95%B4%E7%90%86/1506070894349245.png" alt="avatar"></p>
<h2 id="DevOps与Kubernetes"><a href="#DevOps与Kubernetes" class="headerlink" title="DevOps与Kubernetes"></a>DevOps与Kubernetes</h2><h3 id="Kubernetes对DevOps的影响"><a href="#Kubernetes对DevOps的影响" class="headerlink" title="Kubernetes对DevOps的影响"></a>Kubernetes对DevOps的影响</h3><p>DevOps并不是一个新概念，前期是没有好的工具来辅助DevOps的发展，虚拟机、IAAS管理不能解决应用管理的多样化需求。</p>
<p>应用管理的需求：</p>
<p>1、 应用运行环境、应用版本功能的不确定性，导致运维需要适配不同的运行环境，定制多种应用编译部署脚本，容器的出现解决了这个问题</p>
<p>2、 基于容器的应用不断增多，产生了对容器集群管理的需求—Kubernetes</p>
<p>3、应用升级回滚对容器集群管理的需求—Kubernetes</p>
<p>  4、应用的生命周期管理可以完全由Kubernetes管理，用户将更多精力放到代码开发</p>
<h3 id="持续集成工具Jenkis与Kubernetes"><a href="#持续集成工具Jenkis与Kubernetes" class="headerlink" title="持续集成工具Jenkis与Kubernetes"></a>持续集成工具Jenkis与Kubernetes</h3><p> Jenkins与Kubernetes结合：基于Kubernetes部署Jenkins Master。在Jenkins Master 安装Kubernetes Plugin，并下载Jenkins Slave 镜像。Jenkins的任务通过Jenkins Plugin 转化为Kubernetes Pod 模板，Kubernetes 根据Pod 模板自动拉起Slave容器，Slave容器会自动加入Jenkins 集群。Jenkins 执行任务时，自动调度Job到某个Slave容器，任务结束后，Jenkins自动删除相关街道，并销毁对应容器，实现资源释放。</p>
]]></content>
  </entry>
  <entry>
    <title>GPU 相关的基础知识</title>
    <url>/2020/10/10/GPU-%E7%9B%B8%E5%85%B3%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[<p>整理了认为了解GPU，比较重要的几个概念<br>###CPU与GPU的区别<br>CPU需要很强的通用性来处理各种不同的数据类型，还需要进行多种逻辑判断，引入大量的分支跳转和中断处理。GPU面对的则是类型高度统一的、相互无依赖的大规模数据和不需要被打断的纯净的计算环境，如<br>下图所示（绿色的是计算单元，橙红色的是存储单元，橙黄色的是控制单元），与CPU擅长逻辑控制、串行的运算、通用类型数据运算不同，GPU擅长的是大规模并发计算，GPU的工作部分计算量大，但没有什么技术含量,<br>而且需要重复很多次。CPU与GPU相比就类似 教授和小学生，教授积分微分都会算，小学生只会算加减乘除。唯一的限制是，运行在GPU的计算任务可以拆分为多个相同的简单小任务，而且是相互独立的。现在的GPU也能做一些<br>稍微复制的工作，相当于升级成初中生高中生的水平，但是还需要CPU配合才可以，终究还是需要靠GPU来管理。</p>
<p> GPU上适合运行计算密集型的程序和易于并行的程序</p>
<p><img src="/2020/10/10/GPU-%E7%9B%B8%E5%85%B3%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/cpugpu.jpg" alt="avatar"></p>
<p>###SP SM Thread Block grid warp<br>SP(streaming processor):最基本的处理单元，最终的指令和任务都是在SP上执行，GPU的并行计算，即多个SP同时做处理，一个SP 对应一个thread<br>warp：SM调度和执行的基础概念，同时也是一个硬件概念，一个SM中的SP会分成几个warp（SM中的SP进行分组）<br>SM（streaming multiprocessor）:多个SP加上一些其他资源组成SM，其他资源包括存储资源、共享内存、寄存器</p>
<p>###GPU Memory</p>
<p>###GPU P2P</p>
<p>###RDMA</p>
<p>###CUDA</p>
<p>###NVLINK</p>
<p>###NCCL</p>
]]></content>
  </entry>
  <entry>
    <title>Etcd的db文件很大</title>
    <url>/2020/09/21/Etcd%E7%9A%84db%E6%96%87%E4%BB%B6%E5%BE%88%E5%A4%A7/</url>
    <content><![CDATA[<p>     Etcd运行一段时间后，发现db占用的空间很大，将etcd内的数据导出，发现只有180多k,为什么会占用这么多空间呢？</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node3 snap]# pwd</span><br><span class="line">&#x2F;var&#x2F;lib&#x2F;etcd&#x2F;member&#x2F;snap</span><br><span class="line">[root@node3 snap]# ll -lh</span><br><span class="line">total 509M</span><br><span class="line">-rw-r--r-- 1 root root 390K Jun 14 12:31 000000000001a198-0000000001357eb0.snap</span><br><span class="line">-rw-r--r-- 1 root root 390K Jun 14 13:11 000000000001a198-000000000135a5c3.snap</span><br><span class="line">-rw-r--r-- 1 root root 390K Jun 14 13:52 000000000001a198-000000000135ccd5.snap</span><br><span class="line">-rw-r--r-- 1 root root 390K Jun 14 14:29 000000000001a198-000000000135f3e6.snap</span><br><span class="line">-rw-r--r-- 1 root root 391K Jun 14 14:50 000000000001a19a-0000000001361af7.snap</span><br><span class="line">-rw------- 1 root root 523M Jun 14 15:05 db</span><br></pre></td></tr></table></figure>

<p>    看一下一下etcd官方的说明</p>
<p>          since etcd keeps an exact history of its keyspace, this history should be periodically compacted to avoid performance degradation and eventual storage space exhaustion。</p>
<p>意思就是etcd保存了keys的历史信息，所以会占用的空间比较大，需要周期的进行压缩，以避免出现性能下降和存储资源耗尽，继续看官方说明</p>
<p>         After compacting the keyspace, the backend database may exhibit internal fragmentation. Any internal fragmentation is space that is free to use by the backend but still consumes storage space. The process of defragmentation releases this storage space back to the file system. Defragmentation is issued on a per-member so that cluster-wide latency spikes may be avoided</p>
<p>     大概的意思是定期压缩etcd 的db后，虽然释放了一些空间，但是只能被etcd使用，并不能被宿主机使用，根据上面的解释，如果不是etcd突然释放大量keys或者etcd需求大量磁盘的场景下，只需要执行compact就可以了，执行defrag是对硬盘的一些操作而已。</p>
<p>     解决方法：</p>
<p>etcd的启动参数增加ETCD_AUTO_COMPACTION_RETENTION=1，如果需要释放硬盘空间，可以执行defrag命令，如下所示：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node2 snap]# etcdctl --endpoints http:&#x2F;&#x2F;10.110.17.119:2379  defrag</span><br><span class="line">Finished defragmenting etcd member\[http:&#x2F;&#x2F;10.110.17.119:2379\]</span><br><span class="line">[root@node2 snap]# ll -lh</span><br><span class="line">total 3.0M</span><br><span class="line">-rw-r--r-- 1 root root 390K Jun 14 13:08 000000000001a198-000000000135a24e.snap</span><br><span class="line">-rw-r--r-- 1 root root 390K Jun 14 13:48 000000000001a198-000000000135c961.snap</span><br><span class="line">-rw-r--r-- 1 root root 390K Jun 14 14:27 000000000001a198-000000000135f072.snap</span><br><span class="line">-rw-r--r-- 1 root root 390K Jun 14 14:48 000000000001a19a-0000000001361783.snap</span><br><span class="line">-rw-r--r-- 1 root root 390K Jun 14 15:09 000000000001a19b-0000000001363e96.snap</span><br><span class="line">-rw------- 1 root root  18M Jun 14 15:20 db</span><br></pre></td></tr></table></figure>

<p>附：</p>
<p>Etcd默认的db 配额是2GB，etcd主要用于存储元数据，这个一般就够用了。</p>
]]></content>
  </entry>
  <entry>
    <title>docker基础镜像debain的乱码问题</title>
    <url>/2020/09/04/Docker%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8Fdebain%E7%9A%84%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>问题</p>
<p>公司内的项目在进行容器化并实现DevOps的时候，由于代码文件编码的问题，出现了乱码问题，在windows环境下，正常没有问题，首先看一下前期基于debain+nodejs+ionic构建的用于项目打包的基础镜像，镜像文件如下所示：</p>
<p>FROM 10.10.70.65/base/andreptb/maven:3.3.9-jdk8<br>COPY settings.xml /usr/share/maven/conf/settings.xml<br>COPY linux-x64-57_binding.node /usr/local/<br>ENV SASS_BINARY_PATH=/usr/local/linux-x64-48_binding.node<br>COPY  node-v8.6.0-linux-x64.tar.gz /home/node-v8.6.0-linux-x64.tar.gz<br>WORKDIR /home/<br>RUN tar xvf node-v8.6.0-linux-x64.tar.gz <br>    &amp;&amp; mv node-v8.6.0-linux-x64/ /usr/local/<br>RUN echo ‘’ &gt; /etc/apt/sources.list.d/jessie-backports.list <br>  &amp;&amp; echo “deb <a href="http://mirrors.aliyun.com/debian" target="_blank" rel="noopener">http://mirrors.aliyun.com/debian</a> jessie main contrib non-free” &gt; /etc/apt/sources.list <br>  &amp;&amp; echo “deb <a href="http://mirrors.aliyun.com/debian" target="_blank" rel="noopener">http://mirrors.aliyun.com/debian</a> jessie-updates main contrib non-free” &gt;&gt; /etc/apt/sources.list <br>  &amp;&amp; echo “deb <a href="http://mirrors.aliyun.com/debian-security" target="_blank" rel="noopener">http://mirrors.aliyun.com/debian-security</a> jessie/updates main contrib non-free” &gt;&gt; /etc/apt/sources.list</p>
<p>RUN apt-get update &amp;&amp; apt-get install -y libltdl7<br>RUN  export PATH=/usr/local/node-v8.6.0-linux-x64/bin:$PATH <br>   &amp;&amp; npm config set registry <a href="https://registry.npm.taobao.org/" target="_blank" rel="noopener">https://registry.npm.taobao.org</a> <br>   &amp;&amp; npm install -g @angular/cli <br>   &amp;&amp; npm install uglify-js -g <br>   &amp;&amp; npm install -g cordova <br>   &amp;&amp; npm install -g ionic<br>ENV PATH=/usr/local/node-v8.6.0-linux-x64/bin:$PATH<br>基于上述镜像，制作的war包，对于中文，会出现乱码问题，如下所示</p>
<pre><code>&lt;display-name&gt;????????????????????????&lt;/display-name&gt;
&lt;context-param&gt;
    &lt;param-name&gt;webAppRootKey&lt;/param-name&gt;
    &lt;param-value&gt;dfweb.root&lt;/param-value&gt;
&lt;/context-param&gt;</code></pre>
<p>尝试在pom.xml上增加以下配置，并未解决问题，但是这应该是必须的配置<br>&lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;<br>在windows环境和centos 环境下进行了mvn package，都未出现乱码问题，最终怀疑是基础镜像的语言环境问题，查看Centos7的语言环境如下所示：<br>[root@RD65 ~]# locale<br>LANG=en_US.UTF-8<br>LC_CTYPE=”en_US.UTF-8”<br>LC_NUMERIC=”en_US.UTF-8”<br>LC_TIME=”en_US.UTF-8”<br>LC_COLLATE=”en_US.UTF-8”<br>LC_MONETARY=”en_US.UTF-8”<br>LC_MESSAGES=”en_US.UTF-8”<br>LC_PAPER=”en_US.UTF-8”<br>LC_NAME=”en_US.UTF-8”<br>LC_ADDRESS=”en_US.UTF-8”<br>LC_TELEPHONE=”en_US.UTF-8”<br>LC_MEASUREMENT=”en_US.UTF-8”<br>LC_IDENTIFICATION=”en_US.UTF-8”<br>LC_ALL=<br>查看基础镜像的语言环境如下所示：</p>
<p>root@82f9c92e247c:/home# locale<br>LANG=<br>LANGUAGE=<br>LC_CTYPE=”POSIX”<br>LC_NUMERIC=”POSIX”<br>LC_TIME=”POSIX”<br>LC_COLLATE=”POSIX”<br>LC_MONETARY=”POSIX”<br>LC_MESSAGES=”POSIX”<br>LC_PAPER=”POSIX”<br>LC_NAME=”POSIX”<br>LC_ADDRESS=”POSIX”<br>LC_TELEPHONE=”POSIX”<br>LC_MEASUREMENT=”POSIX”<br>LC_IDENTIFICATION=”POSIX”<br>LC_ALL=</p>
<p>解决方法</p>
<p>修改基础镜像的dockerfile</p>
<p>FROM 10.10.70.65/base/andreptb/maven:3.3.9-jdk8<br>COPY settings.xml /usr/share/maven/conf/settings.xml<br>COPY linux-x64-57_binding.node /usr/local/<br>ENV SASS_BINARY_PATH=/usr/local/linux-x64-48_binding.node<br>COPY  node-v8.6.0-linux-x64.tar.gz /home/node-v8.6.0-linux-x64.tar.gz<br>WORKDIR /home/<br>RUN tar xvf node-v8.6.0-linux-x64.tar.gz <br>    &amp;&amp; mv node-v8.6.0-linux-x64/ /usr/local/<br>RUN echo ‘’ &gt; /etc/apt/sources.list.d/jessie-backports.list <br>  &amp;&amp; echo “deb <a href="http://mirrors.aliyun.com/debian" target="_blank" rel="noopener">http://mirrors.aliyun.com/debian</a> jessie main contrib non-free” &gt; /etc/apt/sources.list <br>  &amp;&amp; echo “deb <a href="http://mirrors.aliyun.com/debian" target="_blank" rel="noopener">http://mirrors.aliyun.com/debian</a> jessie-updates main contrib non-free” &gt;&gt; /etc/apt/sources.list <br>  &amp;&amp; echo “deb <a href="http://mirrors.aliyun.com/debian-security" target="_blank" rel="noopener">http://mirrors.aliyun.com/debian-security</a> jessie/updates main contrib non-free” &gt;&gt; /etc/apt/sources.list</p>
<p>RUN apt-get update &amp;&amp; apt-get install -y libltdl7<br>RUN  export PATH=/usr/local/node-v8.6.0-linux-x64/bin:$PATH <br>   &amp;&amp; npm config set registry <a href="https://registry.npm.taobao.org/" target="_blank" rel="noopener">https://registry.npm.taobao.org</a> <br>   &amp;&amp; npm install -g @angular/cli <br>   &amp;&amp; npm install uglify-js -g <br>   &amp;&amp; npm install -g cordova <br>   &amp;&amp; npm install -g ionic<br>ENV PATH=/usr/local/node-v8.6.0-linux-x64/bin:$PATH</p>
<p>#config locale<br>RUN sed -i -e ‘s/# en_US.UTF-8 UTF-8/en_US.UTF-8 UTF-8/‘ /etc/locale.gen &amp;&amp; <br>    locale-gen<br>ENV LANGUAGE=en_US.UTF-8<br>ENV LANG=en_US.UTF-8<br>ENV LC_ALL=en_US.UTF-8</p>
]]></content>
  </entry>
  <entry>
    <title>Kubernetes 详解-Replica Sets 和Service</title>
    <url>/2020/09/21/Kubernetes-%E8%AF%A6%E8%A7%A3-Replica-Sets-%E5%92%8CService/</url>
    <content><![CDATA[<h2 id="1-1-Replica-Sets"><a href="#1-1-Replica-Sets" class="headerlink" title="1.1 Replica Sets"></a>1.1 Replica Sets</h2><p>下一代的Replication Controller，两者的区别主要在选择器selector,Replica 支持集合级别的选择器，而前期的Replication Controller，支持在等号描述的选择器，kubectl命令支持使用replica sets （目前kubectl命令中的rolling-update 还不支持），目前replica sets主要用于deployment中</p>
<p>Replica Sets 能够确保在某个时间点上，一定数量的Pod在运行。然而Deployment 是Replica Sets更高一层的抽象，用于更新Pods 以及其他一些特性。推荐使用Deployment而不是直接使用Replica Set进行编排Pods。</p>
<h2 id="1-2-Service"><a href="#1-2-Service" class="headerlink" title="1.2 Service"></a>1.2 Service</h2><p>由于Pod的IP会变化，提供某些功能的POD如果IP发生变化，会导致其他Pod无法发现这些功能，因此 引入了Service的功能。</p>
<p>Service是一组逻辑Pod的抽象，定义了一个访问这些Pod的策略（或者叫做微服务），这些Service 通常通过Label Selector指向这些Pod。</p>
<p>举个例子：一个提供镜像处理的后端有三个运行的副本，这些副本是可以取代的，但是前端并不需要感知，这时就需要Service作为抽象</p>
<p>对于可以部署在K8s内部应用，K8s通过Endpoints Api更新Service对应的Pod集合，对于那些没K8s外部的应用，K8s提供了虚拟IP桥接到Service，然后Service重定向到Pod集合。</p>
<h3 id="1-2-1-Service-定义"><a href="#1-2-1-Service-定义" class="headerlink" title="1.2.1 Service 定义"></a>1.2.1 Service 定义</h3><p><strong>{</strong></p>
<p> <strong>“kind”**</strong>:**  <strong>“Service”**</strong>,**</p>
<p> <strong>“apiVersion”**</strong>:**  <strong>“v1”**</strong>,**</p>
<p> <strong>“metadata”**</strong>:**  <strong>{</strong></p>
<p> <strong>“name”**</strong>:**  <strong>“my-service”</strong></p>
<p> <strong>},</strong></p>
<p> <strong>“spec”**</strong>:**  <strong>{</strong></p>
<p> <strong>“selector”**</strong>:**  <strong>{</strong></p>
<p> <strong>“app”**</strong>:**  <strong>“MyApp”</strong></p>
<p> <strong>},</strong></p>
<p> <strong>“ports”**</strong>:**  <strong>[</strong></p>
<p> <strong>{</strong></p>
<p> <strong>“protocol”**</strong>:**  <strong>“TCP”**</strong>,**</p>
<p> <strong>“port”**</strong>:**  <strong>80**</strong>,**</p>
<p> <strong>“targetPort”**</strong>:**  <strong>9376</strong></p>
<p> <strong>}</strong></p>
<p> <strong>]</strong></p>
<p> <strong>}</strong></p>
<p><strong>}</strong></p>
<p>该Service 对应的Pod集合：带有label app=Myapp，对外暴露端口9376</p>
<p>Service 能将任意的流入Port 重定向到targetPort,默认情况下，targetPort和Port为相同值，不同的Pod 可以对应不同的端口号（例如，在你应用的下一个版本中会使用不同的端口号，但是并不应用之前版本的使用）</p>
<p>Service 支持UDP和TCP，默认是TCP</p>
<h3 id="1-2-2-Service-without-selector"><a href="#1-2-2-Service-without-selector" class="headerlink" title="1.2.2 Service without selector"></a>1.2.2 Service without selector</h3><p>Service可以抽象访问Pod集群，同时 Service也可以抽象其他后端</p>
<p>1、 在生产环境中使用外部数据库，在测试环境中使用自己的数据库</p>
<p>2、 将自己的Service指向其他集群或者其他命名空间的Service</p>
<p>3、 迁移应用到k8s，但是还是有些应用运行在k8s之外</p>
<p>通过定义不包含selector的Service实现</p>
<p><strong>{</strong></p>
<p> <strong>“kind”**</strong>:**  <strong>“Service”**</strong>,**</p>
<p> <strong>“apiVersion”**</strong>:**  <strong>“v1”**</strong>,**</p>
<p> <strong>“metadata”**</strong>:**  <strong>{</strong></p>
<p> <strong>“name”**</strong>:**  <strong>“my-service”</strong></p>
<p> <strong>},</strong></p>
<p> <strong>“spec”**</strong>:**  <strong>{</strong></p>
<p> <strong>“ports”**</strong>:**  <strong>[</strong></p>
<p> <strong>{</strong></p>
<p> <strong>“protocol”**</strong>:**  <strong>“TCP”**</strong>,**</p>
<p> <strong>“port”**</strong>:**  <strong>80**</strong>,**</p>
<p> <strong>“targetPort”**</strong>:**  <strong>9376</strong></p>
<p> <strong>}</strong></p>
<p><strong>]</strong></p>
<p> <strong>}</strong></p>
<p><strong>}</strong></p>
<p>Service 没有Selector，K8s不会创建Endpoints，你可以通过手动创建Endpoint指向自己的endpoint</p>
<p><strong>{</strong></p>
<p> <strong>“kind”**</strong>:**  <strong>“Endpoints”**</strong>,**</p>
<p> <strong>“apiVersion”**</strong>:**  <strong>“v1”**</strong>,**</p>
<p> <strong>“metadata”**</strong>:**  <strong>{</strong></p>
<p> <strong>“name”**</strong>:**  <strong>“my-service”</strong></p>
<p> <strong>},</strong></p>
<p> <strong>“subsets”**</strong>:**  <strong>[</strong></p>
<p> <strong>{</strong></p>
<p> <strong>“addresses”**</strong>:**  <strong>[</strong></p>
<p> <strong>{</strong>  <strong>“ip”**</strong>:**  <strong>“1.2.3.4”</strong>  <strong>}</strong></p>
<p> <strong>],</strong></p>
<p> <strong>“ports”**</strong>:**  <strong>[</strong></p>
<p> <strong>{</strong>  <strong>“port”**</strong>:**  <strong>9376</strong>  <strong>}</strong></p>
<p> <strong>]</strong></p>
<p> <strong>}</strong></p>
<p> <strong>]</strong></p>
<p><strong>}</strong></p>
<p>Endpoint的IP不能是loopback（127.0.0.1/8），link-local（169.254.0.0/16）, link-local multicast (224.0.0.0/24).</p>
<p>访问不含有selector的Service和访问含有Selector的Service 方式一样，都会讲流向重定向的endpoint</p>
<p> 其他命名空间的服务是一个特例，他不会定义ports和endpoint，他只是返回一个访问外部服务的别名</p>
<p><strong>{</strong></p>
<p> <strong>“kind”**</strong>:**  <strong>“Service”**</strong>,**</p>
<p> <strong>“apiVersion”**</strong>:**  <strong>“v1”**</strong>,**</p>
<p> <strong>“metadata”**</strong>:**  <strong>{</strong></p>
<p> <strong>“name”**</strong>:**  <strong>“my-service”**</strong>,**</p>
<p> <strong>“namespace”**</strong>:**  <strong>“prod”</strong></p>
<p> <strong>},</strong></p>
<p> <strong>“spec”**</strong>:**  <strong>{</strong></p>
<p> <strong>“type”**</strong>:**  <strong>“ExternalName”**</strong>,**</p>
<p> <strong>“externalName”**</strong>:**  <strong>“my.database.example.com”</strong></p>
<p> <strong>}</strong></p>
<p><strong>}</strong></p>
<p>当你访问服务<strong>my-service.prod.svc.CLUSTER**</strong>时，**<strong>cluster**</strong>的**<strong>dns**</strong>服务会返回记录**<strong>my.database.example.com</strong> <strong>的**</strong>CNAME**<strong>，这个重定向是发生在**</strong>dns**<strong>解析阶段。</strong></p>
<h3 id="1-2-3-虚拟IP-和服务代理"><a href="#1-2-3-虚拟IP-和服务代理" class="headerlink" title="1.2.3 虚拟IP 和服务代理"></a>1.2.3 虚拟IP 和服务代理</h3><h4 id="1-2-3-1-代理"><a href="#1-2-3-1-代理" class="headerlink" title="1.2.3.1 代理"></a>1.2.3.1 代理</h4><p>K8s集群内每个节点都会运行kube-proxy，负责实现服务的虚拟机IP（不是externalName）。1.0版本的代理模式在是userspace，1.1增加了iptables proxy，从1.2开始 iptables 代理是默认的模式</p>
<p>K8s 1.0的service是四层（TCP/UDP），从k8s1.1开始，增加了Ingress，实现七层（HTTP）服务</p>
<p><strong>用户空间的代理模式</strong></p>
<p>Kube-proxy监控k8s master节点来发现Service、Endpointd的增加和删除，对于Service，在本地打开一个随机端口作为代理端口，任何访问改代理端口的连接都会被指向Service对象的Pod集合，最终指向哪个Pod取决于Service的SessionAffinity，最后，他会配置iptables，捕获流向Service 的Cluster IP 和Port的连接，并重定向到这个代理端口。</p>
<p>最终结果，任何到Service Cluster Ip 和port的流量都会指向合适的Pod</p>
<p>默认情况下，都是轮训算法选择后端，也可以通过设置service.spec.sessionAffinity 为ClientIP，将选择算法改为Client-IP based session affinity</p>
<p><strong>Iptables**</strong>的代理模式**</p>
<p>该模式与userspace模式类似，只是没有这个代理端口</p>
<p>比userspace方式更快更可靠，然后与userspace方式不同，当选择的pod异常时，该方式无法自动尝试选择其他Pod。</p>
<p>1、userspace模式只不适合大规模集群使用（数千个服务）</p>
<p>2、userspace模式隐藏了访问服务的源IP，iptables模式虽然没有隐藏源IP，但是也是通过负载均衡或者nodeport 影响了客户端输入</p>
]]></content>
      <tags>
        <tag>云计算</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes详解--Pod</title>
    <url>/2020/09/21/Kubernetes%E8%AF%A6%E8%A7%A3-Pod/</url>
    <content><![CDATA[<h3 id="（题外话：之前研究了好多开源软件，但是每当研究开源软件的时候，感觉了解的都不是很透彻，这次尝试研究官方文档，看看效果如何，下面的资料，是按照官方文档翻译的，比较笨，但是了解更深入了，希望能坚持下来-）"><a href="#（题外话：之前研究了好多开源软件，但是每当研究开源软件的时候，感觉了解的都不是很透彻，这次尝试研究官方文档，看看效果如何，下面的资料，是按照官方文档翻译的，比较笨，但是了解更深入了，希望能坚持下来-）" class="headerlink" title="（题外话：之前研究了好多开源软件，但是每当研究开源软件的时候，感觉了解的都不是很透彻，这次尝试研究官方文档，看看效果如何，下面的资料，是按照官方文档翻译的，比较笨，但是了解更深入了，希望能坚持下来**）**"></a><strong>（题外话：之前研究了好多开源软件，但是每当研究开源软件的时候，感觉了解的都不是很透彻，这次尝试研究官方文档，看看效果如何，下面的资料，是按照官方文档翻译的，比较笨，但是了解更深入了，希望能坚持下来**</strong>）**</h3><h3 id="1-1-1-POD"><a href="#1-1-1-POD" class="headerlink" title="1.1.1 POD"></a>1.1.1 POD</h3><p>一组容器（一个或者多个Container），共享存储，以相同的方式运行、Pods的容器位于同一节点，被一起调度，同时部署，启动、重启、删除，伸缩，运行在相同的Context。POD的模型对应 应用专属的逻辑主机，他包含一个或多个相对紧耦合的应用容器。PS：在使用容器之前，这些应用可能需要部署在相同的物理机或者虚拟机。</p>
<p>POD内Container共享的上下文包括：Linux Namespace、cgroups等（docker相关的隔离策略），在POD的上下文中，每个应用可能会有深层次的隔离</p>
<p>POD内的容器共享一个IP和PORT空间，容器可以通过localhost 互相发现，容器也可以通过标准的内部进程进行交互（System V semaphores 或者Posix 共享内存），不同POD内的容器具有不同的IP，无法通过IPC进行交互</p>
<p> POD内的容器可以访问共享卷，可以被挂载到每个应用的文件系统。</p>
<p>当POD所在节点挂掉后，该POD不会被重新调度到其他节点，而是一个新的POD在其他节点创建，uuid不同（将来版本，可能会提供迁移POD的功能），与POD同生命周期的概念，具体是指和该uuid pod的生命周期相同。</p>
<h3 id="1-1-2-POD-产生原因"><a href="#1-1-2-POD-产生原因" class="headerlink" title="1.1.2 POD 产生原因"></a>1.1.2 POD 产生原因</h3><p>l  管理，POD的模型可以理解为：由多个可以组成一个服务的协作进程的集合。这种模式提供了比Container更高一层的抽象，从而简化了部署和管理。POD作为部署、水平伸缩，副本的执行单元。POD内的Container统一调度、拥有一样的生命周期、一致的副本，资源共享、统一的依赖管理</p>
<p>l  资源共享和通信：POD资源Containers的资源共享和通信。POD中的Container的host name 和POD的name相同</p>
<p>POD虽然也可以部署一组垂直的容器，例如LAMP，但是POD的主要目的是用于以下程序:</p>
<p>1、 content management systems, file and data loaders, local cache managers, etc.</p>
<p>2、 log and checkpoint backup, compression, rotation, snapshotting, etc.</p>
<p>3、 data change watchers, log tailers, logging and monitoring adapters, event publishers, etc.</p>
<p>4、 proxies, bridges, and adapters</p>
<p>5、 controllers, managers, configurators, and updaters</p>
<h3 id="1-1-3-POD-删除"><a href="#1-1-3-POD-删除" class="headerlink" title="1.1.3 POD 删除"></a>1.1.3 POD 删除</h3><p>POD 代表一组运行的进程，所以应该能够优雅的终止这些进程（让这些进程能够执行一些数据清理，而不是直接kill），用户应能够请求删除POD，并指导什么时候该POD会被删除，并且能够确保POD内的进程最终被删除。当用户请求删除POD时，系统会记录可以允许该POD多久进行自我删除，超过该时间，TERM信号就会发送到POD内的全部容器。当POD正在删除过程中，Kubelete或者容器被重启，终止进程将会重新开始删除Pod（with full grace period）</p>
<p>一个删除流程的例子：</p>
<p>1．用户请求删除POD，默认的 grace period 是30s</p>
<p>2．API server更新该POD应该被删除的时间</p>
<p>3．当查询POD时，显示该POD “Terminating”</p>
<p>4．与第三步同步，当Kubelet发现Pod被标记为Terminating，kubelet开始关闭进程。</p>
<p>5．若Pod定义了 preStop hook，那么该hook会被激活，若该hook的运行时间超过了grace period，会再次执行第二步，grace period会变为30s+2s</p>
<p>6．发送TERM 信号到Pod内的进程</p>
<p>7．与第三步同时，POD将会从Service 的endpoint列表移除，但是关闭比较慢的POD 仍然可以进行服务访问（前提是svc没有被删除）</p>
<p>8．当grace period后，POD内仍然运行的进程都会收到SIGKILL信号</p>
<p>9．Kubelet在API server中设置grace period 为0 代表已经删除完成</p>
<p>默认情况下，POD会在30s内被删除，但是可以命令行设置该事件 通过 –grace-period=<seconds> ,0表示立即删除POD（这样该POD的名称可以尽快重复使用，但是该POD仍然会有一段比较小的grace period）</seconds></p>
<h3 id="1-1-4-Pod-的Privileged-模式"><a href="#1-1-4-Pod-的Privileged-模式" class="headerlink" title="1.1.4 Pod 的Privileged 模式"></a>1.1.4 Pod 的Privileged 模式</h3><p>K8s 1.1 版本以后，可以为Pod中的Container设置privileged模式，通过设置<strong>SecurityContext</strong> <strong>参数</strong></p>
]]></content>
      <tags>
        <tag>docker</tag>
        <tag>云计算</tag>
        <tag>Kubernetes</tag>
        <tag>Pod</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的tempfs</title>
    <url>/2020/12/01/Linux%E7%9A%84tempfs/</url>
    <content><![CDATA[<p>###tempfs简介</p>
<ol>
<li><p>tmpfs 是 Linux/Unix 系统上的一种基于内存的文件系统，即 tmpfs 使用内存或 swap 分区来存储文件。Linux 内核中的 VM 子系统负责在后台管理虚拟内存资源 Virtual Memory，即 RAM 和 swap 资源，透明地将 RAM 页移动到交换分区或从交换分区到 RAM 页，tmpfs 文件系统需要 VM 子系统的页面来存储文件。tmpfs 自己并不知道这些页面是在交换分区还是在 RAM 中；做这种决定是 VM 子系统的工作。tmpfs 文件系统所知道的就是它正在使用某种形式的虚拟内存。</p>
</li>
<li><p>由于 tmpfs 是基于内存的，因此速度是相当快的。另外 tmpfs 使用的 VM 资源是动态的，当删除 tmpfs 中文件，tmpfs 文件系统驱动程序会动态地减小文件系统并释放 VM 资源，当然在其中创建文件时也会动态的分配VM资源。另外，tmpfs 不具备持久性，重启后数据不保留。</p>
</li>
</ol>
<p>在Linux主机上，查看常用tempfs的目录如下所示</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node2 ~]# df -h</span><br><span class="line">Filesystem                  Size  Used Avail Use% Mounted on</span><br><span class="line">&#x2F;dev&#x2F;mapper&#x2F;centos-root     442G   78G  364G  18% &#x2F;</span><br><span class="line">devtmpfs                     94G     0   94G   0% &#x2F;dev</span><br><span class="line">tmpfs                        94G     0   94G   0% &#x2F;dev&#x2F;shm</span><br><span class="line">tmpfs                        94G  1.2G   93G   2% &#x2F;run</span><br><span class="line">tmpfs                        94G     0   94G   0% &#x2F;sys&#x2F;fs&#x2F;cgroup</span><br></pre></td></tr></table></figure>
<p>1.其中/run 目录主要存放的是自系统启动以来描述系统信息的文件。比较常见的用途是 daemon 进程将自己的 pid 保存到这个目录。</p>
<p>2./dev/shm/ 是 Linux 下一个非常有用的目录，它的意思是 Shared memory，也就是共享内存。由于它在内存上，所以所有系统进程都能共享该目录。默认情况下它的大小是内存的一半</p>
]]></content>
  </entry>
  <entry>
    <title>Kubernetes 详解--简介</title>
    <url>/2020/09/21/Kubernetes-%E8%AF%A6%E8%A7%A3-%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<p>K8s 开源平台：跨集群主机的自动化部署、伸缩、应用管理，提供以容器为中心的基础设施。</p>
<p>1、迅速部署应用或者定时部署</p>
<p>2、伸缩应用</p>
<p>3、无缝升级回滚应用</p>
<p>4、最大化利用硬件资源（每个应用只分配它所需要的资源）</p>
<p>容器相对于虚拟机的优势：</p>
<p>1、应用的敏捷创建和部署：得益于容器镜像的轻量级</p>
<p>2、持续的部署、集成、部署：提供可靠搞笑的容器镜像制作和部署，易于回滚(基于镜像部署时，镜像并不会改变)</p>
<p>3、Dev和ops 分离：在编译发布阶段创建容器镜像，而不是在部署阶段。能够将应用的运行和基础设施分离</p>
<p>4、开发、测试、生产三种场景，可以在笔记本也可以在公有云</p>
<p>5、不感知操作系统：Centos、Ubuntu，各种容器引擎，都可以。</p>
<p>6、以应用为中心的管理：不感知底层资源（基于虚拟机还是物理机）</p>
<p>7、松散，分布式、弹性、无约束的微服务</p>
<p>8、资源隔离：应用性能可以预测</p>
<p>9、资源利用率：高效率和密集度的资源利用</p>
<p>Kubernets可以将运行在物理或者虚拟机集群，可以将应用从主机架构的基础设施迁移到以容器为中心的基础设施。Kubernets 主要是构建以容器为中心的基础设施。Kubernets满足了将应用运行到生产环境的大部分需求：</p>
<p>1、容器级别的进程协作:组合复杂应用，同时保留 一个应用一个容器的模型，参考Kubernets POD的概念</p>
<p>2、挂载存储</p>
<p>3、密钥管理</p>
<p>4、应用健康检查</p>
<p>5、水平弹性伸缩</p>
<p>6、命名和服务发现</p>
<p>7、负载均衡</p>
<p>8、滚动升级</p>
<p>9、资源监控</p>
<p>10、日志收集</p>
<p>11、<a href="http://kubernetes.io/docs/user-guide/introspection-and-debugging/" target="_blank" rel="noopener">support for introspection and debugging</a></p>
<p>12、认证和权限控制</p>
<p>l  Kubernets 不是一个传统的，全部包含的Paas。K8s不限制运行在k8s的应用运行环境，不区分应用和服务这两个概念。K8s目标是能够支持极端多样的负载，包含无状态、有状态、数据处理流。如果一个应用能够运行在Container，那么它就能够运行在K8s</p>
<p>l  K8s不提供中间件服务，消息中间件，数据处理框架、数据库，不提供集群存储并不会内置到K8s，但是这些服务可以运行到K8s</p>
<p>l  K8s 不提供一键部署的Service Market</p>
<p>l  K8s 不会部署源码，不会build 应用。CI因人而已</p>
<p>l  K8s 允许用户选择日志，监控，告警</p>
<p>l  K8s 没有提供，也没有强制一个综合的应用管理系统</p>
<p>l  K8s 没有提供也没有采用任何复杂的集群配置、维护、管理、自愈系统</p>
<p>K8s主要进行应用级别的管理，提供一些通用的应用管理特性：部署、扩容、负载均衡、日志、监控。然而k8s并不是单一的整理，这些默认的解决方案都是可选，可插拔的</p>
]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes 中的port、nodePort、targetPort</title>
    <url>/2020/09/21/Kubernetes-%E4%B8%AD%E7%9A%84port%E3%80%81nodePort%E3%80%81targetPort/</url>
    <content><![CDATA[<p>Kubernetes 在定义Service的时候有几个Port需要澄清一下，例如下面的Service定义  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1  </span><br><span class="line">kind: Service  </span><br><span class="line">metadata:  </span><br><span class="line">  labels:  </span><br><span class="line">    name: app1  </span><br><span class="line">  name: app1  </span><br><span class="line">  namespace: default  </span><br><span class="line">spec:  </span><br><span class="line">  type: NodePort  </span><br><span class="line">  ports:  </span><br><span class="line">  - port: 8080  </span><br><span class="line">    targetPort: 8080  </span><br><span class="line">    nodePort: 30062&lt;&#x2F;strong&gt;  </span><br><span class="line">  selector:  </span><br><span class="line">    name: app1</span><br></pre></td></tr></table></figure>

<p>参考官方的解释  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Port：</span><br><span class="line">The port that the service is exposed on the service’s cluster ip (virsual ip). Port is the service port which is accessed by others with cluster ip.</span><br></pre></td></tr></table></figure>

<p>  Port是在Service IP中使用的，使用Service IP +Port就可以访问到服务</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TargetPort：</span><br><span class="line">The port on the pod that the service should proxy traffic to.</span><br></pre></td></tr></table></figure>

<p>  TargetPort 说的是Pod内的应用暴露的服务端口，Service IP+Port的访问会被代理到这个Target Port  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NodePort：</span><br><span class="line">On top of having a cluster-internal IP, expose the service on a port on each node of the cluster (the same port on each node). You&#39;ll be able to contact the service on any</span><br><span class="line"></span><br><span class="line">&lt;nodeIP&gt;:nodePort</span><br><span class="line">address. So nodePort is alse the service port which can be accessed by the node ip by others with external ip.</span><br></pre></td></tr></table></figure>

<p>NodePort是Kubernetes集群提供给外部客户端访问Service 使用的端口，一般是主机IP+NodePort 就可以访问到该服务</p>
]]></content>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenJdk移除sun.image.codec package</title>
    <url>/2020/09/04/OpenJdk%E7%A7%BB%E9%99%A4sun-image-codec-package/</url>
    <content><![CDATA[<p>问题描述</p>
<p>一个项目在windows下执行mvn package正常，但是放在Linux环境下，会出现找不到com.sun.image.codec的问题，如下所示</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[ERROR] COMPILATION ERROR : </span><br><span class="line">[INFO] -------------------------------------------------------------</span><br><span class="line">[ERROR] /home/ztzx/ztzx.service/src/main/java/com/telchina/ztzx/common/controller/UploadController2.java:[<span class="number">24</span>,<span class="number">40</span>] package com.sun.image.codec.jpeg does <span class="keyword">not</span> exist</span><br><span class="line">[ERROR] /home/ztzx/ztzx.service/src/main/java/com/telchina/ztzx/common/controller/UploadController2.java:[<span class="number">25</span>,<span class="number">40</span>] package com.sun.image.codec.jpeg does <span class="keyword">not</span> exist</span><br><span class="line">[ERROR] /home/ztzx/ztzx.service/src/main/java/com/telchina/ztzx/common/controller/UploadController.java:[<span class="number">25</span>,<span class="number">32</span>] package com.sun.image.codec.jpeg does <span class="keyword">not</span> exist</span><br><span class="line">[ERROR] /home/ztzx/ztzx.service/src/main/java/com/telchina/ztzx/common/controller/UploadController.java:[<span class="number">26</span>,<span class="number">32</span>] package com.sun.image.codec.jpeg does <span class="keyword">not</span> exist</span><br><span class="line">[INFO] <span class="number">4</span> errors </span><br><span class="line">[INFO] -------------------------------------------------------------</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Reactor Summary:</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] ztzx <span class="number">1.0</span><span class="number">.0</span> ......................................... SUCCESS [  <span class="number">0.007</span> s]</span><br><span class="line">[INFO] ztzx.service ....................................... FAILURE [<span class="number">02</span>:<span class="number">11</span> min]</span><br><span class="line">[INFO] ztzx.web <span class="number">1.0</span><span class="number">.0</span> ..................................... SKIPPED</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD FAILURE</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: <span class="number">02</span>:<span class="number">11</span> min</span><br><span class="line">[INFO] Finished at: <span class="number">2018</span><span class="number">-08</span><span class="number">-06</span>T01:<span class="number">51</span>:<span class="number">45</span>Z</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:<span class="number">3.1</span>:compile (default-compile) on project ztzx.service: Compilation failure: Compilation failure: </span><br><span class="line">[ERROR] /home/ztzx/ztzx.service/src/main/java/com/telchina/ztzx/common/controller/UploadController2.java:[<span class="number">24</span>,<span class="number">40</span>] package com.sun.image.codec.jpeg does <span class="keyword">not</span> exist</span><br><span class="line">[ERROR] /home/ztzx/ztzx.service/src/main/java/com/telchina/ztzx/common/controller/UploadController2.java:[<span class="number">25</span>,<span class="number">40</span>] package com.sun.image.codec.jpeg does <span class="keyword">not</span> exist</span><br><span class="line">[ERROR] /home/ztzx/ztzx.service/src/main/java/com/telchina/ztzx/common/controller/UploadController.java:[<span class="number">25</span>,<span class="number">32</span>] package com.sun.image.codec.jpeg does <span class="keyword">not</span> exist</span><br><span class="line">[ERROR] /home/ztzx/ztzx.service/src/main/java/com/telchina/ztzx/common/controller/UploadController.java:[<span class="number">26</span>,<span class="number">32</span>] package com.sun.image.codec.jpeg does <span class="keyword">not</span> exist</span><br><span class="line">[ERROR] -&gt; [Help 1]</span><br><span class="line">[ERROR] </span><br><span class="line">[ERROR] To see the full stack trace of the errors, re-run Maven <span class="keyword">with</span> the -e switch.</span><br><span class="line">[ERROR] Re-run Maven using the -X switch to enable full debug logging.</span><br><span class="line">[ERROR] </span><br><span class="line">[ERROR] For more information about the errors <span class="keyword">and</span> possible solutions, please read the following articles:</span><br><span class="line">[ERROR] [Help <span class="number">1</span>] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException</span><br><span class="line">[ERROR] </span><br><span class="line">[ERROR] After correcting the problems, you can resume the build <span class="keyword">with</span> the command</span><br><span class="line">[ERROR]   mvn &lt;goals&gt; -rf :ztzx.service</span><br></pre></td></tr></table></figure>
<p>分析一</p>
<p>按照Java官方的解释,sun.image.codec这个package已经被deprecated，建议不要使用，看官方的解释：</p>
<p>Why Developers Should Not Write Programs That Call ‘sun’ Packages<br>The java., javax. and org.* packages documented in the Java Platform Standard Edition API Specification make up the official, supported, public interface. If a Java program directly calls only API in these packages, it will operate on all Java-compatible platforms, regardless of the underlying OS platform.</p>
<p>The sun.* packages are not part of the supported, public interface. A Java program that directly calls into sun.* packages is not guaranteed to work on all Java-compatible platforms. In fact, such a program is not guaranteed to work even in future versions on the same platform. Each company that implements the Java platform will do so in their own private way. The classes in sun.* are present in the JDK to support Oracle’s implementation of the Java platform: the sun.* classes are what make the Java platform classes work “under the covers” for Oracle’s JDK. These classes will not in general be present on another vendor’s Java platform. If your Java program asks for a class “sun.package.Foo” by name, it may fail with ClassNotFoundError, and you will have lost a major advantage of developing in Java.</p>
<p>Technically, nothing prevents your program from calling into sun.* by name. From one release to another, these classes may be removed, or they may be moved from one package to another, and it’s fairly likely that their interface (method names and signatures) will change. (From Oracle’s point of view, since we are committed to maintaining the Java platform, we need to be able to change sun.* to refine and enhance the platform.) In this case, even if you are willing to run only on Oracle’s implementation, you run the risk of a new version of the implementation breaking your program.</p>
<p>In general, writing java programs that rely on sun.* is risky: those classes are not portable, and are not supported</p>
<p>可以这样理解，Java已经被Oracle收购多年，里面再去出现sun的package算怎么回事。。O(∩_∩)O哈哈~，当然你还是可以去使用的，可以在pom.xml 经配置了下面的参数，排除无法引入jar包的问题，这个方法并不能解决我在Linux无法进行构建的的问题。</p>
<pre><code>            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.1&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;source&gt;${jdkVersion}&lt;/source&gt;
                    &lt;target&gt;${jdkVersion}&lt;/target&gt;
                    &lt;compilerArguments&gt;
                        &lt;verbose /&gt;
                        &lt;bootclasspath&gt;${JAVA_HOME}/jre/lib/rt.jar${path.separator}${JAVA_HOME}/jre/lib/jce.jar&lt;/bootclasspath&gt;
                    &lt;/compilerArguments&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;</code></pre>
<p>分析二</p>
<p>查看mvn仓库信息</p>
<p>root@30e8e1cd5962:/home/ztzx# mvn -version<br>Apache Maven 3.5.3 (3383c37e1f9e9b3bc3df5050c29c8aff9f295297; 2018-02-24T19:49:05Z)<br>Maven home: /usr/share/maven<br>Java version: 1.8.0_91, vendor: Oracle Corporation<br>Java home: /usr/lib/jvm/java-8-openjdk-amd64/jre<br>Default locale: en, platform encoding: UTF-8<br>OS name: “linux”, version: “3.10.0-693.el7.x86_64”, arch: “amd64”, family: “unix”<br>查看Java 信息</p>
<p>root@30e8e1cd5962:/home/ztzx# java -version<br>openjdk version “1.8.0_91”<br>OpenJDK Runtime Environment (build 1.8.0_91-8u91-b14-1~bpo8+1-b14)<br>OpenJDK 64-Bit Server VM (build 25.91-b14, mixed mode)</p>
<p>与windows的运行环境相比，出Java的小版本不同外，还有一个区别，就是Oracle Java与OpenJdk的区别，google资料，发现OpenJdk已经在1.7版本移除了该package。OpenJdk移除jepg的package，将Linux 默认的OpenJdk替换为Oracle的Jdk，即可以解决问题</p>
<p>其他解决方法</p>
<p>JPEGImageEncoder类是SUN公司私有类</p>
<p>一般出现在这样的代码段中：<br>    FileOutputStream out = new FileOutputStream(dstName);<br>     JPEGImageEncoder encoder = JPEGCodec.createJPEGEncoder(out);<br>     encoder.encode(dstImage);</p>
<p>改写成：</p>
<pre><code>String formatName = dstName.substring(dstName.lastIndexOf(&quot;.&quot;) + 1);
 //FileOutputStream out = new FileOutputStream(dstName);
 //JPEGImageEncoder encoder = JPEGCodec.createJPEGEncoder(out);
 //encoder.encode(dstImage);
 ImageIO.write(dstImage, /*&quot;GIF&quot;*/ formatName /* format desired */ , new File(dstName) /* target */ );</code></pre>
<p>都使用统一的ImageIO进行图像格式文件的读写，没有必要使用过时的实现类JPEGImageEncoder类。</p>
]]></content>
  </entry>
  <entry>
    <title>Nginx代理端口丢失问题</title>
    <url>/2020/09/21/Nginx%E4%BB%A3%E7%90%86%E7%AB%AF%E5%8F%A3%E4%B8%A2%E5%A4%B1%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>     Kubernetes环境中在使用Nginx进行代理，在进行端口代理时，总是出现端口丢失的问题，例如访问</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">  </span><br><span class="line">http:&#x2F;&#x2F;10.10.70.58:32007&#x2F;demo</span><br></pre></td></tr></table></figure>

<p>地址会跳转到 <a href="http://10.10.70.58:32007/demo" target="_blank" rel="noopener"></a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http:&#x2F;&#x2F;10.10.70.58:32007&#x2F;demo</span><br></pre></td></tr></table></figure>

<p>查看代理配置如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">upstream archdemo &#123;</span><br><span class="line">        server 10.10.70.61:32007;</span><br><span class="line">        server 10.10.70.62:32007;</span><br><span class="line">&#125;</span><br><span class="line">server&#123;</span><br><span class="line">    listen 32007;</span><br><span class="line">    location &#x2F; &#123;</span><br><span class="line">        proxy\_pass         http:&#x2F;&#x2F;archdemo; </span><br><span class="line">        server\_name\_in\_redirect off;</span><br><span class="line">        proxy\_set\_header X-Real-IP $remote\_addr;</span><br><span class="line">        proxy\_set\_header REMOTE-HOST $remote\_addr;</span><br><span class="line">        proxy\_set\_header X-Forwarded-For $proxy\_add\_x\_forwarded\_for;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>这里经过“面向搜索引擎的编程“，解决该问题，在进行代理配置是需要使用以下配置  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">upstream archdemo &#123;</span><br><span class="line">        server 10.10.70.61:32007;</span><br><span class="line">        server 10.10.70.62:32007;</span><br><span class="line">&#125;</span><br><span class="line">server&#123;</span><br><span class="line">    listen 32007;</span><br><span class="line">        server\_name\_in\_redirect off;</span><br><span class="line">        proxy\_set\_header Host $host:$server\_port;</span><br><span class="line">        proxy\_set\_header X-Real-IP $remote\_addr;</span><br><span class="line">        proxy\_set\_header REMOTE-HOST $remote\_addr;</span><br><span class="line">        proxy\_set\_header X-Forwarded-For $proxy\_add\_x\_forwarded\_for;</span><br><span class="line">    location &#x2F; &#123;</span><br><span class="line">        proxy\_pass         http:&#x2F;&#x2F;archdemo;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernets 详解--Volume</title>
    <url>/2020/09/21/Kubernets-%E8%AF%A6%E8%A7%A3-Volume/</url>
    <content><![CDATA[<h2 id="1-1-Volume"><a href="#1-1-Volume" class="headerlink" title="1.1 Volume"></a>1.1 Volume</h2><p>容器内的磁盘都是临时的，Volume引入的原因:</p>
<p>1、当一个容器宕机后，kubelet会重启改容器，但是容器内的文件就会丢失</p>
<p>2、一个Pod内的多个容器需要共享数据</p>
<h3 id="1-1-1-背景"><a href="#1-1-1-背景" class="headerlink" title="1.1.1 背景"></a>1.1.1 背景</h3><p>docker中也有Volume的概念docker中的Volume只是简单的一个磁盘目录或者其他Container中的目录，管理比较简单，虽然目前支持了volume driver，但是单个容器只支持使用一个volume driver。</p>
<p>   K8s中的Volume，有着明确的生命周期，与Pod的生命周期相同，Volume独立于Pod内的Container，在Container重启过程中，Volume保持不变。当然，让一个Pod停止退出时，Volume也会停止退出。除此之外，一个POD可以同时使用任意数量的，任意类型的卷。</p>
<p>Pod中的Container必须明确指定卷的挂载点</p>
<h3 id="1-1-2-卷类型"><a href="#1-1-2-卷类型" class="headerlink" title="1.1.2 卷类型"></a>1.1.2 卷类型</h3><h4 id="1-1-2-1-emptyDir"><a href="#1-1-2-1-emptyDir" class="headerlink" title="1.1.2.1 emptyDir"></a>1.1.2.1 emptyDir</h4><p>当使用emptyDir卷的Pod在节点创建时，会在该节点创建一个新的空目录，只要改Pod运行在该节点，该目录会一直存在，Pod内的容器可以将改目录挂载到不同的挂载点，但都可以读写emptyDir内的文件。当Pod不论什么原因被删除，emptyDir的数据都会永远被删除（一个Container Crash 并不会在该节点删除Pod，因此在Container crash时，数据不会丢失）</p>
<p>使用场景</p>
<p>1、 临时空间，例如基于磁盘空间做合并排序</p>
<p>2、 检测一个比较长的计算任务，能够让改计算任务从crash 恢复</p>
<p>3、 保存 内容管理Container 获取的文件，webserver 容器处理这些数据</p>
<p>默认情况下，emptyDir支持任何类型的后端存储：disk、ssd、网络存储。也可以通过设置 emptyDir.medium 为Memory，K8s会默认mount一个tmpfs（RAM-backed filesystem），因为是RAM Backed,因此tmpfs 通常很快。但是会在容器重启或者crash时，数据丢失。</p>
<h4 id="1-1-2-2-hostPath"><a href="#1-1-2-2-hostPath" class="headerlink" title="1.1.2.2 hostPath"></a>1.1.2.2 hostPath</h4><p>挂载Node节点以及存在的文件或者目录，不太常用，一下场景</p>
<p>1、 运行的容器需要访问宿主机的docker 内部信息 例如/var/lib/docker 目录</p>
<p>2、 容器内运行cadvisor，需要访问 /dev/cgroups</p>
<p>使用该类型的卷，需要注意以下几个方面：</p>
<p>1、 使用同一个模板创建的Pod，由于不同的节点有不同的目录信息，可能会导致不同的结果</p>
<p>2、 如果K8s增加了已知资源的调度，该调度不会考虑hostPath使用的资源</p>
<p>3、 如果宿主机目录上已经存在的目录，只可以被root可以写，所以容器需要root权限访问该目录，或者修改目录权限</p>
<h4 id="1-1-2-3-gcePersistentDisk"><a href="#1-1-2-3-gcePersistentDisk" class="headerlink" title="1.1.2.3 gcePersistentDisk"></a>1.1.2.3 gcePersistentDisk</h4><p>GCE提供的存储</p>
<h4 id="1-1-2-4-awsElasticBlockStore"><a href="#1-1-2-4-awsElasticBlockStore" class="headerlink" title="1.1.2.4 awsElasticBlockStore"></a>1.1.2.4 awsElasticBlockStore</h4><p>AWS提供的块存储</p>
<h4 id="1-1-2-5-NFS"><a href="#1-1-2-5-NFS" class="headerlink" title="1.1.2.5 NFS"></a>1.1.2.5 NFS</h4><p>与emptyDir不同，基于NFs的卷，在Pod删除时，卷并不会清除，只是与容器解绑。NFS支持同时读写。</p>
<p>NFS Server 需要单独搭建</p>
<h4 id="1-1-2-6-Iscsi"><a href="#1-1-2-6-Iscsi" class="headerlink" title="1.1.2.6 Iscsi"></a>1.1.2.6 Iscsi</h4><p>iScSi提供卷，在Pod删除时，卷并不会清除，只是与容器解绑</p>
<p>iSCSI Server 必须自己搭建</p>
<p>使用iscsi的一个特性，多个容器挂载卷时，可以指定挂载类型为read-only，但是有个缺点，iscsi卷只能同时被一个Container挂载为读写模式，不支持多个Container同时读写。</p>
<h4 id="1-1-2-7-Flocker"><a href="#1-1-2-7-Flocker" class="headerlink" title="1.1.2.7 Flocker"></a>1.1.2.7 Flocker</h4><p>开源，容器集群 卷管理，支持管理和编排多种存储后端的数据卷</p>
<p>一个flocker volume 允许挂载一个flocker dataset 到一个Pod</p>
<h4 id="1-1-2-8-Glusterfs"><a href="#1-1-2-8-Glusterfs" class="headerlink" title="1.1.2.8 Glusterfs"></a>1.1.2.8 Glusterfs</h4><p>支持多容器同时写</p>
<h4 id="1-1-2-9-RBD"><a href="#1-1-2-9-RBD" class="headerlink" title="1.1.2.9 RBD"></a>1.1.2.9 RBD</h4><p>Rados Block Device voluem 挂载到Pod</p>
<p>Rbd特点：可以被同时挂载为Read-Only。但是只能同时被一个Container 挂载为读写模式</p>
<h4 id="1-1-2-10-Cephfs"><a href="#1-1-2-10-Cephfs" class="headerlink" title="1.1.2.10 Cephfs"></a>1.1.2.10 Cephfs</h4><p>支持多容器同时写</p>
<h4 id="1-1-2-11-Gitrepo"><a href="#1-1-2-11-Gitrepo" class="headerlink" title="1.1.2.11 Gitrepo"></a>1.1.2.11 Gitrepo</h4><p>可以类似一个卷插件，挂载一个空目录，clone git上的仓库到该目录，Pod可以使用该仓库</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">**apiVersion****:** **v1**</span><br><span class="line"></span><br><span class="line">**kind****:** **Pod**</span><br><span class="line"></span><br><span class="line">**metadata****:**</span><br><span class="line"></span><br><span class="line"> **name****:** **server**</span><br><span class="line"></span><br><span class="line">**spec****:**</span><br><span class="line"></span><br><span class="line"> **containers****:**</span><br><span class="line"></span><br><span class="line">**-** **image****:** **nginx**</span><br><span class="line"></span><br><span class="line"> **name****:** **nginx**</span><br><span class="line"></span><br><span class="line"> **volumeMounts****:**</span><br><span class="line"></span><br><span class="line">**-** **mountPath****:** **&#x2F;mypath**</span><br><span class="line"></span><br><span class="line"> **name****:** **git-volume**</span><br><span class="line"></span><br><span class="line"> **volumes****:**</span><br><span class="line"></span><br><span class="line">**-** **name****:** **git-volume**</span><br><span class="line"></span><br><span class="line"> **gitRepo****:**</span><br><span class="line"></span><br><span class="line"> **repository****:** **&quot;git@somewhere:me&#x2F;my-git-repository.git&quot;**</span><br><span class="line"></span><br><span class="line"> **revision****:** **&quot;22f1d8406d464b0c0874075539c1f2e96c253775&quot;**</span><br></pre></td></tr></table></figure>
<h4 id="1-1-2-12-secret"><a href="#1-1-2-12-secret" class="headerlink" title="1.1.2.12 secret"></a>1.1.2.12 secret</h4><p>存放敏感信息的卷，具体可以参考K8s的Secret介绍</p>
<h4 id="1-1-2-13-其他"><a href="#1-1-2-13-其他" class="headerlink" title="1.1.2.13 其他"></a>1.1.2.13 其他</h4><p>PersistentVolumeClain</p>
<p>dowanwardAPI</p>
<p>AzureFileVolume</p>
<p>AzureDiskVolume</p>
<p>vsphereVolume</p>
]]></content>
  </entry>
  <entry>
    <title>Linux执行df和du查看磁盘时占用结果不一致的解决办法</title>
    <url>/2020/09/21/Linux%E6%89%A7%E8%A1%8Cdf%E5%92%8Cdu%E6%9F%A5%E7%9C%8B%E7%A3%81%E7%9B%98%E6%97%B6%E5%8D%A0%E7%94%A8%E7%BB%93%E6%9E%9C%E4%B8%8D%E4%B8%80%E8%87%B4%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</url>
    <content><![CDATA[<p><strong>问题现象</strong> </p>
<p>1、执行 df -h 查看 ECS Linux 实例文件系统使用率，可以看到 /dev/xvdb1 磁盘占用了约27G，挂载目录为 /opt 。</p>
<p><img src="http://p3.pstatp.com/large/pgc-image/1531049590662f3fa303a98" alt="Linux 执行 df 和 du 查看磁盘时占用结果不一致的解决办法"></p>
<p>2、进入到 /opt 目录执行 du -sh ，显示空间总占用量约 2.4 G，即df 和du查看到的结果不一致。</p>
<p><img src="http://p1.pstatp.com/large/pgc-image/1531049590682d3db0a9740" alt="Linux 执行 df 和 du 查看磁盘时占用结果不一致的解决办法"></p>
<p><strong>原因分析</strong></p>
<ul>
<li><p>du 命令对统计文件逐个进行 fstat 系统调用，获取文件大小。它的数据是基于文件获取，可以跨多个分区操作。</p>
</li>
<li><p>df 命令使用 statfs 系统调用，直接读取分区的超级块信息获取分区使用情况。它的数据基于分区元数据，只能针对整个分区。</p>
</li>
<li><p>用户删除了大量的文件后，du 就不会在文件系统目录中统计这些文件。如果此时还有运行中的进程持有这个已经被删除的文件句柄，那么这个文件就不会真正在磁盘中被删除，分区超级块中的信息也就不会更改，df 仍会统计这个被删除的文件。</p>
</li>
<li><p>通过 lsof 查询处于 deleted 状态的文件，被删除的文件在系统中被标记为 deleted 。如果系统有大量 deleted 状态的文件，会导致 du 和 df 统计结果不一致。</p>
</li>
</ul>
<p>##解决方案<br>  1、根据 lsof 列出的 pid，kill 相应进程或者重启相应的服务，如：#kill -9 692。 </p>
<p>  2、重启服务器。重启服务器系统会退出现有的进程，开机后重新加载，过程中会释放调用的 deleted 文件的句柄。</p>
]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes Dashboard开发说明</title>
    <url>/2020/09/21/Kubernetes-Dashboard%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/</url>
    <content><![CDATA[<p>  部门准备做一个Kuberentes的发行版，研究了一下Dashboard这个项目，以及这个项目应该如何开发，把一些总结写下。</p>
<h1 id="Dashboard-源码说明"><a href="#Dashboard-源码说明" class="headerlink" title="Dashboard 源码说明"></a>Dashboard 源码说明</h1><p>    dashboard 项目分为backend和frontend两部分，可以通过执行gulp serve进行调试运行，执行gulp build 进行编译<br> <img src="/2020/09/21/Kubernetes-Dashboard%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/1504234553698022.png" alt="avatar"></p>
<p>       dashboard的backend项目封装了k8s API，heapster API 做了一层封装，包括封装分页查询、界面元数据重新组合等（这里的dashboard backend项目类似一个API 网关，可以集成多个项目的API，提供统一的接口给front项目使用，我们自己就在dashboard的基础上，增加了对tiller的调用）</p>
<p>      dashboard的front项目是基于angular js 实现，（个人对于这块也不是很熟悉，照葫芦画瓢了），封装了不少css，component，还是很好的模仿进行开发的，我在此基础增加了基于Chart创建应用</p>
<p> <img src="/2020/09/21/Kubernetes-Dashboard%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/1504235671108490.png" alt="avatar"><br>###后端代码</p>
<p>   backend项目是一个golang 项目，main函数在dashboard.go 文件，我们开发的时候，主要是在backend/handler/apihandler.go 文件中增加访问路由，以及访问路由的处理函数。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiV1Ws.Route(</span><br><span class="line">   apiV1Ws.GET(&quot;&#x2F;chart&quot;).</span><br><span class="line">      To(apiHandler.handleGetChartList).</span><br><span class="line">      Writes(helm.ChartListWeb&#123;&#125;))</span><br><span class="line">      </span><br><span class="line">&#x2F;&#x2F;get app template list</span><br><span class="line">func (apiHandler \*APIHandler) handleGetChartList(request \*restful.Request, response \*restful.Response) &#123;</span><br><span class="line">   namespace :&#x3D; parseNamespacePathParameter(request)</span><br><span class="line">   dataSelect :&#x3D; parseDataSelectPathParameter(request)</span><br><span class="line">   result, err :&#x3D; chart.GetChartList(namespace,&quot;&quot;, dataSelect)</span><br><span class="line">   if err !&#x3D; nil &#123;</span><br><span class="line">      handleInternalError(response, err)</span><br><span class="line">      return</span><br><span class="line">   &#125;</span><br><span class="line">   response.WriteHeaderAndEntity(http.StatusOK, result)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>    函数的实现思路可以参考dashboard中的查询pod的思路开发，其中做了分页查询，只要熟悉golang，基本没什么难度</p>
<p>###前端代码</p>
<p>此处略。。完全模仿，让以后的js高手写吧。。  </p>
<p>###翻译</p>
<p>dashboard 的翻译比较麻烦，使用的是google的开源项目。我们要增加自己的字段进行翻译的话，不需要手动在i18中的xtb文件中添加字段，只需要执行一下gulp build，在i18n文件夹中会自动添加我们使用到的字段，然后在xtb文件中进行翻译就好了。具体参考官方说明。<a href="https://github.com/kubernetes/dashboard/blob/master/docs/devel/localization.md" target="_blank" rel="noopener">Locaization Guide</a></p>
<p>###DashBoard 扩展架构</p>
<p> 目前我们把dashboard 进行了扩展，包括镜像管理、模板仓库、监控告警、认证授权 ，具体的组件架构如下：<br><img src="/2020/09/21/Kubernetes-Dashboard%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/1517796478876012.png" alt="avatar"></p>
]]></content>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenStack Centos6.5 image 制作</title>
    <url>/2020/09/15/OpenStack-Centos6-5-image-%E5%88%B6%E4%BD%9C/</url>
    <content><![CDATA[<p>查找了很多资料，包括官方文档，几处资料结合起来终于制作好了Centos 6.5 的镜像。但是不能够进行硬盘伸缩，还待优化（但是个人觉得硬盘伸缩的作用不是很大，体验了阿里云、UnitedStack，都是固定了系统盘的大小（linux是20G、windows是40G的系统盘）） </p>
<p>1、使用ubuntu12.04 server 64bits，首先安装kvm</p>
<p>  sudo apt-get install kvm qemu libvirt-bin virtinst virt-manager virt-viewer</p>
<p>2、创建kvm 虚拟机磁盘文件：</p>
<p>     qemu-img create -f qcow2 centos.img 20G    //20G 是该虚拟机的硬盘大小</p>
<p>3、挂载iso，安装centos系统</p>
<p>    kvm -hda centos.img -cdrom /tmp/CentOS-6.5-x86_64-bin-DVD1.iso -m 768 -boot d -vnc :0<br>  使用vnc工具连接，在vnc中完成安装centos的操作。推荐使用TightVNC viewer。安装完成后，关闭虚拟机</p>
<p>4、启动虚拟机，配置网络</p>
<p>   kvm centos.img -m 768 -smp 2 -net nic -net tap,ifname=tap1,script=/etc/qemu-ifup -vnc :0 -daemonize</p>
<p>  登录系统后，eth0网卡未启动，需要设置eth0 开机启动 文件/etc/sysconfig/network-scripts/ifcfg-eth0 设置ONBOOT=“yes”</p>
<p>  重启网络</p>
<p>5、更新操作：</p>
<p>        yum update</p>
<p>       yum upgrade</p>
<p>6、网络配置</p>
<p> 在网络接口配置里面注释或删除这行 #HWADDR= 一行，启用 DHCP：</p>
<blockquote>
<blockquote>
<p># vi /etc/sysconfig/network-scripts/ifcfg-eth0</p>
</blockquote>
<blockquote>
<p>DEVICE=”eth0”</p>
</blockquote>
<blockquote>
<p>#UUID=fe8e2c29-a8d2-4529-accd-a5b4dabb892c</p>
</blockquote>
<blockquote>
<p>#HWADDR=”00:11:22:12:34:56”</p>
</blockquote>
<blockquote>
<p>NM_CONTROLLED=”yes”</p>
</blockquote>
<blockquote>
<p>BOOTPROTO=dhcp</p>
</blockquote>
<blockquote>
<p>ONBOOT=”yes”</p>
</blockquote>
</blockquote>
<p>修改sshd配置</p>
<blockquote>
<blockquote>
<p>sed -i ‘s/PasswordAuthentication no/PasswordAuthentication yes/g’ /etc/ssh/sshd_config </p>
</blockquote>
<blockquote>
<p>sed -i ‘s/#PasswordAuthentication yes /PasswordAuthentication yes /g’ /etc/ssh/sshd_config </p>
</blockquote>
<blockquote>
<p># vi /etc/ssh/sshd_config</p>
</blockquote>
<blockquote>
<p>…</p>
</blockquote>
<blockquote>
<p>PasswordAuthentication yes </p>
</blockquote>
<blockquote>
<p>RSAAuthentication yes</p>
</blockquote>
<blockquote>
<p>PubkeyAuthentication yes</p>
</blockquote>
<blockquote>
<p>ChallengeResponseAuthentication no</p>
</blockquote>
</blockquote>
<p>      service sshd restart</p>
<p>需要关闭 SELINUX </p>
<blockquote>
<blockquote>
<p># vi /etc/selinux/config</p>
</blockquote>
<blockquote>
<p>SELINUX=disabled</p>
</blockquote>
<blockquote>
<p>SELINUXTYPE=targeted</p>
</blockquote>
</blockquote>
<p> 关闭防火墙服务</p>
<blockquote>
<blockquote>
<p>service iptables stop &amp;&amp; chkconfig iptables off</p>
</blockquote>
<blockquote>
<p>service ip6tables stop &amp;&amp; chkconfig ip6tables off</p>
</blockquote>
</blockquote>
<p>清空文件（不是删除）：</p>
<blockquote>
<blockquote>
<p>/etc/udev/rules.d/70-persistent-net.rules</p>
</blockquote>
<blockquote>
<p>/lib/udev/rules.d/75-persistent-net-generator.rules</p>
</blockquote>
</blockquote>
<p> 7、安装cloud-init,cloud-utils, cloud-initramfs-growroot cloud-init</p>
<blockquote>
<p>rpm -ivh <a href="http://ftp-stud.hs-esslingen.de/pub/epel/6/x86/_64/epel-release-6-8.noarch.rpm" target="_blank" rel="noopener">http://ftp-stud.hs-esslingen.de/pub/epel/6/x86\_64/epel-release-6-8.noarch.rpm</a></p>
<p>yum install git parted cloud-utils  cloud-initramfs-growroot cloud-init</p>
</blockquote>
<p> 编辑/etc/cloud/cloud.cfg 文件,开启root 账号登陆：</p>
<blockquote>
<p> disable_root: 1</p>
<p> ssh_pwauth:   1</p>
</blockquote>
<p> 8、修改grub，是系统启动日志能够通过OpenStack控制台输出</p>
<p>   Vi  /boot/grub/grub.conf</p>
<p>   增加 console=ttyS0</p>
<blockquote>
<blockquote>
<p>default=0</p>
</blockquote>
<blockquote>
<p>timeout=5</p>
</blockquote>
<blockquote>
<p>splashimage=(hd0,0)/boot/grub/splash.xpm.gz</p>
</blockquote>
<blockquote>
<p>hiddenmenu</p>
</blockquote>
<blockquote>
<p>title CentOS (2.6.32-279.el6.x86_64)</p>
</blockquote>
<blockquote>
<p>        root (hd0,0)</p>
</blockquote>
<blockquote>
<p>        kernel /boot/vmlinuz-2.6.32-279.el6.x86_64 ro root=UUID=587a6161-e327-48b8-80a2-2fd5da0b3989 rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet console=tty0 console=ttyS0,115200n8</p>
</blockquote>
<blockquote>
<p>        initrd /boot/initramfs-2.6.32-279.el6.x86_64.img</p>
</blockquote>
</blockquote>
<p>现在就可以将centos.img 注册到OpenStack使用了。制作出来有2G，有需要的可以留言给我。</p>
]]></content>
      <tags>
        <tag>OpenStack</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenStack 源码中的OSLO</title>
    <url>/2020/09/15/OpenStack-%E6%BA%90%E7%A0%81%E4%B8%AD%E7%9A%84OSLO/</url>
    <content><![CDATA[<h3 id="Oslo"><a href="#Oslo" class="headerlink" title="Oslo"></a>Oslo</h3><p>在RYU的目录下可以找到cfg.py文件，这个文件中import了oslo的相关模块，以便调用时减少引用数目。从文件中可以发现oslo.config.cfg文件是关键文件，其在系统中的文件位置在：/usr/local/lib/python2.7/dist-packages/oslo/config/cfg.py。想查看源码的读者可以自行查看。在该cfg.py文件中 定义了ConfigOpts类，包含了_opts, _groups等成员变量。该类完成了命令行和配置参数的解析。</p>
<p>如果要快速学习某一个知识，最好的办法就是把它用起来。所以首先我会介绍一个入门的教程。如果你没有看懂，可以去看原始的<a href="http://www.giantflyingsaucer.com/blog/?p=4822" target="_blank" rel="noopener">教程</a>。</p>
<p>首先安装<a href="https://virtualenv.pypa.io/en/latest/virtualenv.html" target="_blank" rel="noopener">python-virtualenv</a>，此python库可以用于创建一个虚拟的，与外界隔离的运行环境，听起来和docker好像有点像。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get install python-virtualenv</span><br><span class="line">virtualenv example-app</span><br><span class="line">cd example-app</span><br><span class="line">source bin&#x2F;activate</span><br><span class="line">pip install oslo.config</span><br><span class="line">touch app.py</span><br><span class="line">touch app.conf</span><br></pre></td></tr></table></figure>



<p>然后修改app.conf。添加了两个group:simple和morestuff。simple组中有一个BoolOpt:enable。morestuff组有StrOpt, ListOpt, DictOpt, IntOpt,和FloatOpt。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[simple]</span><br><span class="line">enable &#x3D; True</span><br><span class="line">[morestuff]</span><br><span class="line"># StrOpt</span><br><span class="line">message &#x3D; Hello World</span><br><span class="line"># ListOpt</span><br><span class="line">usernames &#x3D; [&#39;Licheng&#39;, &#39;Muzixing&#39;, &#39;Distance&#39;]</span><br><span class="line"># DictOpt</span><br><span class="line">jobtitles &#x3D; &#123;&#39;Licheng&#39;: &#39;Manager&#39;, &#39;Muzixing&#39;: &#39;CEO&#39;, &#39;Distance&#39;: &#39;Security Guard&#39;&#125;</span><br><span class="line"># IntOpt</span><br><span class="line">payday &#x3D; 20</span><br><span class="line"># FloatOpt</span><br><span class="line">pi &#x3D; 3.14</span><br></pre></td></tr></table></figure>



<p>修改app.py文件。首先定义两个group，再对两个group的option进行定义。最后使用register_group和register_opts函数来完成group和option的注册。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from __future__ import print_function</span><br><span class="line">from oslo.config import cfg</span><br><span class="line">opt_simple_group &#x3D; cfg.OptGroup(name&#x3D;&#39;simple&#39;,</span><br><span class="line">                         title&#x3D;&#39;A Simple Example&#39;)</span><br><span class="line">opt_morestuff_group &#x3D; cfg.OptGroup(name&#x3D;&#39;morestuff&#39;,</span><br><span class="line">                         title&#x3D;&#39;A More Complex Example&#39;)</span><br><span class="line">simple_opts &#x3D; [</span><br><span class="line">    cfg.BoolOpt(&#39;enable&#39;, default&#x3D;False,</span><br><span class="line">                help&#x3D;(&#39;True enables, False disables&#39;))</span><br><span class="line">]</span><br><span class="line">morestuff_opts &#x3D; [</span><br><span class="line">    cfg.StrOpt(&#39;message&#39;, default&#x3D;&#39;No data&#39;,</span><br><span class="line">               help&#x3D;(&#39;A message&#39;)),</span><br><span class="line">    cfg.ListOpt(&#39;usernames&#39;, default&#x3D;None,</span><br><span class="line">                help&#x3D;(&#39;A list of usernames&#39;)),</span><br><span class="line">    cfg.DictOpt(&#39;jobtitles&#39;, default&#x3D;None,</span><br><span class="line">                help&#x3D;(&#39;A dictionary of usernames and job titles&#39;)),</span><br><span class="line">    cfg.IntOpt(&#39;payday&#39;, default&#x3D;30,</span><br><span class="line">                help&#x3D;(&#39;Default payday monthly date&#39;)),</span><br><span class="line">    cfg.FloatOpt(&#39;pi&#39;, default&#x3D;0.0,</span><br><span class="line">                help&#x3D;(&#39;The value of Pi&#39;))</span><br><span class="line">]</span><br><span class="line">CONF &#x3D; cfg.CONF</span><br><span class="line">CONF.register_group(opt_simple_group)</span><br><span class="line">CONF.register_opts(simple_opts, opt_simple_group)</span><br><span class="line">CONF.register_group(opt_morestuff_group)</span><br><span class="line">CONF.register_opts(morestuff_opts, opt_morestuff\_group)</span><br><span class="line">if __name__ &#x3D;&#x3D; &quot;__main__&quot;:</span><br><span class="line">    CONF(default_config_files&#x3D;[&#39;app.conf&#39;])</span><br><span class="line">    print(&#39;(simple) enable: &#123;&#125;&#39;.format(CONF.simple.enable))</span><br><span class="line">    print(&#39;(morestuff) message :&#123;&#125;&#39;.format(CONF.morestuff.message))</span><br><span class="line">    print(&#39;(morestuff) usernames: &#123;&#125;&#39;.format(CONF.morestuff.usernames))</span><br><span class="line">    print(&#39;(morestuff) jobtitles: &#123;&#125;&#39;.format(CONF.morestuff.jobtitles))</span><br><span class="line">    print(&#39;(morestuff) payday: &#123;&#125;&#39;.format(CONF.morestuff.payday))</span><br><span class="line">    print(&#39;(morestuff) pi: &#123;&#125;&#39;.format(CONF.morestuff.pi))</span><br></pre></td></tr></table></figure>




<p>完成之后，运行app.py文件。可以查看到相关输出。</p>
<p>回到RYU中，之前一篇<a href="http://www.muzixing.com/pages/2014/12/10/ryuxue-xi-eventlet.html" target="_blank" rel="noopener">博客</a>介绍了RYU的main函数。在ryu/ryu/cmd/manager.py文件中我们可以看到如下的代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CONF.register_cli_opts([</span><br><span class="line">    cfg.ListOpt(&#39;app-lists&#39;, default&#x3D;[],</span><br><span class="line">                help&#x3D;&#39;application module name to run&#39;),</span><br><span class="line">    cfg.MultiStrOpt(&#39;app&#39;, positional&#x3D;True, default&#x3D;[],</span><br><span class="line">                    help&#x3D;&#39;application module name to run&#39;),</span><br><span class="line">    cfg.StrOpt(&#39;pid-file&#39;, default&#x3D;None, help&#x3D;&#39;pid file name&#39;),</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">以上的注册了三个Option，其中的app-lists和app参数是运行ryu-manager时的参数，即APP的名称。在以下的main函数中，我们可以看到首先获取了输入的参数，若参数为空，则默认开启ofp\_handler应用。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def main(args&#x3D;None, prog&#x3D;None):</span><br><span class="line">    try:</span><br><span class="line">        CONF(args&#x3D;args, prog&#x3D;prog,</span><br><span class="line">             project&#x3D;&#39;ryu&#39;, version&#x3D;&#39;ryu-manager %s&#39; % version,</span><br><span class="line">             default_config_files&#x3D;[&#39;&#x2F;usr&#x2F;local&#x2F;etc&#x2F;ryu&#x2F;ryu.conf&#39;])</span><br><span class="line">    except cfg.ConfigFilesNotFoundError:</span><br><span class="line">        CONF(args&#x3D;args, prog&#x3D;prog,</span><br><span class="line">             project&#x3D;&#39;ryu&#39;, version&#x3D;&#39;ryu-manager %s&#39; % version)</span><br><span class="line"></span><br><span class="line">    log.init_log()</span><br><span class="line"></span><br><span class="line">    if CONF.pid_file:</span><br><span class="line">        import os</span><br><span class="line">        with open(CONF.pid_file, &#39;w&#39;) as pid\_file:</span><br><span class="line">            pid_file.write(str(os.getpid()))</span><br><span class="line"></span><br><span class="line">    app_lists &#x3D; CONF.app_lists + CONF.app</span><br><span class="line">    # keep old behaivor, run ofp if no application is specified.</span><br><span class="line">    if not app_lists:</span><br><span class="line">        app_lists &#x3D; [&#39;ryu.controller.ofp_handler&#39;]</span><br></pre></td></tr></table></figure>



<p>oslo模块使用能够使得整个工程的不同模块可以使用同一个配置文件，从而减少了命令冲突的可能，此外，oslo提供的模板，可以让命令解析更方便。在oslo.config之外，还有oslo.db,oslo.messaging等。</p>
<p>  针对OpenStack 多个组件，OpenStack社区开发了不少公共组件OSOL：<a href="https://github.com/openstack/?query=oslo" target="_blank" rel="noopener">https://github.com/openstack/?query=oslo</a></p>
]]></content>
      <tags>
        <tag>OpenStack</tag>
      </tags>
  </entry>
  <entry>
    <title>[OpenStack]glance url被截断问题定位解决</title>
    <url>/2020/09/15/OpenStack-glance-url%E8%A2%AB%E6%88%AA%E6%96%AD%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D%E8%A7%A3%E5%86%B3/</url>
    <content><![CDATA[<p>环境信息：两个控制节点做HA，2个计算节点问题描述：<br>    dashboard界面创建VM时，总是创建失败。查看nova日志，是下载镜像失败导致。<br>1、  命令行执行下载镜像命令<br>       glance –debug image-download 33830a96-d8a7-47fc-a732-271fde266d40 &gt; a.img <br>出现错误日志。发现第二次请求的url为空<br>2、查看glance日志 报错的代码位置<br>  /glance/api/middleware/version_negotiation.py<br><img src="http://bbs.iop365.com/iop/data/attachment/forum/201504/20/100426sn8aff8j2rnwcam2.png">   </p>
<p>非常奇怪，之前从未遇到过该现象<br>2.1 怀疑glance配置错误，与其他环境的glance配置文件对比后，发现没有错误<br>2.2 glance存储可以上传镜像，排查ceph问题<br>在其他机器上验证，发现偶尔能够成功，大部分时间都是失败的。在主控制节点一直成功，怀疑网卡网络问题<br>。。。。。。  </p>
<p>最终发现是keepalived导致的，主节点备节点IP分别是10.68.25.40  10。68.25.41，浮动IP地址为10.68.25.50<br>在两个控制节点发现都存在10.68.25.50这个浮动IP（正常情况，只能在一个节点有该IP），初步判定是keepalived配置问题，但是对比其他环境，配置一样。。。。。最终发现 我们在配置外部网络的时候配置在了eth0，在eth0创建了<br>一个br-ex网桥，静态IP配置到了br-ex，导致eth0上是没有IP的，这就不太正常了。所以修改 keepalived配置文件监听的端口为br-ex  问题解决。</p>
]]></content>
      <tags>
        <tag>OpenStack</tag>
      </tags>
  </entry>
  <entry>
    <title>Restore iSCSI configuration for Cinder/Nova</title>
    <url>/2020/09/15/Restore-iSCSI-configuration-for-Cinder-Nova/</url>
    <content><![CDATA[<h3 id="Restore-iSCSI-configuration-for-Cinder-Nova"><a href="#Restore-iSCSI-configuration-for-Cinder-Nova" class="headerlink" title="Restore iSCSI configuration for Cinder / Nova"></a>Restore iSCSI configuration for Cinder / Nova</h3><p>In few cases (i.e. cinder-volume crash), some cinder volumes cannot be accessed by a VM (I/O errors), but are still displayed as associated when using cinder or nova CLI. Looking at the hypervisor’s log, you may see:<br>May 11 13:26:45 cloudhyp1 iscsid: conn 0 login rejected: target error (03/01)<br>May 11 13:26:45 cloudhyp1 iscsid: conn 0 login rejected: initiator failed authorization with target<br>May 11 13:26:45 cloudhyp1 iscsid: conn 0 login rejected: initiator failed authorization with target<br>On the cinder-volume host, check the configuration of iSCSI target:  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\[root@controller?~\]\# targetcli ls  </span><br><span class="line">o- &#x2F; ......................................................................................................................... [...]  </span><br><span class="line">? o- backstores .............................................................................................................. [...]  </span><br><span class="line">? | o- block .................................................................................................. [Storage Objects: 1]  </span><br><span class="line">? | | o- iqn.2010-10.org.openstack:volume-6e95e5b6-83e1-4958-a5e1-ba5afc94559e? \[&#x2F;dev&#x2F;cinder-volumes&#x2F;volume-6e95e5b6-83e1-4958-a5e1-ba5afc94559e (20.0GiB) write-thru activated]  </span><br><span class="line">? | o- fileio ................................................................................................. [Storage Objects: 0]  </span><br><span class="line">? | o- pscsi .................................................................................................. [Storage Objects: 0]  </span><br><span class="line">? | o- ramdisk ................................................................................................ [Storage Objects: 0]  </span><br><span class="line">? o- iscsi ............................................................................................................ [Targets: 7]  </span><br><span class="line">? | o- iqn.2010-10.org.openstack:volume-6e95e5b6-83e1-4958-a5e1-ba5afc94559e ............................................. [TPGs: 1]  </span><br><span class="line">? | | o- tpg1 .......................................................................................... [no-gen-acls, auth per-acl]  </span><br><span class="line">? | |?? o- acls .......................................................................................................... [ACLs: 0]  </span><br><span class="line">? | |?? o- luns .......................................................................................................... [LUNs: 1]  </span><br><span class="line">? | |?? | o- lun0? [block&#x2F;iqn.2010-10.org.openstack:volume-6e95e5b6-83e1-4958-a5e1-ba5afc94559e (&#x2F;dev&#x2F;cinder-volumes&#x2F;volume-6e95e5b6-83e1-4958-a5e1-ba5afc94559e)\]  </span><br><span class="line">? | |?? o- portals .................................................................................................... [Portals: 1]  </span><br><span class="line">? | |???? o- 192.168.1.1:3260 ................................................................................................. [OK]  </span><br><span class="line">? o- loopback ......................................................................................................... [Targets: 0]</span><br></pre></td></tr></table></figure>
<p>In that case, the cloudhyp1 cannot connect to the target because no ACL are defined ([ACLs: 0])  </p>
<p>?You have to setup the ACL manually:  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@controller?~]# mysql -u cinder -p -e &quot;select provider_auth from volumes where id&#x3D;&#39;6e95e5b6-83e1-4958-a5e1-ba5afc94559e&#39;&quot; cinder  </span><br><span class="line">Enter password:?  </span><br><span class="line">+------------------------------------------------+  </span><br><span class="line">| provider_auth????????????????????????????????? |  </span><br><span class="line">+------------------------------------------------+  </span><br><span class="line">| CHAP xjrFIwOQ66ktkxjrFIwO?vr2twXxoDww7wvr2twXx |  </span><br><span class="line">+------------------------------------------------+  </span><br><span class="line">The first entry is the username and the second the password. You can check that you have the same value on the hypervisor (1, 2):  </span><br><span class="line">[root@cloudhyp1 ~]# grep node.session.auth &#x2F;var&#x2F;lib&#x2F;iscsi&#x2F;nodes&#x2F;iqn.2010-10.org.openstack:volume-6e95e5b6-83e1-4958-a5e1-ba5afc94559e&#x2F;192.168.1.1,3260,1&#x2F;default?  </span><br><span class="line">node.session.auth.authmethod &#x3D; CHAP  </span><br><span class="line">node.session.auth.username &#x3D;?xjrFIwOQ66ktkxjrFIwO  </span><br><span class="line">node.session.auth.password &#x3D;?vr2twXxoDww7wvr2twXx  </span><br><span class="line">On the hypervisor, you need also to get the initiator id (3):  </span><br><span class="line">[root@cloudhyp1 ~]# cat &#x2F;etc&#x2F;iscsi&#x2F;initiatorname.iscsi  </span><br><span class="line">InitiatorName&#x3D;iqn.1994-05.com.redhat:1abc12d345e6  </span><br><span class="line">  </span><br><span class="line">To update the ACL, first save the targetcli configuration:  </span><br><span class="line">[root@controller?~]# targetctl save  </span><br><span class="line">[root@controller?~]# cp &#x2F;etc&#x2F;target&#x2F;saveconfig.json &#x2F;etc&#x2F;target&#x2F;saveconfig.old  </span><br><span class="line">  </span><br><span class="line">Replace:  </span><br><span class="line">????????? &quot;node_acls&quot;: []?  </span><br><span class="line">  </span><br><span class="line">By for the right volume (iqn.2010-10.org.openstack:volume-6e95e5b6-83e1-4958-a5e1-ba5afc94559e?in our case) :  </span><br><span class="line">????????? &quot;node_acls&quot;: [  </span><br><span class="line">??????????? &#123;  </span><br><span class="line">????????????? &quot;attributes&quot;: &#123;  </span><br><span class="line">??????????????? &quot;dataout_timeout&quot;: 3,?  </span><br><span class="line">??????????????? &quot;dataout_timeout_retries&quot;: 5,?  </span><br><span class="line">??????????????? &quot;default_erl&quot;: 0,?  </span><br><span class="line">??????????????? &quot;nopin_response_timeout&quot;: 30,?  </span><br><span class="line">??????????????? &quot;nopin_timeout&quot;: 15,?  </span><br><span class="line">??????????????? &quot;random_datain_pdu_offsets&quot;: 0,?  </span><br><span class="line">??????????????? &quot;random_datain_seq_offsets&quot;: 0,?  </span><br><span class="line">??????????????? &quot;random_r2t_offsets&quot;: 0  </span><br><span class="line">????????????? &#125;,?  </span><br><span class="line">????????????? &quot;chap_password&quot;: &quot;vr2twXxoDww7wvr2twXx&quot;,?  </span><br><span class="line">????????????? &quot;chap_userid&quot;: &quot;xjrFIwOQ66ktkxjrFIwO&quot;,?  </span><br><span class="line">????????????? &quot;mapped_luns&quot;: [  </span><br><span class="line">??????????????? &#123;  </span><br><span class="line">????????????????? &quot;index&quot;: 0,?  </span><br><span class="line">????????????????? &quot;tpg_lun&quot;: 0,?  </span><br><span class="line">????????????????? &quot;write_protect&quot;: false  </span><br><span class="line">??????????????? &#125;  </span><br><span class="line">????????????? ],?  </span><br><span class="line">????????????? &quot;node_wwn&quot;: &quot;iqn.1994-05.com.redhat:1abc12d345e6&quot;  </span><br><span class="line">??????????? &#125;?  </span><br><span class="line">????????? ]?</span><br></pre></td></tr></table></figure>
<p>You have to replace?<em>chap_userid_,?_chap_password</em>?and?_node_wwn_?by values obtained in steps?<strong>1</strong>,?<strong>2</strong>and?<strong>3</strong>?respectively.<br>Then check and load the configuration:  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@controller ~]# cat &#x2F;etc&#x2F;target&#x2F;saveconfig.json | json_verify  </span><br><span class="line">JSON is valid  </span><br><span class="line">[root@controller ~]# targetctl restore  </span><br><span class="line">You can connect again to the iSCSI target from the hypervisor:  </span><br><span class="line">[root@cloudhyp1 ~]# iscsiadm -m node -T iqn.2010-10.org.openstack:volume-6e95e5b6-83e1-4958-a5e1-ba5afc94559e -l</span><br></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title>Tensorflow中的placeholder和feed_dict</title>
    <url>/2020/09/15/Tensorflow%E4%B8%AD%E7%9A%84placeholder%E5%92%8Cfeed-dict/</url>
    <content><![CDATA[<p>TensorFlow 支持占位符placeholder。占位符并没有初始值，它只会分配必要的内存。在会话中，占位符可以使用 feed_dict 馈送数据。 feed_dict是一个字典，在字典中需要给出每一个用到的占位符的取值。 在训练神经网络时需要每次提供一个批量的训练样本，如果每次迭代选取的数据要通过常量表示，那么TensorFlow 的计算图会非常大。因为每增加一个常量，TensorFlow 都会在计算图中增加一个结点。所以说拥有几百万次迭代的神经网络会拥有极其庞大的计算图，而占位符却可以解决这一点，它只会拥有占位符这一个结点。 placeholder函数的定义为 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tf.placeholder(dtype, shape&#x3D;None, name&#x3D;None)&#96;</span><br></pre></td></tr></table></figure>
<p>参数：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dtype：数据类型。常用的是tf.int32，tf.float32，tf.float64，tf.string等数据类型。 </span><br><span class="line">shape：数据形状。默认是None，也就是一维值。 也可以表示多维，比如要表示2行3列则应设为[2, 3]。 形如[None, 3]表示列是3，行不定。 </span><br><span class="line">name：名称。 返回：Tensor类型&#96;</span><br></pre></td></tr></table></figure>
<p> ##例1<br> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import tensorflow as tf </span><br><span class="line">x &#x3D; tf.placeholder(tf.string) </span><br><span class="line">with tf.Session() as sess: </span><br><span class="line">  output &#x3D; sess.run(x, feed_dict&#x3D;&#123;x: &#39;Hello World&#39;&#125;) </span><br><span class="line">  print(output)</span><br><span class="line">  &#96;</span><br></pre></td></tr></table></figure><br> 运行结果：<br>    <code>Hello World</code><br>##例2 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import tensorflow as tf </span><br><span class="line">x &#x3D; tf.placeholder(tf.string) </span><br><span class="line">y &#x3D; tf.placeholder(tf.int32) </span><br><span class="line">z &#x3D; tf.placeholder(tf.float32) </span><br><span class="line">with tf.Session() as sess: </span><br><span class="line">  output &#x3D; sess.run(x, feed_dict &#x3D; &#123;x :&#39;Hello World&#39;, y:123, z:45.67&#125;) </span><br><span class="line">  print(output) </span><br><span class="line">  output &#x3D; sess.run(y, feed_dict &#x3D; &#123;x :&#39;Hello World&#39;, y:123, z:45.67&#125;) </span><br><span class="line">  print(output) </span><br><span class="line">  output &#x3D; sess.run(z, feed_dict &#x3D; &#123;x :&#39;Hello World&#39;, y:123, z:45.67&#125;) </span><br><span class="line">  print(output) </span><br><span class="line">&#96;&#96;&#96;&#96;  </span><br><span class="line"> 运行结果：</span><br></pre></td></tr></table></figure>
<p>  Hello Word 123 45.66999816894531`<br>  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">##例3：</span><br></pre></td></tr></table></figure><br> import tensorflow as tf<br> import numpy as np<br> x = tf.placeholder(tf.float32, shape=(3, 3))<br> y = tf.matmul(x, x) with tf.Session() as sess:<br>   rand_array = np.random.rand(3, 3)<br>   print(sess.run(y, feed_dict = {x: rand_array}))</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">运行结果：</span><br><span class="line">&#96;&#96;&#96;&#96; </span><br><span class="line">\[\[0.62475741 0.40487182 0.5968855 \] </span><br><span class="line">\[0.17491265 0.08546661 0.23616122\] </span><br><span class="line">\[0.53931886 0.24997233 0.56168258\]\]\</span><br></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title>GPU中的Hyper-Q技术</title>
    <url>/2020/12/10/GPU%E4%B8%AD%E7%9A%84Hyper-Q%E6%8A%80%E6%9C%AF/</url>
    <content><![CDATA[<h2 id="GPU-抢占"><a href="#GPU-抢占" class="headerlink" title="GPU 抢占"></a>GPU 抢占</h2><p>由于 GPU 核数较多, 抢占 GPU 需要保存大量的上下文信息, 开销较大, 所以目前市场上 GPU 都不支持抢占特性. 只用当前任务完成之后, GPU 才能被下个应用程序使用。 在 GPU 虚拟化的环境中, 多用户使用的场景会导致 GPU 进行频繁的任务切换, 可抢占的 GPU 能够防止恶意用户长期占用, 并且 能够实现用户优先级权限管理。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A CUDA context is a virtual execution space that holds the code and data owned by a host thread or process. Only one context can ever be active on a GPU with all current hardware.</span><br><span class="line"></span><br><span class="line">So to answer your first question, if you have seven separate threads or processes all trying to establish a context and run on the same GPU simultaneously, they will be serialised and any process waiting for access to the GPU will be blocked until the owner of the running context yields. There is, to the best of my knowledge, no time slicing and the scheduling heuristics are not documented and (I would suspect) not uniform from operating system to operating system.</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">You would be better to launch a single worker thread holding a GPU context and use messaging from the other threads to push work onto the GPU. Alternatively there is a context migration facility available in the CUDA driver API, but that will only work with threads from the same process, and the migration mechanism has latency and host CPU overhead.</span><br></pre></td></tr></table></figure>

<p>翻译一下：</p>
<p>尝试建立context并且同时运行在同一GPU设备上的不同的线程或进程，它们会被串行化而且任何等待访问GPU的进程将会被阻塞直到运行的context的进程退出。并没有文档来介绍时间分片还有调度算法。建议最好先启动包含着GPU上下文的单 worker 线程，使用来自别的线程的消息来将工作推给GPU。或者，CUDA driver API有个上下文迁移工具，它也能与来自同一进程的线程配合，但是迁移机制有延迟，对CPU带来负荷。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CUDA activity from independent host processes will normally create independent CUDA contexts, one for each process. Thus, the CUDA activity launched from separate host processes will take place in separate CUDA contexts, on the same device.</span><br><span class="line"></span><br><span class="line">CUDA activity in separate contexts will be serialized. The GPU will execute the activity from one process, and when that activity is idle, it can and will context-switch to another context to complete the CUDA activity launched from the other process. The detailed inter-context scheduling behavior is not specified. (Running multiple contexts on a single GPU also cannot normally violate basic GPU limits, such as memory availability for device allocations.)</span><br><span class="line"></span><br><span class="line">The &quot;exception&quot; to this case (serialization of GPU activity from independent host processes) would be the CUDA Multi-Process Server. In a nutshell, the MPS acts as a &quot;funnel&quot; to collect CUDA activity emanating from several host processes, and run that activity as if it emanated from a single host process. The principal benefit is to avoid the serialization of kernels which might otherwise be able to run concurrently. The canonical use-case would be for launching multiple MPI ranks that all intend to use a single GPU resource.</span><br><span class="line"> </span><br><span class="line">Note that the above description applies to GPUs which are in the &quot;Default&quot; compute mode. GPUs in &quot;Exclusive Process&quot; or &quot;Exclusive Thread&quot; compute modes will reject any attempts to create more than one process&#x2F;context on a single device. In one of these modes, attempts by other processes to use a device already in use will result in a CUDA API reported failure. The compute mode is modifiable in some cases using the nvidia-smi utility.</span><br></pre></td></tr></table></figure>


<h2 id="Hyper-Q-技术"><a href="#Hyper-Q-技术" class="headerlink" title="Hyper-Q 技术"></a>Hyper-Q 技术</h2><p>为了解决多个Kernel 函数同时在GPU中运行的问题，Nvidia 推出了Hyper-Q这个硬件技术，具体可以参考下面的ppt。目前实行多进程同时运行在GPU的方法是基于NVIDIA的MPS技术</p>
<object data="./20191031_MPS_davidwu.pdf" type="application/pdf" width="100%" height="877px"></object>]]></content>
  </entry>
  <entry>
    <title>Window导入postgres的sql文件的encoding 错误</title>
    <url>/2020/09/15/Window%E5%AF%BC%E5%85%A5postgres%E7%9A%84sql%E6%96%87%E4%BB%B6%E7%9A%84encoding-%E9%94%99%E8%AF%AF/</url>
    <content><![CDATA[<p>postgres的windows客户端使用pgadmin，pgadmin没有直接导入sql的操作，需要命令行导入，在windows的命令行执行导入命令，会报以下错误：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">character with byte sequence 0xc2 0x90 in encoding GBK has no </span><br><span class="line">equivalent in encodeing utf8</span><br></pre></td></tr></table></figure>
<p>出现这种错误的原因，通常是psql的客户端编码与服务端的编码不一致导致的，可以使用以下操作，解决编码问题`</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">psql -u postgres -p 5432 -d slip -h 10.10.70.58</span><br><span class="line">slip&#x3D;#encoding UTF8;</span><br><span class="line">slip&#x3D;# \i &#39;c:&#x2F;public.sql&#39;;</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>cuda与driver版本关系</title>
    <url>/2020/09/11/cuda%E4%B8%8Edriver%E7%89%88%E6%9C%AC%E5%85%B3%E7%B3%BB/</url>
    <content><![CDATA[<p>#问题<br>  最近遇到了不少需要容器镜像需要更新cuda版本的问题，宿主机安装了低版本的GPU 驱动，但是需要使用高版本的CUDA，通常下载driver时，都会选择cuda版本，然后再去下载对于的GPU 驱动。Nvidia 官方给出了低版本驱动兼容cuda 的兼容列表，<a href="https://docs.nvidia.com/deploy/cuda-compatibility/index.html" target="_blank" rel="noopener">参考</a></p>
<p>  目前升级cuda的方式时，需要同时升级驱动，如下图所示 <img src="/2020/09/11/cuda%E4%B8%8Edriver%E7%89%88%E6%9C%AC%E5%85%B3%E7%B3%BB/1.png" alt="avatar"></p>
<p>  cuda toolkit包含两个主要组件</p>
<ol>
<li><p>开发库，包括cuda runtime</p>
</li>
<li><p>驱动部分，驱动部分又进一步分为两类</p>
<ol>
<li>kernel 态相关组件（display driver）</li>
<li>用户态组件（cuda driver、openGL driver等等）</li>
</ol>
<p>从cuda10.0开始，NVIDIA引入了一个前向升级的途径，能够在升级cuda driver的时候不修改内核态的组件。参考下图，这就能够基于已经存在的驱动，使用最新的cuda，从而降低驱动升级带来的风险。<img src="/2020/09/11/cuda%E4%B8%8Edriver%E7%89%88%E6%9C%AC%E5%85%B3%E7%B3%BB/2.png" alt="avatar"></p>
</li>
</ol>
<p> #源码兼容性<br> 基于特定版本的库（SDK）编译的应用仍然能够正常编译和运行，跨不同版本的SDK，CUDA driver 和Cuda runtime 都不支持源码级别的兼容性。API可能被废弃或者移除，开发者需要通过官方文档来获取这些信息。</p>
<p> #二进制兼容性<br> cuda driver（libcuda.so）提供了后向兼容性，例如，一个基于cuda3.2 SDK编译的应用仍然能够在现在的driver stack上正常运行，另一方面，cuda runtime不会做上述保证，如果你的应用动态链接到cuda9.2版本，那么这个应用只能运行在9.2的cuda runtime。如果应用是静态链接到runtime，那么他会在最小支持的driver上正常运行，下表列出了cuda 依赖的driver 版本信息<img src="/2020/09/11/cuda%E4%B8%8Edriver%E7%89%88%E6%9C%AC%E5%85%B3%E7%B3%BB/3.png" alt="avatar"></p>
<p> #支持<br> ##硬件兼容性<br> 当前支持的硬件如下表所示：<br> <img src="/2020/09/11/cuda%E4%B8%8Edriver%E7%89%88%E6%9C%AC%E5%85%B3%E7%B3%BB/4.png" alt="avatar"></p>
<p> ##前向兼容的升级途径<br> 新的升级cuda driver的方式是为了简化大规模系统的管理。当前这种升级方式只支持Tesla GPU。硬件支持是由kernel model driver 决定，新的cuda driver不会开启新的硬件支持</p>
<p> ##cuda应用兼容性<br> 基于行的cuda toolkits 编译的应用可以在特别的企业版Tesla driver 分支上支持。下表列出了cuda 和driver的兼容列表<br> <img src="/2020/09/11/cuda%E4%B8%8Edriver%E7%89%88%E6%9C%AC%E5%85%B3%E7%B3%BB/5.png" alt="avatar"></p>
<h2 id="特性支持"><a href="#特性支持" class="headerlink" title="特性支持"></a>特性支持</h2><p> cuda driver里面可能需要kernel-model的支持，而且可能只能使用新的kernel mode driver。 <img src="/2020/09/11/cuda%E4%B8%8Edriver%E7%89%88%E6%9C%AC%E5%85%B3%E7%B3%BB/6.png" alt="avatar"></p>
<p> #cuda兼容性平台<br> 涉及到cuda兼容性的的文件（也就是对于已经安装完的系统，这些文件不能替换），这些主要包括libcuda.so.<em>(cuda driver)和libnvidia-ptxjitcompiler.so.</em>(用于PTX文件的JIT just in time 编译器)，为了减少部署，nvidia引入了一个新的软件包cuda-compat-11.0，这个软件包提供了cuda兼容性的平台<br> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get install cuda-compat-11-0</span><br></pre></td></tr></table></figure></p>
]]></content>
  </entry>
  <entry>
    <title>com.sun.image.codec.jpeg does not exist</title>
    <url>/2020/09/21/com-sun-image-codec-jpeg-does-not-exist/</url>
    <content><![CDATA[<h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>一个项目在windows下执行mvn package正常，但是放在Linux环境下，会出现找不到com.sun.image.codec的问题，如下所示</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ERROR] COMPILATION ERROR : </span><br><span class="line">[INFO] -------------------------------------------------------------</span><br><span class="line">[ERROR] &#x2F;home&#x2F;ztzx&#x2F;ztzx.service&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;telchina&#x2F;ztzx&#x2F;common&#x2F;controller&#x2F;UploadController2.java:[24,40] package com.sun.image.codec.jpeg does not exist</span><br><span class="line">[ERROR] &#x2F;home&#x2F;ztzx&#x2F;ztzx.service&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;telchina&#x2F;ztzx&#x2F;common&#x2F;controller&#x2F;UploadController2.java:[25,40] package com.sun.image.codec.jpeg does not exist</span><br><span class="line">[ERROR] &#x2F;home&#x2F;ztzx&#x2F;ztzx.service&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;telchina&#x2F;ztzx&#x2F;common&#x2F;controller&#x2F;UploadController.java:[25,32] package com.sun.image.codec.jpeg does not exist</span><br><span class="line">[ERROR] &#x2F;home&#x2F;ztzx&#x2F;ztzx.service&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;telchina&#x2F;ztzx&#x2F;common&#x2F;controller&#x2F;UploadController.java:[26,32] package com.sun.image.codec.jpeg does not exist</span><br><span class="line">[INFO] 4 errors </span><br><span class="line">[INFO] -------------------------------------------------------------</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Reactor Summary:</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] ztzx 1.0.0 ......................................... SUCCESS [  0.007 s]</span><br><span class="line">[INFO] ztzx.service ....................................... FAILURE [02:11 min]</span><br><span class="line">[INFO] ztzx.web 1.0.0 ..................................... SKIPPED</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD FAILURE</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 02:11 min</span><br><span class="line">[INFO] Finished at: 2018-08-06T01:51:45Z</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project ztzx.service: Compilation failure: Compilation failure: </span><br><span class="line">[ERROR] &#x2F;home&#x2F;ztzx&#x2F;ztzx.service&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;telchina&#x2F;ztzx&#x2F;common&#x2F;controller&#x2F;UploadController2.java:[24,40] package com.sun.image.codec.jpeg does not exist</span><br><span class="line">[ERROR] &#x2F;home&#x2F;ztzx&#x2F;ztzx.service&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;telchina&#x2F;ztzx&#x2F;common&#x2F;controller&#x2F;UploadController2.java:[25,40] package com.sun.image.codec.jpeg does not exist</span><br><span class="line">[ERROR] &#x2F;home&#x2F;ztzx&#x2F;ztzx.service&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;telchina&#x2F;ztzx&#x2F;common&#x2F;controller&#x2F;UploadController.java:[25,32] package com.sun.image.codec.jpeg does not exist</span><br><span class="line">[ERROR] &#x2F;home&#x2F;ztzx&#x2F;ztzx.service&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;telchina&#x2F;ztzx&#x2F;common&#x2F;controller&#x2F;UploadController.java:[26,32] package com.sun.image.codec.jpeg does not exist</span><br><span class="line">[ERROR] -&gt; [Help 1]</span><br><span class="line">[ERROR] </span><br><span class="line">[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.</span><br><span class="line">[ERROR] Re-run Maven using the -X switch to enable full debug logging.</span><br><span class="line">[ERROR] </span><br><span class="line">[ERROR] For more information about the errors and possible solutions, please read the following articles:</span><br><span class="line">[ERROR] [Help 1] http:&#x2F;&#x2F;cwiki.apache.org&#x2F;confluence&#x2F;display&#x2F;MAVEN&#x2F;MojoFailureException</span><br><span class="line">[ERROR] </span><br><span class="line">[ERROR] After correcting the problems, you can resume the build with the command</span><br><span class="line">[ERROR]   mvn &lt;goals&gt; -rf :ztzx.service</span><br></pre></td></tr></table></figure>

<h3 id="分析一"><a href="#分析一" class="headerlink" title="分析一"></a>分析一</h3><p>按照Java官方的解释,sun.image.codec这个package已经被deprecated，建议不要使用，看官方的解释： Why Developers Should Not Write Programs That Call ‘sun’ Packages The java.*, javax.* and org.* packages documented in the Java Platform Standard Edition API Specification make up the official, supported, public interface. If a Java program directly calls only API in these packages, it will operate on all Java-compatible platforms, regardless of the underlying OS platform. The sun.* packages are not part of the supported, public interface. A Java program that directly calls into sun.* packages is not guaranteed to work on all Java-compatible platforms. In fact, such a program is not guaranteed to work even in future versions on the same platform. Each company that implements the Java platform will do so in their own private way. The classes in sun.* are present in the JDK to support Oracle’s implementation of the Java platform: the sun.* classes are what make the Java platform classes work “under the covers” for Oracle’s JDK. These classes will not in general be present on another vendor’s Java platform. If your Java program asks for a class “sun.package.Foo” by name, it may fail with ClassNotFoundError, and you will have lost a major advantage of developing in Java. Technically, nothing prevents your program from calling into sun.* by name. From one release to another, these classes may be removed, or they may be moved from one package to another, and it’s fairly likely that their interface (method names and signatures) will change. (From Oracle’s point of view, since we are committed to maintaining the Java platform, we need to be able to change sun.* to refine and enhance the platform.) In this case, even if you are willing to run only on Oracle’s implementation, you run the risk of a new version of the implementation breaking your program. In general, writing java programs that rely on sun.* is risky: those classes are not portable, and are not supported<br>可以这样理解，Java已经被Oracle收购多年，里面再去出现sun的package算怎么回事。。O(∩_∩)O哈哈~，当然你还是可以去使用的，可以在pom.xml 经配置了下面的参数，排除无法引入jar包的问题，这个方法并不能解决我在Linux无法进行构建的的问题。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;plugin&gt;</span><br><span class="line">                   &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;</span><br><span class="line">                   &lt;artifactId&gt;maven-compiler-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">                   &lt;version&gt;3.1&lt;&#x2F;version&gt;</span><br><span class="line">                   &lt;configuration&gt;</span><br><span class="line">                       &lt;source&gt;$&#123;jdkVersion&#125;&lt;&#x2F;source&gt;</span><br><span class="line">                       &lt;target&gt;$&#123;jdkVersion&#125;&lt;&#x2F;target&gt;</span><br><span class="line">                       &lt;compilerArguments&gt;</span><br><span class="line">                           &lt;verbose &#x2F;&gt;</span><br><span class="line">                           &lt;bootclasspath&gt;$&#123;JAVA_HOME&#125;&#x2F;jre&#x2F;lib&#x2F;rt.jar$&#123;path.separator&#125;$&#123;JAVA_HOME&#125;&#x2F;jre&#x2F;lib&#x2F;jce.jar&lt;&#x2F;bootclasspath&gt;</span><br><span class="line">                       &lt;&#x2F;compilerArguments&gt;</span><br><span class="line">                   &lt;&#x2F;configuration&gt;</span><br><span class="line">               &lt;&#x2F;plugin&gt;</span><br></pre></td></tr></table></figure>

<h3 id="分析二"><a href="#分析二" class="headerlink" title="分析二"></a>分析二</h3><p>查看mvn仓库信息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@30e8e1cd5962:&#x2F;home&#x2F;ztzx# mvn -version</span><br><span class="line">Apache Maven 3.5.3 (3383c37e1f9e9b3bc3df5050c29c8aff9f295297; 2018-02-24T19:49:05Z)</span><br><span class="line">Maven home: &#x2F;usr&#x2F;share&#x2F;maven</span><br><span class="line">Java version: 1.8.0_91, vendor: Oracle Corporation</span><br><span class="line">Java home: &#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-8-openjdk-amd64&#x2F;jre</span><br><span class="line">Default locale: en, platform encoding: UTF-8</span><br><span class="line">OS name: &quot;linux&quot;, version: &quot;3.10.0-693.el7.x86_64&quot;, arch: &quot;amd64&quot;, family: &quot;unix&quot; </span><br><span class="line">&#96;&#96;&#96;查看Java 信息</span><br></pre></td></tr></table></figure>
<p>root@30e8e1cd5962:/home/ztzx# java -version<br>openjdk version “1.8.0_91”<br>OpenJDK Runtime Environment (build 1.8.0_91-8u91-b14-1~bpo8+1-b14)<br>OpenJDK 64-Bit Server VM (build 25.91-b14, mixed mode) </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">与windows的运行环境相比，出Java的小版本不同外，还有一个区别，就是Oracle Java与OpenJdk的区别，google资料，发现OpenJdk已经在1.7版本移除了该package。[OpenJdk移除jepg的package](http:&#x2F;&#x2F;jira.icesoft.org&#x2F;browse&#x2F;PDF-332?jql&#x3D;project%20%3D%20PDF%20AND%20fixVersion%20%3D%205.1%20ORDER%20BY%20updated%20DESC%2C%20priority%20DESC%2C%20created%20ASC)，将Linux 默认的OpenJdk替换为Oracle的Jdk，即可以解决问题</span><br><span class="line"></span><br><span class="line">### 其他解决方法</span><br><span class="line"></span><br><span class="line">JPEGImageEncoder类是SUN公司私有类</span><br></pre></td></tr></table></figure>
<p>一般出现在这样的代码段中：<br>    FileOutputStream out = new FileOutputStream(dstName);<br>     JPEGImageEncoder encoder = JPEGCodec.createJPEGEncoder(out);<br>     encoder.encode(dstImage);</p>
<p>改写成：</p>
<pre><code>String formatName = dstName.substring(dstName.lastIndexOf(&quot;.&quot;) + 1);
 //FileOutputStream out = new FileOutputStream(dstName);
 //JPEGImageEncoder encoder = JPEGCodec.createJPEGEncoder(out);
 //encoder.encode(dstImage);
 ImageIO.write(dstImage, /*&quot;GIF&quot;*/ formatName /* format desired */ , new File(dstName) /* target */ ); </code></pre>
<p>```<br>都使用统一的ImageIO进行图像格式文件的读写，没有必要使用过时的实现类JPEGImageEncoder类。</p>
]]></content>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2020/10/06/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>my first blog</title>
    <url>/2020/09/03/my-first-blog/</url>
    <content><![CDATA[<h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3>]]></content>
  </entry>
  <entry>
    <title>WiWarden启动源码分析</title>
    <url>/2020/09/15/WiWarden%E5%90%AF%E5%8A%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<p>今天研究warden的源码，分析了启动流程，整理了一下。</p>
<p>Warden 启动入口:src\warden\warden\lib\warden\server.rb  def self.run!</p>
<p>  （1）Process.setrlimit(Process::RLIMIT_NOFILE, 32768):linux 内核资源限制，一个进程能够打开的最大文件数</p>
<p>  （2）container_klass.setup(self.config)  调用src\warden\warden\lib\warden\container\linux.rb setup</p>
<p>  （3）执行脚本\src\warden\warden\root\linux\setup.sh</p>
<p>  （4） cgroup 控制</p>
<p>           （4.1）创建 /tmp/warden/cgroup</p>
<p>           （4.2）mount -t tmpfs none /tmp/warden/cgroup   创建虚拟文件系统（存储的内容在RM或者Swap空间）</p>
<p>            (4.3)  挂载cgroup子系统</p>
<p>                     none /tmp/warden/cgroup/cpu cgroup rw,relatime,cpu 0 0</p>
<p>                     none /tmp/warden/cgroup/cpuacct cgroup rw,relatime,cpuacct 0 0</p>
<p>                     none /tmp/warden/cgroup/devices cgroup rw,relatime,devices 0 0</p>
<p>                     none /tmp/warden/cgroup/memory cgroup rw,relatime,memory 0 0</p>
<p>   Cgroup子系统作用介绍</p>
<p>   blkio : 这个子系统设置限制每个块设备的输入输出控制。例如:磁盘，光盘以及usb等等。</p>
<p>   cpu  : 这个子系统使用调度程序为cgroup任务提供cpu的访问。</p>
<p>   cpuacct : 产生cgroup任务的cpu资源报告。</p>
<p>   cpuset : 如果是多核心的cpu，这个子系统会为cgroup任务分配单独的cpu和内存。</p>
<p>   devices : 允许或拒绝cgroup任务对设备的访问。</p>
<p>   freezer : 暂停和恢复cgroup任务。</p>
<p>   memory : 设置每个cgroup的内存限制以及产生内存资源报告。</p>
<p>   net_cls : 标记每个网络包以供cgroup方便使用。</p>
<p>   ns    :   名称空间子系统。</p>
<p>   perf_event:   增加了对每group的监测跟踪的能力，即可以监测属于某个特定的group的所有线程以及运行在特定CPU上的线程，此功能对于监测整个group非常有用</p>
<p>（5） <!--\[endif\]-->网络配置，执行脚本src\warden\warden\root\linux\net.sh</p>
<p>           （5.1）setup_filter: </p>
<p>               iptables -N warden-forward 2&gt; /dev/null || iptables -F warden-forward</p>
<p>               iptables -A warden-forward -j DROP   </p>
<p>                     创建过滤链，增加过滤规则（丢弃封包不予处理，进行完此处理动作后，将不再比对其它规则，直接中断过滤程序）</p>
<p>              iptables -N warden-default 2&gt; /dev/null || iptables -F warden-default</p>
<p>                创建默认过滤链</p>
<p>              iptables -A warden-default -m conntrack –ctstate ESTABLISHED,RELATED -j ACCEPT</p>
<p>                默认过滤链增加规则，允许已经建立的连接到containers</p>
<p>              iptables -A warden-default –destination “$n” –jump RETURN</p>
<p>              iptables -A warden-default –destination “$n” –jump DROP</p>
<p>                设置配置文件中配置的 被允许的网络，以及被禁止的网络</p>
<p>              iptables -A FORWARD -i w-+ –jump warden-forward</p>
<p>                     配置outbound traffic</p>
<p>             default_interface=$(ip route show | grep default | cut -d’ ‘ -f5 | head -1)</p>
<p>             iptables -I warden-forward -i $default_interface –jump ACCEPT</p>
<p>                设置使用的网卡接口 设置inround traffic</p>
<p>    (5.2)setup_nat</p>
<p>        iptables -t nat -N warden-prerouting 2&gt; /dev/null || true</p>
<p>            新建一个 nat规则表</p>
<p>      (iptables -t nat -S PREROUTING | grep -q “\-j warden-prerouting\b”) ||</p>
<p>      iptables -t nat -A PREROUTING \</p>
<p>      –jump warden-prerouting</p>
<p>     检查是否存在nat的prerouting 规则链 与warden-prerouting 绑定，如果没有将warden-prerouting  绑定到nat的prerouting规则链。</p>
<p>    (iptables -t nat -S OUTPUT | grep -q “\-j warden-prerouting\b”) ||</p>
<p>    iptables -t nat -A OUTPUT \</p>
<p>      –out-interface “lo” \</p>
<p>      –jump warden-prerouting</p>
<p>  Bind chain to OUTPUT (for traffic originating from same host)</p>
<p>  # Create postrouting chain</p>
<p>  iptables -t nat -N ${nat_postrouting_chain} 2&gt; /dev/null || true</p>
<p>  # Bind chain to POSTROUTING</p>
<p>  (iptables -t nat -S POSTROUTING | grep -q “\-j ${nat_postrouting_chain}\b”) ||</p>
<p>    iptables -t nat -A POSTROUTING \</p>
<p>      –jump ${nat_postrouting_chain}</p>
<p>  # Enable NAT for traffic coming from containers</p>
<p>  (iptables -t nat -S ${nat_postrouting_chain} | grep -q “\-j SNAT\b”) ||</p>
<p>    iptables -t nat -A ${nat_postrouting_chain} \</p>
<p>      –source ${POOL_NETWORK} \</p>
<p>      –jump SNAT \</p>
<p>      –to $(external_ip)</p>
<p> （6） 关闭AppArmor</p>
<p> （7） 设置warden的配额</p>
<p>        配置文件设置了quota:</p>
<p>                          disk_quota_enabled: true</p>
<p>         并且存放container的目录（/tmp/warden/containers）开启了配额管理</p>
<p>           mount -o remount,usrjquota=aquota.user,grpjquota=aquota.group,jqfmt=vfsv0 $CONTAINER_DEPOT_MOUNT_POINT_PATH</p>
<!--\[if !supportLists\]--> (8)<!--\[endif\]-->回到 src\\warden\\warden\\lib\\warden\\server.rb 执行：recover\_containers

<p>   检查 /tmp/warden/containers 的container 状态</p>
<p>       （1）将死去的container删除（destroy.sh）</p>
<p>       （2）将仍然存活的container 启动(根据snapshot.json 中的信息恢复)</p>
<!--\[if !supportLists\]-->（9） <!--\[endif\]-->启动warden 进程

<p>        FileUtils.rm_f(unix_domain_path)</p>
<p>          server = ::EM.start_unix_domain_server(unix_domain_path, ClientConnection)</p>
<p>          ::EM.start_server(“127.0.0.1”, config.health_check_server[“port”],HealthCheck)</p>
<p>（10）</p>
<p>    @drainer = Drainer.new(server, “USR2”)</p>
<p>    @drainer.on_complete do</p>
<p>            Fiber.new do</p>
<p>              logger.info(“Drain complete”)</p>
<p>              # Serialize container state</p>
<p>              container_klass.registry.each { |_, c| c.write_snapshot }</p>
<p>              EM.stop</p>
<p>            end.resume</p>
<p>          End</p>
<p>   目前还不清楚是做什么。</p>
<p>（11） </p>
<p>          FileUtils.chmod(unix_domain_permissions, unix_domain_path)</p>
<p>          修改/tmp/warden.sock 文件属性为0777</p>
<p>          # Let the world know Warden is ready for action.</p>
<p>          logger.info(“Listening on #{unix_domain_path}”)</p>
<p>          if pidfile = config.server[“pidfile”]</p>
<p>            logger.info(“Writing pid #{Process.pid} to #{pidfile}”)</p>
<p>            PidFile.new(piddir: File.dirname(pidfile), pidfile: File.basename(pidfile))</p>
<p>          end</p>
]]></content>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title>test</title>
    <url>/2020/09/14/test/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Spring的IOC与AOP（转载）</title>
    <url>/2020/09/15/Spring%E7%9A%84IOC%E4%B8%8EAOP%EF%BC%88%E8%BD%AC%E8%BD%BD%EF%BC%89/</url>
    <content><![CDATA[<p>众所周知，Spring的核心特性就是IOC和AOP，IOC（Inversion of Control），即“控制反转”；AOP（Aspect-OrientedProgramming），即“面向切面编程”。参考书《Spring In Action》，下面分享一下我对这两大特性的个人理解。</p>
<p>IOC：IOC，另外一种说法叫DI（Dependency Injection），即依赖注入。它并不是一种技术实现，而是一种设计思想。在任何一个有实际开发意义的程序项目中，我们会使用很多类来描述它们特有的功能，并且通过类与类之间的相互协作来完成特定的业务逻辑。这个时候，每个类都需要负责管理与自己有交互的类的引用和依赖，代码将会变的异常难以维护和极度的高耦合。而IOC的出现正是用来解决这个问题，我们通过IOC将这些相互依赖对象的创建、协调工作交给Spring容器去处理，每个对象只需要关注其自身的业务逻辑关系就可以了。在这样的角度上来看，获得依赖的对象的方式，进行了反转，变成了由spring容器控制对象如何获取外部资源（包括其他对象和文件资料等等）。</p>
<blockquote>
<p>举例：某一天，你生病了，但是你不清楚自己到底得了什么病，你只知道自己头疼，咳嗽，全身无力。这个时候你决定去药店买药，药店有很多种药，仅仅是治疗头疼就有好几十种，还有西药中药等区别。然后你自己看了看说明书，选择了一盒你自己觉得最能治疗自己病症的药，付钱吃药，期待可以早点好起来。 <br>但是这个过程，对于一个病人来说，太辛苦了。头疼，咳嗽，全身无力，还要一个个的看药品说明书，一个个的比较哪个药比较好，简直是太累了。这个时候，你决定直接去医院看医生。 <br>医生给你做了检查，知道你的病症是什么，有什么原因引起的；同时医生非常了解有哪些药能治疗你的病痛，并且能根据你的自身情况进行筛选。只需要短短的十几分钟，你就能拿到对症下药的药品，即省时又省力。</p>
</blockquote>
<p>在上面这个例子中，IOC起到的就是医生的作用，它收集你的需求要求，并且对症下药，直接把药开给你。你就是对象，药品就是你所需要的外部资源。通过医生，你不用再去找药品，而是通过医生把药品开给你。这就是整个IOC的精髓所在。</p>
<p>AOP：面向切面编程，往往被定义为促使软件系统实现关注点的分离的技术。系统是由许多不同的组件所组成的，每一个组件各负责一块特定功能。除了实现自身核心功能之外，这些组件还经常承担着额外的职责。例如日志、事务管理和安全这样的核心服务经常融入到自身具有核心业务逻辑的组件中去。这些系统服务经常被称为横切关注点，因为它们会跨越系统的多个组件。</p>
<p>AOP的概念不好像IOC一样实例化举例，现在我们以一个系统中的具体实现来讲讲AOP具体是个什么技术。</p>
<blockquote>
<p>我们以系统中常用到的事务管控举例子。在系统操作数据库的过程中，不可避免地要考虑到事务相关的内容。如果在每一个方法中都新建一个事务管理器，那么无疑是对代码严重的耦合和侵入。为了简化我们的开发过程（实际上spring所做的一切实现都是为了简化开发过程），需要把事务相关的代码抽成出来做为一个独立的模块。通过AOP，确认每一个操作数据库方法为一个连接点，这些连接点组成了一个切面。当程序运行到其中某个一个切点时，我们将事务管理模块顺势织入对象中，通过通知功能，完成整个事务管控的实现。这样一来，所有的操作数据库的方法中不需要再单独关心事务管理的内容，只需要关注自身的业务代码的实现即可。所有的事务管控相关的内容都通过AOP的方式进行了实现。简化了代码的内容，将目标对象复杂的内容进行解耦，分离业务逻辑与横切关注点。</p>
</blockquote>
<p>下面介绍一下AOP相关的术语：</p>
<ul>
<li>通知： 通知定义了切面是什么以及何时使用的概念。Spring 切面可以应用5种类型的通知：</li>
</ul>
<ul>
<li><p>前置通知（Before）：在目标方法被调用之前调用通知功能。</p>
</li>
<li><p>后置通知（After）：在目标方法完成之后调用通知，此时不会关心方法的输出是什么。</p>
</li>
<li><p>返回通知（After-returning）：在目标方法成功执行之后调用通知。</p>
</li>
<li><p>异常通知（After-throwing）：在目标方法抛出异常后调用通知。</p>
</li>
<li><p>环绕通知（Around）：通知包裹了被通知的方法，在被通知的方法调用之前和调用之后执行自定义的行为。</p>
</li>
</ul>
<ul>
<li><p>连接点：是在应用执行过程中能够插入切面的一个点。</p>
</li>
<li><p>切点： 切点定义了切面在何处要织入的一个或者多个连接点。</p>
</li>
<li><p>切面：是通知和切点的结合。通知和切点共同定义了切面的全部内容。</p>
</li>
<li><p>引入：引入允许我们向现有类添加新方法或属性。</p>
</li>
<li><p>织入：是把切面应用到目标对象，并创建新的代理对象的过程。切面在指定的连接点被织入到目标对象中。在目标对象的生命周期中有多个点可以进行织入：   </p>
</li>
</ul>
<ul>
<li><p>编译期： 在目标类编译时，切面被织入。这种方式需要特殊的编译器。AspectJ的织入编译器就是以这种方式织入切面的。</p>
</li>
<li><p>类加载期：切面在目标加载到JVM时被织入。这种方式需要特殊的类加载器(class loader)它可以在目标类被引入应用之前增强该目标类的字节码。</p>
</li>
<li><p>运行期： 切面在应用运行到某个时刻时被织入。一般情况下，在织入切面时，AOP容器会为目标对象动态地创建一个代理对象。SpringAOP就是以这种方式织入切面的。</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>容器内Tomcat的JVM内存配置</title>
    <url>/2020/09/04/%E5%AE%B9%E5%99%A8%E5%86%85Tomcat%E7%9A%84JVM%E5%86%85%E5%AD%98%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>1、<br>JVM内存分配机制</p>
<p>编写测试Demo</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -itd -p 8080:8080 tomcat:8.5.29</span><br><span class="line">docker cp demo&#x2F; cas233af:&#x2F;usr&#x2F;local&#x2F;tomcat&#x2F;webapps</span><br><span class="line">docker restart cas233af</span><br><span class="line">curl http:&#x2F;&#x2F;127.0.0.1:8080&#x2F;demo&#x2F;jvm&#x2F;hello</span><br><span class="line">&#123;&quot;totalMemory&quot;:&quot;124 M&quot;,&quot;maxMemory&quot;:&quot;405 M&quot;,&quot;freeMemory&quot;:&quot;72 M&quot;&#125;</span><br><span class="line"></span><br><span class="line">[root@localhost tomcatjvm]# free -m</span><br><span class="line">                     total        used        free      shared  buff&#x2F;cache   available</span><br><span class="line">Mem:           1823         408        1028           8         386        1198</span><br><span class="line">Swap:          2047           0        2047</span><br></pre></td></tr></table></figure>

<p>3、测试<br>基于社区的Tomcat进行测试</p>
<p>4、修改<br> 容器启动时，获取该容器的内存，并进行修改JAVA的最大可用内存，下图为tomcat的内存配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">limit_in_bytes&#x3D;$(cat &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;memory&#x2F;memory.limit_in_bytes)</span><br><span class="line">echo $limit_in_bytes</span><br><span class="line"># If not default limit_in_bytes in cgroup</span><br><span class="line">if [ &quot;$limit_in_bytes&quot; -ne &quot;9223372036854771712&quot; ]</span><br><span class="line">then</span><br><span class="line">        limit_in_megabytes&#x3D;&#96;expr $&#123;limit_in_bytes&#125; &#x2F; 1048576&#96;</span><br><span class="line">        echo $limit_in_megabytes</span><br><span class="line">        heap_size&#x3D;$limit_in_megabytes</span><br><span class="line">        export JAVA_OPTS&#x3D;&quot;-Xms$&#123;heap_size&#125;m -Xmx$&#123;heap_size&#125;m $JAVA_OPTS&quot;</span><br><span class="line">fi</span><br><span class="line">exec &#x2F;usr&#x2F;local&#x2F;tomcat&#x2F;bin&#x2F;catalina.sh run</span><br></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title>编译tensorflow 源码</title>
    <url>/2020/12/15/%E7%BC%96%E8%AF%91tensorflow-%E6%BA%90%E7%A0%81/</url>
    <content><![CDATA[<p><a href="https://www.cnblogs.com/dzzy/p/13493876.html" target="_blank" rel="noopener">https://www.cnblogs.com/dzzy/p/13493876.html</a></p>
<p><a href="http://fancyerii.github.io/2020/11/14/centos-build-tf/" target="_blank" rel="noopener">http://fancyerii.github.io/2020/11/14/centos-build-tf/</a></p>
]]></content>
      <tags>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title>ngc cuda11镜像运行mpi任务</title>
    <url>/2020/11/11/ngc-cuda11%E9%95%9C%E5%83%8F%E8%BF%90%E8%A1%8Cmpi%E4%BB%BB%E5%8A%A1/</url>
    <content><![CDATA[<p>ngc官网的cuda 11镜像如果运行MPI任务，以太网使用以下命令提交训练任务，否则会出现以下错误</p>
<p> <img src="/2020/11/11/ngc-cuda11%E9%95%9C%E5%83%8F%E8%BF%90%E8%A1%8Cmpi%E4%BB%BB%E5%8A%A1/ucxerror.png" alt="avatar"><br>这是由于镜像内置了ucx 组件，需要IB的支持，如果没有IB的话，会报错，建议使用一下命令运行mpi任务</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mpirun --oversubscribe --allow-run-as-root -np 2 -mca pml ob1  python &#x2F;inspur&#x2F;models&#x2F;horovod&#x2F;tensorflow_mnist.py  --data_dir&#x3D;&#x2F;MNIST_data</span><br></pre></td></tr></table></figure>
<p>mpi这块积累不多，只记录这个错误了，后续深入后，再详细研究</p>
]]></content>
  </entry>
  <entry>
    <title>Win 208 R2——由于管理员设置的策略，该磁盘处于脱机状态</title>
    <url>/2020/09/15/Win-208-R2%E2%80%94%E2%80%94%E7%94%B1%E4%BA%8E%E7%AE%A1%E7%90%86%E5%91%98%E8%AE%BE%E7%BD%AE%E7%9A%84%E7%AD%96%E7%95%A5%EF%BC%8C%E8%AF%A5%E7%A3%81%E7%9B%98%E5%A4%84%E4%BA%8E%E8%84%B1%E6%9C%BA%E7%8A%B6%E6%80%81/</url>
    <content><![CDATA[<p>1.原系统为Windows 2012挂载了2T的存储，因业务要求重新安装为Windows 2008R2，并没有在磁盘存储空间上重新做映射。  </p>
<p>2.系统安装完成，安装完多路径软件后，无法对挂载的分区进行操作。如下图除了删除卷和帮助其他的都是灰的。点击删除卷提示介质写入保护</p>
<p>3.鼠标指向小叹号提示由于管理员设置的策略，该磁盘处于脱机状态。</p>
<p><img src="https://images2015.cnblogs.com/blog/813376/201510/813376-20151009102500799-1326229038.jpg"></p>
<p><strong>解决方案步骤如下：</strong>  </p>
<p>使用DISKPART.exe命令 解除策略</p>
<p>1.运行：cmd</p>
<p>2.输入：DISKPART.exe搜索</p>
<p>3.DISKPART&gt; san</p>
<p>4.DISKPART&gt; san policy=onlineall</p>
<p>5.DISKPART&gt;list disk</p>
<p>6.DISKPART&gt; select disk 1</p>
<p>7.DISKPART&gt;attributes disk clear readonly</p>
<p><img src="https://images2015.cnblogs.com/blog/813376/201510/813376-20151009103049284-2075799642.jpg"></p>
<p>8.DISKPART&gt;online disk</p>
<p><img src="https://images2015.cnblogs.com/blog/813376/201510/813376-20151009103227471-1421585187.jpg"></p>
<p>NOW！就可以对硬盘进行分区了操作了</p>
<p><img src="https://images2015.cnblogs.com/blog/813376/201510/813376-20151009103346049-1965641745.jpg"></p>
]]></content>
  </entry>
  <entry>
    <title>nginx出现403 is forbidden的4个原因</title>
    <url>/2020/09/04/nginx%E5%87%BA%E7%8E%B0403-is-forbidden%E7%9A%844%E4%B8%AA%E5%8E%9F%E5%9B%A0/</url>
    <content><![CDATA[<p>nginx缺少配置</p>
<p>缺少index.html或者index.php文件，就是配置文件中index index.html index.htm这行中的指定的文件。</p>
<p>server {<br>listen 80;<br>server_name localhost;<br>index index.php index.html;<br>root /var/www; } 如果在/ var/www下面没有index.php,index.html的时候，直接访问域名，找不到文件，会报403 forbidden。</p>
<p>权限问题</p>
<p>如果nginx没有web目录的操作权限，也会出现403错误。</p>
<p>解决办法：修改web目录的读写权限，或者是把nginx的启动用户改成目录的所属用户，重启Nginx即可解决</p>
<p>chmod -R 755 /var/www</p>
<p>Selinux</p>
<p>SELinux设置为开启状态（enabled）的原因</p>
<p>首先查看本机SELinux的开启状态，如果SELinux status参数为enabled即为开启状态</p>
<p>/usr/sbin/sestatus -v 或者使用getenforce命令检查</p>
<p>找到原因了，如何关闭 SELinux 呢</p>
<p>1、临时关闭（不用重启）</p>
<p>setenforce 0 2、修改配置文件 /etcselinux/config，将SELINUX=enforcing改为SELINUX=disabled</p>
<p>vi /etc/selinux/config</p>
<p>SELINUX=enforcing </p>
<p>SELINUX=disabled</p>
<p>文件被其他进程占用</p>
<p>确认nginx的目录是否被其他程序占用，我这里出现的问题就是这个原因，tomcat 启动后加载了该目录，nginx也加载了该目录，就会出现无权限访问的问题</p>
]]></content>
  </entry>
  <entry>
    <title>声明式API</title>
    <url>/2020/12/07/%E5%A3%B0%E6%98%8E%E5%BC%8FAPI/</url>
    <content><![CDATA[<p>声明式API的核心原理，就是当用户向 Kubernetes 提交了一个 API 对象的描述之后，Kubernetes 会负责为你保证整个集群里各项资源的状态，都与你的 API 对象描述的需求相一致。更重要的是，这个保证是一项“无条件的”、“没有期限”的承诺：对于每个保存在 etcd 里的 API 对象，Kubernetes 都通过启动一种叫做“控制器模式”（Controller Pattern）的无限循环，不断检查，然后调谐，最后确保整个集群的状态与这个 API 对象的描述一致。</p>
<p>简单理解就是对象的声明与对象的创建相解耦，在普通程序中创建对象需要向操作系统申请资源，相似的，在容器云平台上创建对象，需要向k8s申请资源。但k8s更进一步的是，你只需要提交一个申请单，然后由k8s系统完成对象的创建。</p>
<blockquote>
<p>命令式编程：命令“机器”如何去做事情(how)，这样不管你想要的是什么(what)，它都会按照你的命令实现。</p>
</blockquote>
<blockquote>
<p>声明式编程：告诉“机器”你想要的是什么(what)，让机器想出如何去做(how)。</p>
</blockquote>
<p>下面这个例子如下所示：</p>
<p><img src="/2020/12/07/%E5%A3%B0%E6%98%8E%E5%BC%8FAPI/1.png" alt="avatar"></p>
]]></content>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>谈docker容器</title>
    <url>/2020/09/08/%E8%B0%88Docker%E5%AE%B9%E5%99%A8/</url>
    <content><![CDATA[<p>##什么是容器<br>  在云计算或者说虚拟机普及的过程中，用户常常会问虚拟机是什么？虚拟机有什么优势？性能如何？她是如何提高硬件利用率？。。。当然我们会给客户解释CPU与内存虚拟化、资源超分配、分布式存储等等概念。到现在，虚拟机完全被普及，虚拟机带来的优势适合诸多业务场景，逐渐打消了人们对虚拟机的各种疑虑。那么，被不少激进的IT人宣称的，会替代虚拟机的容器又是什么呢？<br>   网上许多关于容器的介绍都是针对docker，其实容器并不是docker，docker只是容器技术的一种实现，或者说是就是把容器的管理以命令行的方式呈现出来。之前有个老外写了篇100行Golang代码实现容器（<a href="https://www.infoq.com/articles/build-a-container-golang%EF%BC%89%EF%BC%8C" target="_blank" rel="noopener">https://www.infoq.com/articles/build-a-container-golang），</a><br>   基于这个代码实现的容器，更能体现容器技术的本质，容器的核心应该是三个方面：</p>
<ol>
<li>命名空间：隔离，容器内的应用只能看到该容器内的资源（用户信息、进程信息，网络信息、挂载信息等）</li>
<li>Cgroup：为不同的容器提供资源限制，定义容器对宿主机资源（CPU、内存等）的最大使用量。</li>
<li>分层文件系统：基于写时复制(COW)、联合挂载的文件系统，为容器提供文件系统<br>再来看一下，以docker（Moby）为代表的容器，官方的描述：   <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A container image is a lightweight, stand-alone, executable package of a piece of software that includes everything needed to run it: code, runtime, system tools, system libraries, settings. Available for both Linux and Windows based apps, containerized software will always run the same, regardless of the environment. Containers isolate software from its surroundings, for example differences between development and staging environments and help reduce conflicts between teams running different software on the same infrastructure.</span><br></pre></td></tr></table></figure>
翻译一下：<br><br> &nbsp;&nbsp;  容器镜像是一个轻量级、独立、可执行软件的打包，这个包内包含了需要运行该软件的代码、运行环境、系统工具、系统库、配置。基于Linux和Windows的应用，容器化后的软件可以运行在windows或者Linux，无需感知环境的变化。容器将软件与其他不想关的资源隔离，例如不区分开发环境、演示环境，减少不同团队在相同基础环境运行不同软件带来的冲突<br>##容器与镜像</li>
</ol>
<p>参考下面最经典的docker技术架构图。 <br><br><img src="/2020/09/08/%E8%B0%88Docker%E5%AE%B9%E5%99%A8/docker.png" alt="BP"></p>
<p>###按照这幅图上的3个命令梳理一下</p>
<ol>
<li><p>docker build<br>如前文所说，docker只是把容器管理以命令行的方式呈现，docker对容器生态最大的贡献是他的镜像（Image）<br><br>容器镜像可以认为一个应用+运行环境的模板，和虚拟机模板类似，但是与虚拟机模板不同的是：这个镜像一般比较小，通常只是包含应用的执行文件以及特定的运行环境，不会包含操作系统的文件，制作镜像是需要定义一个描述镜像内容的描述文件就OK了，docker里面叫做dockerfile，不会像虚拟机模板那样，需要在虚拟化环境上进行一次操作系统安装，<br><br>镜像是平台无关的，平台无关就是制作了一次镜像，可以运行在windows、linux、阿里云、Vmware、华为云等等，不像虚拟机，你在阿里云上制作的虚拟机模板只能在阿里云使用，在AWS上制作的虚拟机模板只能在AWS使用。容器镜像的平台无关性是容器发展迅速的重要原因，这个特性解放了应用开发商与服务开发商，也让平台提供商有了新的发展方向。<br><br>回到这条命令上来，通常我们执行docker build 是需要编写dockerfile文件，如下所示，是制作大数据Ambari Server镜像的dockerfile文件</p>
<p><img src="/2020/09/08/%E8%B0%88Docker%E5%AE%B9%E5%99%A8/dockerfile.png" alt="avatar"></p>
<p><br>当定义了这个dockerfile后，在命令行执行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">   docker build . -t ambari-server:1.0</span><br><span class="line">&#96;&#96;&#96;&#96;  </span><br><span class="line">&amp;nbsp;&amp;nbsp; 就可以获取到我们制作的容器镜像了，制作完成后，只是放在了本地机器上了，需要执行一个命令</span><br></pre></td></tr></table></figure>
<p>docker push  ambari-server:1.0 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">将镜像保存到镜像仓库（registry），这样其他主机才能使用到该镜像</span><br><span class="line"></span><br><span class="line">  2. docker pull</span><br><span class="line">    </span><br><span class="line">   这个命令就是在主机上将容器镜像从镜像仓库下载下来，实现了镜像的远程获取、分发能力。这个镜像下载并不是全量下载，而是只是把该主机上缺少的镜像下载下来，这里就涉及到容器镜像的分层特性，这里就不展开说了。</span><br><span class="line">     </span><br><span class="line">  3. docker run：</span><br><span class="line"></span><br><span class="line">那么容器是如何从镜像变为容器呢，我们只需要执行docker run 命令</span><br></pre></td></tr></table></figure>
<p>docker run -itd  ambari-server:1.0  bash</p>
<pre><code>执行这个命令后，
1、docker 会在宿主机上分配一个目录，将镜像的文件挂载到这个目录2  &lt;br /&gt;
2、docker会在docker Daemon进程上fork出一个子进程，这个子进程是命名空间隔离的，你在容器内看不到宿主机的信息  &lt;br /&gt;
3、docker会为这个容器分配IP地址  &lt;br /&gt;
</code></pre>
</li>
</ol>
<p>登录到这个容器后，你看到的进程信息和网络信息如下<br> <img src="/2020/09/08/%E8%B0%88Docker%E5%AE%B9%E5%99%A8/net1.png" alt="avatar"></p>
<p><img src="/2020/09/08/%E8%B0%88Docker%E5%AE%B9%E5%99%A8/net2.png" alt="avatar"></p>
<p>##容器与应用</p>
<p>   虚拟机强调资源的分配的管理，而容器更强调对应用的管理，随着容器的出现，容器逐渐开始影响软件架构。与虚拟机相比，容器有哪些优势？可以看下表的对比分析<br>    上表的对比一般都是各个容器厂商的宣传卖点，容器为应用真正带来了哪些？或者说应用的哪些需求推动了容器的普及？<br>###应用部署<br>   容器为应用部署带来的变化主要体现在开发环境、测试环境、生产环境的一致性上，依赖于docker的镜像，在应用开发完成后，架构师就可以定义应用的镜像，这个镜像里面包含了应用的运行环境（Tomcat、JDK、Nginx等），也包含了应用的可执行文件（War文件、Jar文件等），将之前需要在项目现场做的工作交由最熟悉的架构师完成，交付人员在项目现场只需要执行一个简单的docker run命令就可以了。<br>###应用迁移<br>   将应用部署在虚拟机时，应用迁移一般有两种方式<br>   a.将应用所在的虚拟机以虚拟机模板的方式导出，如果是跨云的话，还需要做虚拟机模板的格式转化，将虚拟机模板再导入到另一个云环境,然后再去修改各种参数配置<br>   <br>b.虚拟机模板格式无法转化（例如从AWS迁移到阿里云），这时只能重新部署了。<br>      如果你使用容器转载你的应用，既不会存在这样的问题了，容器镜像与容器技术属于平台无关性，只要把镜像复制过去，然后启动容器就OK了。<br>###应用升级：<br>  应用升级对于复杂的系统是个很棘手的事情，升级前需要做备份，升级失败要做恢复，有了容器就简单多了，停掉旧版本的容器，启动新版本的容器，升级失败，只需要停掉新版本容器，启动旧版本容器就可以了。<br>       在IT领域，最重要的就是应用，或者说一个新的名词-SAAS，无论云计算、大数据还是机器学习，这些其实都是为应用提供支撑，让应用更好的运维、让应用更好的呈现数据价值、让应用能够进化到自我学习等。云计算的PAAS，其实就是为应用提供多种支撑的，只是由于多种因素，PAAS一直不温不火。。直到容器的出现，容器是为应用而生，更进一步说，容器是云时代的应用载体。</p>
<p>，</p>
]]></content>
  </entry>
  <entry>
    <title>Discuz 论坛评论回复代码</title>
    <url>/2020/09/21/Discuz-%E8%AE%BA%E5%9D%9B%E8%AF%84%E8%AE%BA%E5%9B%9E%E5%A4%8D%E4%BB%A3%E7%A0%81/</url>
    <content><![CDATA[<p>         本来想着刷下积分，换点礼品，结果居然好有限制。附上代码。更新代码，增加摇一摇赚取浪花的功能。找了台服务器，摇浪花啦。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#-\*-coding:utf-8-\*-</span><br><span class="line">import urllib2, urllib, cookielib</span><br><span class="line">import re</span><br><span class="line">import getpass</span><br><span class="line">import sqlite3</span><br><span class="line">import urlparse</span><br><span class="line">import random</span><br><span class="line">import time</span><br><span class="line">import PyV8</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">class Discuz:</span><br><span class="line">    def \_\_init\_\_(self,user,pwd,args):</span><br><span class="line">        self.username &#x3D; user</span><br><span class="line">        self.password &#x3D; pwd</span><br><span class="line">        self.args &#x3D; args</span><br><span class="line">        self.regex &#x3D; &#123;</span><br><span class="line">            &#39;loginreg&#39;:&#39;&lt;input\\s\*type&#x3D;&quot;hidden&quot;\\s\*name&#x3D;&quot;formhash&quot;\\s\*value&#x3D;&quot;(\[\\w\\W\]+?)&quot;\\s\*\\&#x2F;&gt;&#39;,</span><br><span class="line">            #input type&#x3D;&quot;hidden&quot; name&#x3D;&quot;formhash&quot; value&#x3D;&quot;7f420ac4&quot;</span><br><span class="line">            &#39;replyreg&#39;:&#39;&lt;input\\s\*type&#x3D;&quot;hidden&quot;\\s\*name&#x3D;&quot;formhash&quot;\\s\*value&#x3D;&quot;(\[\\w\\W\]+?)&quot;\\s\*\\&#x2F;&gt;&#39;,</span><br><span class="line">            &#39;tidreg&#39;: &#39;&lt;tbody\\s\*id&#x3D;&quot;normalthread\_\\d+&quot;&gt;\[\\s\\S\]+?&lt;span\\s\*id&#x3D;&quot;thread\_(\\d+)&quot;&gt;&#39;,</span><br><span class="line">            &#39;subform&#39;:&#39;&lt;a href&#x3D;&quot;forum.php\\?mod&#x3D;forumdisplay&amp;fid&#x3D;\\d+&quot;&gt;\\S+&lt;&#x2F;a&gt;&#39;,</span><br><span class="line">            &#39;topidreg&#39;:&#39;&lt;a href&#x3D;&quot;forum.php\\?mod&#x3D;viewthread&amp;tid&#x3D;\\d+&amp;extra&#x3D;page%3D1&quot; onclick&#x3D;&quot;atarget\\(this\\)&quot; class&#x3D;&quot;s xst&quot;&gt;\\S+&lt;&#x2F;a&gt;&#39;</span><br><span class="line">        &#125;</span><br><span class="line">        self.subform&#x3D;\[&#39;OpenStack&#39;,u&#39;云服务&#39;,u&#39;云管理&#39;,&#39;hadoop&#39;,&#39;storm&#39;,&#39;spark&#39;\]</span><br><span class="line">        self.conn &#x3D; None</span><br><span class="line">        self.cur &#x3D; None</span><br><span class="line">        self.islogin &#x3D; False</span><br><span class="line">        self.login()</span><br><span class="line">        self.InitDB()</span><br><span class="line"></span><br><span class="line">    def login(self):</span><br><span class="line">        try:</span><br><span class="line">            loginPage &#x3D; urllib2.urlopen(self.args\[&#39;loginurl&#39;\]).read()</span><br><span class="line">            print &#39;start login...&#39;</span><br><span class="line">            cj &#x3D; cookielib.CookieJar()</span><br><span class="line">            opener &#x3D; urllib2.build\_opener(urllib2.HTTPCookieProcessor(cj))</span><br><span class="line">            user\_agent &#x3D; &#39;Mozilla&#x2F;4.0 (compatible; MSIE 6.0; Windows NT 5.1; Mozilla&#x2F;4.0 \\</span><br><span class="line">                    (compatible; MSIE 6.0; Windows NT 5.1; SV1) ; .NET CLR 2.0.507&#39;</span><br><span class="line">            opener.addheaders &#x3D; \[(&#39;User-agent&#39;, user\_agent)\]</span><br><span class="line">            urllib2.install\_opener(opener)</span><br><span class="line">            logindata &#x3D; urllib.urlencode(&#123;</span><br><span class="line">                &#39;cookietime&#39;:    2592000,</span><br><span class="line">               # &#39;formhash&#39;: formhash,</span><br><span class="line">                &#39;loginfield&#39;:&#39;username&#39;,</span><br><span class="line">                &#39;username&#39;:    self.username,</span><br><span class="line">                &#39;password&#39;:    self.password,</span><br><span class="line">                &#39;quickforward&#39;:    &#39;yes&#39;,</span><br><span class="line">                &#39;fastloginfield&#39;:&#39;username&#39;,</span><br><span class="line">                &#39;handlekey&#39;:&#39;ls&#39;,</span><br><span class="line">                &#39;referer&#39;: self.args\[&#39;referer&#39;\]</span><br><span class="line">                &#125;)</span><br><span class="line"></span><br><span class="line">            request &#x3D; urllib2.Request(self.args\[&#39;loginsubmiturl&#39;\],logindata)</span><br><span class="line">            response &#x3D; urllib2.urlopen(request)</span><br><span class="line">            self.islogin &#x3D; True</span><br><span class="line">            print &#39;login success...&#39;</span><br><span class="line">        except Exception,e:</span><br><span class="line">                print &#39;loggin error: %s&#39; % e</span><br><span class="line"></span><br><span class="line">    def PostReply(self, fid, tid, topicUrl,content):</span><br><span class="line">        try:</span><br><span class="line">            if self.islogin:</span><br><span class="line">                temp&#x3D;self.args\[&#39;replysubmiturl&#39;\]</span><br><span class="line">                replysubmiturl &#x3D; temp %(fid,tid)</span><br><span class="line">                response &#x3D; urllib2.urlopen(topicUrl)</span><br><span class="line">                content11 &#x3D; response.read()</span><br><span class="line">               # print content11</span><br><span class="line">                # update url</span><br><span class="line">                url&#x3D;self.getNewUrlFromJs(content11);</span><br><span class="line">                newTopicUrl&#x3D; self.args\[&#39;redirectBaseUrl&#39;\]+url</span><br><span class="line">                response &#x3D; urllib2.urlopen(newTopicUrl)</span><br><span class="line">                content11 &#x3D; response.read()</span><br><span class="line">                formhashs &#x3D; re.search(self.regex\[&#39;replyreg&#39;\], content11)</span><br><span class="line">                formhash&#x3D; formhashs.group(1)</span><br><span class="line">                print formhash</span><br><span class="line">                replydata &#x3D; urllib.urlencode(&#123;</span><br><span class="line">                    &#39;formhash&#39;: formhash,</span><br><span class="line">                    &#39;message&#39;: content,</span><br><span class="line">                    &#39;subject&#39;: &#39;&#39;,</span><br><span class="line">                    &#39;usesig&#39;:&#39;1&#39;</span><br><span class="line">                &#125;)</span><br><span class="line">                request &#x3D; urllib2.Request(replysubmiturl,replydata)</span><br><span class="line">                response &#x3D; urllib2.urlopen(request)</span><br><span class="line">                print &#39;reply success for \[%s\]&#39; % topicUrl</span><br><span class="line">            else:</span><br><span class="line">                print &#39;user not login&#39;</span><br><span class="line">        except Exception, e:</span><br><span class="line">                print &#39;reply error: %s&#39; % e</span><br><span class="line"></span><br><span class="line">    def GetSubForms(self):</span><br><span class="line">        if self.islogin:</span><br><span class="line">            fidurl &#x3D; self.args\[&#39;fidurl&#39;\]</span><br><span class="line">            response &#x3D; urllib2.urlopen(fidurl)</span><br><span class="line">            content &#x3D; response.read()</span><br><span class="line">            soup &#x3D; BeautifulSoup(content,&quot;html.parser&quot;)</span><br><span class="line">            h1userSoupList&#x3D;soup.findAll(name&#x3D;&quot;a&quot;, attrs&#x3D;&#123;&quot;href&quot;:re.compile(r&quot;forum.php\\?mod&#x3D;forumdisplay&amp;fid&#x3D;\\d+&quot;)&#125;)</span><br><span class="line">            subformDicts&#x3D;&#123;&#125;</span><br><span class="line">            for subform in h1userSoupList:</span><br><span class="line">                if subform.get\_text() in self.subform:</span><br><span class="line">                   # subforms.append(self.args\[&#39;baseUrl&#39;\]+subform\[&quot;href&quot;\])</span><br><span class="line">                    url&#x3D;self.args\[&#39;baseUrl&#39;\]+subform\[&quot;href&quot;\]</span><br><span class="line">                    result&#x3D;urlparse.urlparse(url)</span><br><span class="line">                    params&#x3D;urlparse.parse\_qs(result.query,True)</span><br><span class="line">                    tag&#x3D; params\[&#39;fid&#39;\]\[0\]</span><br><span class="line">                    subformDicts\[tag\]&#x3D;url</span><br><span class="line">            return subformDicts</span><br><span class="line">        else:</span><br><span class="line">            print &#39;Error Please Login...&#39;</span><br><span class="line"></span><br><span class="line">    def getNewUrlFromJs(self,js):</span><br><span class="line">       js&#x3D;js\[31:-9\]</span><br><span class="line">       for st in \[&#39;window&#39;,&#39;location&#39;,&quot;&#39;assign&#39;&quot;,&quot;&#39;href&#39;&quot;,&quot;&#39;replace&#39;&quot;\]:</span><br><span class="line">            equal&#x3D;re.findall(&#39;\[\_A-Za-z0-9 &#x3D;\]+%s;&#39;%st,js)</span><br><span class="line">            if equal&#x3D;&#x3D;\[\]:</span><br><span class="line">                continue</span><br><span class="line">            else:</span><br><span class="line">               equal&#x3D;equal\[0\]</span><br><span class="line">               var&#x3D;equal.split(&#39;&#x3D;&#39;)\[0\].strip()</span><br><span class="line">               js&#x3D;js.replace(equal,&#39;&#39;)</span><br><span class="line">               js&#x3D;js.replace(var,st)</span><br><span class="line">               js&#x3D;js.replace(&quot;\[&#39;%s&#39;\]&quot;%st.strip(&quot;&#39;&quot;),&#39;.%s&#39;%st.strip(&quot;&#39;&quot;))</span><br><span class="line">       if re.findall(&#39;window\\.href&#x3D;.+&#39;,js)!&#x3D;\[\]:</span><br><span class="line">           js&#x3D;js.replace(re.findall(&#39;window\\.href&#x3D;.+&#39;,js)\[0\],&#39;&#39;)</span><br><span class="line">       js&#x3D;js.replace(&#39;location.href&#x3D;&#39;,&#39;&#39;).replace(&#39;location.replace&#39;,&#39;&#39;).replace(&#39;location.assign&#39;,&#39;&#39;)</span><br><span class="line">       ctxt2 &#x3D; PyV8.JSContext()</span><br><span class="line">       ctxt2.enter()</span><br><span class="line">       return ctxt2.eval(js)</span><br><span class="line"></span><br><span class="line">    def haveAGoodLuck(self):</span><br><span class="line">        luckurl&#x3D;&#39;http:&#x2F;&#x2F;bbs.iop365.com&#x2F;iop&#x2F;&#x2F;plugin.php?id&#x3D;yinxingfei\_zzza:yinxingfei\_zzza\_hall&amp;yjjs&#x3D;yes&#39;</span><br><span class="line">        response &#x3D; urllib2.urlopen(luckurl)</span><br><span class="line">        content &#x3D; response.read()</span><br><span class="line">        formhashs &#x3D; re.search(self.regex\[&#39;replyreg&#39;\], content)</span><br><span class="line">        formhash&#x3D; formhashs.group(1)</span><br><span class="line">        soup &#x3D; BeautifulSoup(content,&quot;html.parser&quot;)</span><br><span class="line">        submitUrl2&#x3D;&#39;http:&#x2F;&#x2F;bbs.iop365.com&#x2F;iop&#x2F;&#x2F;plugin.php?id&#x3D;yinxingfei\_zzza:yinxingfei\_zzza\_post&#39;</span><br><span class="line">        replydata &#x3D; urllib.urlencode(&#123;</span><br><span class="line">                    &#39;formhash&#39;: formhash</span><br><span class="line">                &#125;)</span><br><span class="line">        request &#x3D; urllib2.Request(submitUrl2,replydata)</span><br><span class="line">        response &#x3D; urllib2.urlopen(request)</span><br><span class="line"> </span><br><span class="line">    def visitUser(self):</span><br><span class="line">        baseUrl&#x3D;&#39;http:&#x2F;&#x2F;bbs.iop365.com&#x2F;iop&#x2F;?%s&#39;</span><br><span class="line">        for i in range(1,10):</span><br><span class="line">            randNum&#x3D;random.randint(1, 200)</span><br><span class="line">            visitUrl&#x3D;baseUrl %(randNum)</span><br><span class="line">            response &#x3D; urllib2.urlopen(visitUrl)</span><br><span class="line">            content &#x3D; response.read()</span><br><span class="line">            print visitUrl</span><br><span class="line">    def InitDB(self):</span><br><span class="line">        self.conn &#x3D; sqlite3.connect(&#39;data.db&#39;)</span><br><span class="line">        self.cur &#x3D; self.conn.cursor()</span><br><span class="line">        sql &#x3D; &#39;&#39;&#39;create table if not exists post (</span><br><span class="line">            fid text,</span><br><span class="line">            tid text,</span><br><span class="line">            replied integer)&#39;&#39;&#39;</span><br><span class="line">        self.cur.execute(sql)</span><br><span class="line">        self.conn.commit()</span><br><span class="line"></span><br><span class="line">    def getTopicList(self,sunFormUrl):</span><br><span class="line">         topicDis&#x3D;&#123;&#125;</span><br><span class="line">         if self.islogin:</span><br><span class="line">            fidurl &#x3D; sunFormUrl</span><br><span class="line">            response &#x3D; urllib2.urlopen(fidurl)</span><br><span class="line">            content &#x3D; response.read()</span><br><span class="line">            soup &#x3D; BeautifulSoup(content,&quot;html.parser&quot;)</span><br><span class="line">            h1userSoupList&#x3D;soup.findAll(name&#x3D;&quot;a&quot;, attrs&#x3D;&#123;&quot;href&quot;: re.compile(r&quot;forum.php\\?mod&#x3D;viewthread\\&amp;&quot;),&quot;onclick&quot;:&quot;atarget(this)&quot;&#125;)</span><br><span class="line">            for topic in h1userSoupList:</span><br><span class="line">                 #topics.append(self.args\[&#39;baseUrl&#39;\]+topic\[&quot;href&quot;\])</span><br><span class="line">                 url&#x3D;self.args\[&#39;baseUrl&#39;\]+topic\[&quot;href&quot;\]</span><br><span class="line">                 result&#x3D;urlparse.urlparse(url)</span><br><span class="line">                 params&#x3D;urlparse.parse\_qs(result.query,True)</span><br><span class="line">                 topicDis\[params\[&#39;tid&#39;\]\[0\]\]&#x3D;url</span><br><span class="line">            return topicDis</span><br><span class="line">         else:</span><br><span class="line">             print &#39;user doest not login&#39;</span><br><span class="line"></span><br><span class="line">if \_\_name\_\_ &#x3D;&#x3D; &#39;\_\_main\_\_&#39;:</span><br><span class="line">    #username &#x3D; raw\_input(&#39;username:&#39;).strip()</span><br><span class="line">    #password &#x3D; getpass.getpass(&#39;password:&#39;).strip()</span><br><span class="line">    args &#x3D; &#123;</span><br><span class="line">            &#39;loginurl&#39;: &#39;http:&#x2F;&#x2F;bbs.iop365.com&#x2F;forum.php&#39;,</span><br><span class="line">            &#39;loginsubmiturl&#39;: &#39;http:&#x2F;&#x2F;bbs.iop365.com&#x2F;iop&#x2F;member.php?mod&#x3D;logging&amp;action&#x3D;login&amp;loginsubmit&#x3D;yes&amp;infloat&#x3D;yes&amp;lssubmit&#x3D;yes&amp;inajax&#x3D;1&#39;,</span><br><span class="line">            &#39;fidurl&#39;: &#39;http:&#x2F;&#x2F;bbs.iop365.com&#x2F;iop&#x2F;forum.php&#39;,</span><br><span class="line">            &#39;tidurl&#39;: &#39;http:&#x2F;&#x2F;bbs.iop365.com&#x2F;thread-%s-1-1.html&#39;,</span><br><span class="line">            &#39;replysubmiturl&#39;: &#39;http:&#x2F;&#x2F;bbs.iop365.com&#x2F;iop&#x2F;&#x2F;forum.php?mod&#x3D;post&amp;action&#x3D;reply&amp;fid&#x3D;%s&amp;tid&#x3D;%s&amp;extra&#x3D;&amp;replysubmit&#x3D;yes&amp;infloat&#x3D;yes&amp;handlekey&#x3D;fastpost&amp;inajax&#x3D;1&#39;,</span><br><span class="line">            &#39;referer&#39;:&#39;http:&#x2F;&#x2F;bbs.iop365.com&#x2F;forum.php&#39; ,</span><br><span class="line">            &#39;baseUrl&#39;:&#39;http:&#x2F;&#x2F;bbs.iop365.com&#x2F;iop&#x2F;&#39;,</span><br><span class="line">             &#39;redirectBaseUrl&#39;: &#39;http:&#x2F;&#x2F;bbs.iop365.com&#x2F;&#39;&#125;</span><br><span class="line">    userInfo&#x3D;&#123;&#39;wangdk&#39;:&#39;\*\*\*\*&#39;&#125;</span><br><span class="line">    for (username,password) in userInfo.items():</span><br><span class="line">        dz &#x3D; Discuz(username, password,args)</span><br><span class="line">        subforms &#x3D; dz.GetSubForms()</span><br><span class="line">        dz.visitUser()</span><br><span class="line">        topicNum&#x3D;0</span><br><span class="line">        allTopics&#x3D;&#123;&#125;</span><br><span class="line">        for fid in subforms:</span><br><span class="line">          topics&#x3D;dz.getTopicList(subforms\[fid\])</span><br><span class="line">          for tid in topics:</span><br><span class="line">               topicNum&#x3D;topicNum+1</span><br><span class="line">               allTopics\[topicNum\]&#x3D;&#123;&#39;fid&#39;:fid,&#39;tid&#39;:tid,&#39;topicUrl&#39;:topics\[tid\]&#125;</span><br><span class="line">        randNum&#x3D;random.randint(1, topicNum)</span><br><span class="line">        print  &#39;good luck time&#x3D;%s&#39;,time.strftime( &quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime() )</span><br><span class="line">        dz.PostReply(allTopics\[randNum\]\[&#39;fid&#39;\],allTopics\[randNum\]\[&#39;tid&#39;\],allTopics\[randNum\]\[&#39;topicUrl&#39;\],&#39;guanshui,haha&#39;)</span><br><span class="line">        print &#39;topicUrl %s&#39;,allTopics\[randNum\]\[&#39;topicUrl&#39;\]</span><br><span class="line">        dz.haveAGoodLuck()</span><br></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title>docker精简镜像</title>
    <url>/2020/09/21/Docker%E7%B2%BE%E7%AE%80%E9%95%9C%E5%83%8F/</url>
    <content><![CDATA[<h3 id="精简docker镜像大小的必要性"><a href="#精简docker镜像大小的必要性" class="headerlink" title="精简docker镜像大小的必要性"></a>精简docker镜像大小的必要性</h3><p>docker镜像由很多镜像层（Layers）组成（最多127层），镜像层依赖于一系列的底层技术，比如文件系统(filesystems)、写时复制(copy-on-write)、联合挂载(union mounts)等技术，你可以查看docker社区文档以了解更多有关docker存储驱动的内容，这里就不再赘述技术细节。总的来说，dockerfile中的每条指令都会创建一个镜像层，继而会增加整体镜像的尺寸。 下面是精简docker镜像尺寸的好处： 1. 减少构建时间 2. 减少磁盘使用量 3. 减少下载时间 4. 因为包含文件少，攻击面减小，提高了安全性 5. 提高部署速度</p>
<h3 id="五点建议减小docker镜像尺寸"><a href="#五点建议减小docker镜像尺寸" class="headerlink" title="五点建议减小docker镜像尺寸"></a>五点建议减小docker镜像尺寸</h3><h3 id="优化基础镜像"><a href="#优化基础镜像" class="headerlink" title="优化基础镜像"></a>优化基础镜像</h3><p>优化基础镜像的方法就是选用合适的更小的基础镜像，常用的 Linux 系统镜像一般有 Ubuntu、CentOs、Alpine，其中Alpine更推荐使用。大小对比如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">lynzabo@ubuntu ~&#x2F;s&gt; docker images</span><br><span class="line">REPOSITORY         TAG             IMAGE ID            CREATED             SIZE</span><br><span class="line">ubuntu             latest        74f8760a2a8b        8 days ago          82.4MB</span><br><span class="line">alpine             latest        11cd0b38bc3c        2 weeks ago         4.41MB</span><br><span class="line">centos               7           49f7960eb7e4        7 weeks ago         200MB</span><br><span class="line">debian             latest        3bbb526d2608        8 days ago          101MB</span><br><span class="line">lynzabo@ubuntu ~&#x2F;s&gt;</span><br></pre></td></tr></table></figure>
<p>Alpine是一个高度精简又包含了基本工具的轻量级Linux发行版，基础镜像只有4.41M，各开发语言和框架都有基于Alpine制作的基础镜像，强烈推荐使用它。Alpine镜像各个语言和框架支持情况，可以参考《优化docker镜像、加速应用部署，教你6个小窍门》。 查看上面的镜像尺寸对比结果，你会发现最小的镜像也有4.41M，那么有办法构建更小的镜像吗？答案是肯定的，例如 gcr.io/google_containers/pause-amd64:3.1 镜像仅有742KB。为什么这个镜像能这么小？在为大家解密之前，再推荐两个基础镜像： 1、scratch镜像 scratch是一个空镜像，只能用于构建其他镜像，比如你要运行一个包含所有依赖的二进制文件，如Golang程序，可以直接使用scratch作为基础镜像。现在给大家展示一下上文提到的Google pause镜像dockerfile：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM scratch</span><br><span class="line">ARG ARCH</span><br><span class="line">ADD bin&#x2F;pause-$&#123;ARCH&#125; &#x2F;pause</span><br><span class="line">ENTRYPOINT [&quot;&#x2F;pause&quot;]</span><br></pre></td></tr></table></figure>
<p>Google pause镜像使用了scratch作为基础镜像，这个镜像本身是不占空间的，使用它构建的镜像大小几乎和二进制文件本身一样大，所以镜像非常小。当然在我们的Golang程序中也会使用。对于一些Golang/C程序，可能会依赖一些动态库，你可以使用自动提取动态库工具，比如ldd、linuxdeployqt等提取所有动态库，然后将二进制文件和依赖动态库一起打包到镜像中。 2、busybox镜像 scratch是个空镜像，如果希望镜像里可以包含一些常用的Linux工具，busybox镜像是个不错选择，镜像本身只有1.16M，非常便于构建小镜像。</p>
<h4 id="串联-dockerfile-指令"><a href="#串联-dockerfile-指令" class="headerlink" title="串联 dockerfile 指令"></a>串联 dockerfile 指令</h4><p>大家在定义dockerfile时，如果太多的使用RUN指令，经常会导致镜像有特别多的层，镜像很臃肿，而且甚至会碰到超出最大层数（127层）限制的问题，遵循 dockerfile 最佳实践，我们应该把多个命令串联合并为一个 RUN（通过运算符&amp;&amp;和/ 来实现），每一个 RUN 要精心设计，确保安装构建最后进行清理，这样才可以降低镜像体积，以及最大化的利用构建缓存。 下面是一个优化前dockerfile：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM ubuntu</span><br><span class="line"></span><br><span class="line">ENV VER     3.0.0  </span><br><span class="line">ENV TARBALL http:&#x2F;&#x2F;download.redis.io&#x2F;releases&#x2F;redis-$VER.tar.gz  </span><br><span class="line"># &#x3D;&#x3D;&gt; Install curl and helper tools...</span><br><span class="line">RUN apt-get update  </span><br><span class="line">RUN apt-get install -y  curl make gcc  </span><br><span class="line"># &#x3D;&#x3D;&gt; Download, compile, and install...</span><br><span class="line">RUN curl -L $TARBALL | tar zxv  </span><br><span class="line">WORKDIR  redis-$VER  </span><br><span class="line">RUN make  </span><br><span class="line">RUN make install  </span><br><span class="line">#...</span><br><span class="line"># &#x3D;&#x3D;&gt; Clean up...</span><br><span class="line">WORKDIR &#x2F;  </span><br><span class="line">RUN apt-get remove -y --auto-remove curl make gcc  </span><br><span class="line">RUN apt-get clean  </span><br><span class="line">RUN rm -rf &#x2F;var&#x2F;lib&#x2F;apt&#x2F;lists&#x2F;*  &#x2F;redis-$VER  </span><br><span class="line">#...</span><br><span class="line">CMD [&quot;redis-server&quot;]</span><br></pre></td></tr></table></figure>
<p>构建镜像，名称叫 test/test:0.1。 我们对dockerfile做优化，优化后dockerfile：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM ubuntu</span><br><span class="line"></span><br><span class="line">ENV VER     3.0.0  </span><br><span class="line">ENV TARBALL http:&#x2F;&#x2F;download.redis.io&#x2F;releases&#x2F;redis-$VER.tar.gz</span><br><span class="line"></span><br><span class="line">RUN echo &quot;&#x3D;&#x3D;&gt; Install curl and helper tools...&quot;  &amp;&amp; \  </span><br><span class="line">    apt-get update                      &amp;&amp; \</span><br><span class="line">    apt-get install -y  curl make gcc   &amp;&amp; \</span><br><span class="line">    echo &quot;&#x3D;&#x3D;&gt; Download, compile, and install...&quot;  &amp;&amp; \</span><br><span class="line">    curl -L $TARBALL | tar zxv  &amp;&amp; \</span><br><span class="line">    cd redis-$VER               &amp;&amp; \</span><br><span class="line">    make                        &amp;&amp; \</span><br><span class="line">    make install                &amp;&amp; \</span><br><span class="line">    echo &quot;&#x3D;&#x3D;&gt; Clean up...&quot;  &amp;&amp; \</span><br><span class="line">    apt-get remove -y --auto-remove curl make gcc  &amp;&amp; \</span><br><span class="line">    apt-get clean                                  &amp;&amp; \</span><br><span class="line">    rm -rf &#x2F;var&#x2F;lib&#x2F;apt&#x2F;lists&#x2F;*  &#x2F;redis-$VER</span><br><span class="line">#...</span><br><span class="line">CMD [&quot;redis-server&quot;]</span><br></pre></td></tr></table></figure>
<p>构建镜像，名称叫 test/test:0.2。 对比两个镜像大小：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@k8s-master:&#x2F;tmp&#x2F;iops# docker images</span><br><span class="line">REPOSITORY       TAG           IMAGE ID            CREATED             SIZE</span><br><span class="line">test&#x2F;test        0.2         58468c0222ed        2 minutes ago       98.1MB</span><br><span class="line">test&#x2F;test        0.1         e496cf7243f2        6 minutes ago       307MB</span><br><span class="line">root@k8s-master:&#x2F;tmp&#x2F;iops#</span><br></pre></td></tr></table></figure>
<p>可以看到，将多条RUN命令串联起来构建的镜像大小是每条命令分别RUN的三分之一。 提示：为了应对镜像中存在太多镜像层，docker 1.13版本以后，提供了一个压扁镜像功能，即将 dockerfile 中所有的操作压缩为一层。这个特性还处于实验阶段，docker默认没有开启，如果要开启，需要在启动docker时添加-experimental 选项，并在docker build 构建镜像时候添加 –squash 。我们不推荐使用这个办法，请在撰写 dockerfile 时遵循最佳实践编写，不要试图用这种办法去压缩镜像。</p>
<h4 id="使用多阶段构建"><a href="#使用多阶段构建" class="headerlink" title="使用多阶段构建"></a>使用多阶段构建</h4><p>dockerfile中每条指令都会为镜像增加一个镜像层，并且你需要在移动到下一个镜像层之前清理不需要的组件。实际上，有一个dockerfile用于开发（其中包含构建应用程序所需的所有内容）以及一个用于生产的瘦客户端，它只包含你的应用程序以及运行它所需的内容。这被称为“建造者模式”。docker 17.05.0-ce版本以后支持多阶段构建。使用多阶段构建，你可以在dockerfile中使用多个FROM语句，每条FROM指令可以使用不同的基础镜像，这样您可以选择性地将服务组件从一个阶段COPY到另一个阶段，在最终镜像中只保留需要的内容。 下面是一个使用COPY –from 和 FROM … AS … 的dockerfile：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Compile</span><br><span class="line">FROM golang:1.9.0 AS builder</span><br><span class="line">WORKDIR &#x2F;go&#x2F;src&#x2F;v9.git...com&#x2F;...&#x2F;k8s-monitor</span><br><span class="line">COPY . .</span><br><span class="line">WORKDIR &#x2F;go&#x2F;src&#x2F;v9.git...com&#x2F;...&#x2F;k8s-monitor</span><br><span class="line">RUN make build</span><br><span class="line">RUN mv k8s-monitor &#x2F;root</span><br><span class="line"></span><br><span class="line"># Package</span><br><span class="line"># Use scratch image</span><br><span class="line">FROM scratch</span><br><span class="line">WORKDIR &#x2F;root&#x2F;</span><br><span class="line">COPY --from&#x3D;builder &#x2F;root .</span><br><span class="line">EXPOSE 8080</span><br><span class="line">CMD [&quot;&#x2F;root&#x2F;k8s-monitor&quot;]</span><br></pre></td></tr></table></figure>
<p>构建镜像，你会发现生成的镜像只有上面COPY 指令指定的内容，镜像大小只有2M。这样在以前使用两个dockerfile（一个dockerfile用于开发和一个用于生产的瘦客户端），现在使用多阶段构建就可以搞定。</p>
<h4 id="业务服务镜像技巧"><a href="#业务服务镜像技巧" class="headerlink" title="业务服务镜像技巧"></a>业务服务镜像技巧</h4><p>docker在build镜像的时候，如果某个命令相关的内容没有变化，会使用上一次缓存（cache）的文件层，在构建业务镜像的时候可以注意下面两点： 不变或者变化很少的体积较大的依赖库和经常修改的自有代码分开； 因为cache缓存在运行docker build命令的本地机器上，建议固定使用某台机器来进行docker build，以便利用cache。 下面是构建Spring Boot应用镜像的例子，用来说明如何分层。其他类型的应用，比如Java WAR包，Nodejs的npm 模块等，可以采取类似的方式。 1、在dockerfile所在目录，解压缩maven生成的jar包</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ unzip &lt;path-to-app-jar&gt;.jar -d app</span><br></pre></td></tr></table></figure>
<p>2、dockerfile 我们把应用的内容分成4个部分COPY到镜像里面：其中前面3个基本不变，第4个是经常变化的自有代码。最后一行是解压缩后，启动spring boot应用的方式。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM openjdk:8-jre-alpine</span><br><span class="line"></span><br><span class="line">LABEL maintainer &quot;opl-xws@xiaomi.com&quot;</span><br><span class="line">COPY app&#x2F;BOOT-INF&#x2F;lib&#x2F; &#x2F;app&#x2F;BOOT-INF&#x2F;lib&#x2F;</span><br><span class="line">COPY app&#x2F;org &#x2F;app&#x2F;org</span><br><span class="line">COPY app&#x2F;META-INF &#x2F;app&#x2F;META-INF</span><br><span class="line">COPY app&#x2F;BOOT-INF&#x2F;classes &#x2F;app&#x2F;BOOT-INF&#x2F;classes</span><br><span class="line">EXPOSE 8080</span><br><span class="line">CMD [&quot;&#x2F;usr&#x2F;bin&#x2F;java&quot;, &quot;-cp&quot;, &quot;&#x2F;app&quot;, &quot;org.springframework.boot.loader.JarLauncher&quot;]</span><br></pre></td></tr></table></figure>
<p>这样在构建镜像时候可大大提高构建速度。 ###其他优化方法 1. RUN命令中执行apt、apk或者yum类工具技巧 如果在RUN命令中执行apt、apk或者yum类工具，可以借助这些工具提供的一些小技巧来减少镜像层数量及镜像大小。举几个例子： （1）在执行apt-get install -y 时增加选项— no-install-recommends ，可以不用安装建议性（非必须）的依赖，也可以在执行apk add 时添加选项–no-cache 达到同样效果； （2）执行yum install -y 时候， 可以同时安装多个工具，比如yum install -y gcc gcc-c++ make …。将所有yum install 任务放在一条RUN命令上执行，从而减少镜像层的数量； （3）组件的安装和清理要串联在一条指令里面，如 apk –update add php7 &amp;&amp; rm -rf /var/cache/apk/* ，因为dockerfile的每条指令都会产生一个文件层，如果将apk add … 和 rm -rf … 命令分开，清理无法减小apk命令产生的文件层的大小。 Ubuntu或Debian可以使用 rm -rf /<strong>var</strong>/lib/apt/lists/* 清理镜像中缓存文件；CentOS等系统使用yum clean all 命令清理。 2. 压缩镜像 docker 自带的一些命令还能协助压缩镜像，比如 export 和 import</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ docker run -d test&#x2F;test:0.2</span><br><span class="line">$ docker export 747dc0e72d13 | docker import - test&#x2F;test:0.3</span><br></pre></td></tr></table></figure>
<p>使用这种方式需要先将容器运行起来，而且这个过程中会丢失镜像原有的一些信息，比如：导出端口，环境变量，默认指令。 查看这两个镜像history信息，如下，可以看到test/test:0.3 丢失了所有的镜像层信息：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@k8s-master:&#x2F;tmp&#x2F;iops# docker history test&#x2F;test:0.3</span><br><span class="line">IMAGE               CREATED             CREATED BY          SIZE                COMMENT</span><br><span class="line">6fb3f00b7a72        15 seconds ago                          84.7MB              Imported from -</span><br><span class="line">root@k8s-master:&#x2F;tmp&#x2F;iops# docker history test&#x2F;test:0.2</span><br><span class="line">IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT</span><br><span class="line">58468c0222ed        2 hours ago         &#x2F;bin&#x2F;sh -c #(nop)  CMD [&quot;redis-server&quot;]         0B       </span><br><span class="line">1af7ffe3d163        2 hours ago         &#x2F;bin&#x2F;sh -c echo &quot;&#x3D;&#x3D;&gt; Install curl and helper…   15.7MB   </span><br><span class="line">8bac6e733d54        2 hours ago         &#x2F;bin&#x2F;sh -c #(nop)  ENV TARBALL&#x3D;http:&#x2F;&#x2F;downlo…   0B       </span><br><span class="line">793282f3ef7a        2 hours ago         &#x2F;bin&#x2F;sh -c #(nop)  ENV VER&#x3D;3.0.0                0B       </span><br><span class="line">74f8760a2a8b        8 days ago          &#x2F;bin&#x2F;sh -c #(nop)  CMD [&quot;&#x2F;bin&#x2F;bash&quot;]            0B       </span><br><span class="line">&lt;missing&gt;           8 days ago          &#x2F;bin&#x2F;sh -c mkdir -p &#x2F;run&#x2F;systemd &amp;&amp; echo &#39;do…   7B</span><br><span class="line">&lt;missing&gt;           8 days ago          &#x2F;bin&#x2F;sh -c sed -i &#39;s&#x2F;^#\s*\(deb.*universe\)$…   2.76kB</span><br><span class="line">&lt;missing&gt;           8 days ago          &#x2F;bin&#x2F;sh -c rm -rf &#x2F;var&#x2F;lib&#x2F;apt&#x2F;lists&#x2F;*          0B</span><br><span class="line">&lt;missing&gt;           8 days ago          &#x2F;bin&#x2F;sh -c set -xe   &amp;&amp; echo &#39;#!&#x2F;bin&#x2F;sh&#39; &gt; &#x2F;…   745B    </span><br><span class="line">&lt;missing&gt;           8 days ago          &#x2F;bin&#x2F;sh -c #(nop) ADD file:5fabb77ea8d61e02d…   82.4MB   </span><br><span class="line">root@k8s-master:&#x2F;tmp&#x2F;iops#</span><br></pre></td></tr></table></figure>
<p>社区里还有很多压缩工具，比如docker-squash ，用起来更简单方便，并且不会丢失原有镜像的自带信息，大家有兴趣可以试试。 转自<a href="https://mp.weixin.qq.com/s/blZt_jmHBprX9tzbyQRWIg" target="_blank" rel="noopener">米生态云</a></p>
]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes中的Source Ip机制</title>
    <url>/2020/09/21/Kubernetes%E4%B8%AD%E7%9A%84Source-Ip%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>你必须拥有一个正常工作的 Kubernetes 1.5 集群，用来运行本文中的示例。该示例使用一个简单的 nginx webserver 回送它接收到的请求的 HTTP 头中的源 IP 地址。你可以像下面这样创建它：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl run source-ip-app --image&#x3D;k8s.gcr.io&#x2F;echoserver:1.4</span><br><span class="line">deployment &quot;source-ip-app&quot; created</span><br></pre></td></tr></table></figure>

<h2 id="Type-ClusterIP-类型-Services-的-Source-IP"><a href="#Type-ClusterIP-类型-Services-的-Source-IP" class="headerlink" title="Type=ClusterIP 类型 Services 的 Source IP"></a>Type=ClusterIP 类型 Services 的 Source IP</h2><p>如果你的 kube-proxy 运行在 iptables 模式下，从集群内部发送到 ClusterIP 的包永远不会进行源地址 NAT，这从 Kubernetes 1.2 开始是默认选项。Kube-proxy 通过一个 proxyMode endpoint 暴露它的模式。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl get nodes</span><br><span class="line">NAME                           STATUS     AGE     VERSION</span><br><span class="line">kubernetes-minion-group-6jst   Ready      2h      v1.6.0+fff5156</span><br><span class="line">kubernetes-minion-group-cx31   Ready      2h      v1.6.0+fff5156</span><br><span class="line">kubernetes-minion-group-jj1t   Ready      2h      v1.6.0+fff5156</span><br><span class="line">kubernetes-minion-group-6jst $ curl localhost:10249&#x2F;proxyMode</span><br><span class="line">iptables</span><br></pre></td></tr></table></figure>

<p>你可以通过在 source IP 应用上创建一个服务来测试源 IP 保留。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl expose deployment source-ip-app --name&#x3D;clusterip --port&#x3D;80 --target-port&#x3D;8080</span><br><span class="line">service &quot;clusterip&quot; exposed</span><br><span class="line"></span><br><span class="line">$ kubectl get svc clusterip</span><br><span class="line">NAME         CLUSTER-IP    EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">clusterip    10.0.170.92   &lt;none&gt;        80&#x2F;TCP    51s</span><br><span class="line">&#96;&#96;</span><br></pre></td></tr></table></figure>

<p>从相同集群中的一个 pod 访问这个 ClusterIP：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl run busybox -it --image&#x3D;busybox --restart&#x3D;Never --rm</span><br><span class="line">Waiting for pod default&#x2F;busybox to be running, status is Pending, pod ready: false</span><br><span class="line">If you don&#39;t see a command prompt, try pressing enter.</span><br><span class="line"># ip addr</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER\_UP&gt; mtu 65536 qdisc noqueue</span><br><span class="line">    link&#x2F;loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1&#x2F;8 scope host lo</span><br><span class="line">       valid\_lft forever preferred\_lft forever</span><br><span class="line">    inet6 ::1&#x2F;128 scope host</span><br><span class="line">       valid\_lft forever preferred\_lft forever</span><br><span class="line">3: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER\_UP&gt; mtu 1460 qdisc noqueue</span><br><span class="line">    link&#x2F;ether 0a:58:0a:f4:03:08 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 10.244.3.8&#x2F;24 scope global eth0</span><br><span class="line">       valid\_lft forever preferred\_lft forever</span><br><span class="line">    inet6 fe80::188a:84ff:feb0:26a5&#x2F;64 scope link</span><br><span class="line">       valid\_lft forever preferred\_lft forever</span><br></pre></td></tr></table></figure>



<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># wget -qO - 10.0.170.92</span><br><span class="line">CLIENT VALUES:</span><br><span class="line">client\_address&#x3D;10.244.3.8</span><br><span class="line">command&#x3D;GET</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>如果客户端 pod 和 服务端 pod 在相同的节点上，client_address 就是客户端 pod 的 IP 地址。但是，如果它们在不同的节点上， client_address 将会是客户端 pod 所在节点的 flannel IP 地址。</p>
<h2 id="Type-NodePort-类型-Services-的-Source-IP"><a href="#Type-NodePort-类型-Services-的-Source-IP" class="headerlink" title="Type=NodePort 类型 Services 的 Source IP"></a>Type=NodePort 类型 Services 的 Source IP</h2><p>      对于 Kubernetes 1.5，发送给类型为 Type=NodePort Services 的数据包默认进行源地址 NAT。你可以创建一个 NodePort Service 来进行测试：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl expose deployment source-ip-app --name&#x3D;nodeport --port&#x3D;80 --target-port&#x3D;8080 --type&#x3D;NodePort</span><br><span class="line">service &quot;nodeport&quot; exposed</span><br><span class="line">$ NODEPORT&#x3D;$(kubectl get -o jsonpath&#x3D;&quot;&#123;.spec.ports\[0\].nodePort&#125;&quot; services nodeport)</span><br><span class="line">$ NODES&#x3D;$(kubectl get nodes -o jsonpath&#x3D;&#39;&#123; $.items\[\*\].status.addresses\[?(@.type&#x3D;&#x3D;&quot;ExternalIP&quot;)\].address &#125;&#39;)</span><br></pre></td></tr></table></figure>

<p>如果你的集群运行在一个云服务上，你可能需要为上面报告的 nodes:nodeport 开启一条防火墙规则。 现在，你可以通过上面分配的节点端口从外部访问这个 Service。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ for node in $NODES; do curl -s $node:$NODEPORT | grep -i client\_address; done</span><br><span class="line">client\_address&#x3D;10.180.1.1</span><br><span class="line">client\_address&#x3D;10.240.0.5</span><br><span class="line">client\_address&#x3D;10.240.0.3</span><br></pre></td></tr></table></figure>

<p>请注意，这些并不是正确的客户端 IP，它们是集群的内部 IP。这是所发生的事情：</p>
<p>1、客户端发送数据包到 node2:nodePort</p>
<p>2、node2 使用它自己的 IP 地址替换数据包的源 IP 地址（SNAT）</p>
<p>3、node2 使用 pod IP 地址替换数据包的目的 IP 地址</p>
<p>4、数据包被路由到 node 1，然后交给 endpoint</p>
<p>5、Pod 的回复被路由回 node2</p>
<p>6、Pod 的回复被发送回给客户端</p>
<p>形象的：<br> <img src="/2020/09/21/Kubernetes%E4%B8%AD%E7%9A%84Source-Ip%E6%9C%BA%E5%88%B6/1526621848885868.png" alt="avatar"></p>
<p>      为了防止这种情况发生，Kubernetes 提供了一个特性来保留客户端的源 IP 地址(点击此处查看可用特性)。设置 service.spec.externalTrafficPolicy 的值为 Local，请求就只会被代理到本地 endpoints 而不会被转发到其它节点。这样就保留了最初的源 IP 地址。如果没有本地 endpoints，发送到这个节点的数据包将会被丢弃。这样在应用到数据包的任何包处理规则下，你都能依赖这个正确的 source-ip 使数据包通过并到达 endpoint。</p>
<p>   设置 service.spec.externalTrafficPolicy 字段如下：  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl patch svc nodeport -p &#39;&#123;&quot;spec&quot;:&#123;&quot;externalTrafficPolicy&quot;:&quot;Local&quot;&#125;&#125;&#39;</span><br><span class="line">service &quot;nodeport&quot; patched</span><br></pre></td></tr></table></figure>

<p>现在，重新运行测试：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ for node in $NODES; do curl --connect-timeout 1 -s $node:$NODEPORT | grep -i client\_address; done</span><br><span class="line">client\_address&#x3D;104.132.1.79</span><br></pre></td></tr></table></figure>

<p>   请注意，你只从 endpoint pod 运行的那个节点得到了一个回复，这个回复有*正确的*客户端 IP。</p>
<p>这是发生的事情：</p>
<p>1、客户端发送数据包到 node2:nodePort，它没有任何 endpoints</p>
<p>2、数据包被丢弃</p>
<p>3、客户端发送数据包到 node1:nodePort，它*有*endpoints</p>
<p>4、node1 使用正确的源 IP 地址将数据包路由到 endpoint</p>
<p>形象的：<br> <img src="/2020/09/21/Kubernetes%E4%B8%AD%E7%9A%84Source-Ip%E6%9C%BA%E5%88%B6/1526622213101501.png" alt="avatar"></p>
<h2 id="Type-LoadBalancer-类型-Services-的-Source-IP"><a href="#Type-LoadBalancer-类型-Services-的-Source-IP" class="headerlink" title="Type=LoadBalancer 类型 Services 的 Source IP"></a>Type=LoadBalancer 类型 Services 的 Source IP</h2><p>      对于 Kubernetes 1.5，发送给类型为 Type=LoadBalancer Services 的数据包默认进行源地址 NAT，这是由于所有处于 Ready 状态的 Kubernetes 节点对于负载均衡的流量都是符合条件的。所以如果数据包到达一个没有 endpoint 的节点，系统将把这个包代理到有 endpoint 的节点，并替换数据包的源 IP 为节点的 IP（如前面章节所述）。</p>
<p>    你可以通过在一个 loadbalancer 上暴露这个 source-ip-app 来进行测试。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl expose deployment source-ip-app --name&#x3D;loadbalancer --port&#x3D;80 --target-port&#x3D;8080 --type&#x3D;LoadBalancer</span><br><span class="line">service &quot;loadbalancer&quot; exposed</span><br><span class="line">$ kubectl get svc loadbalancer</span><br><span class="line">NAME           CLUSTER-IP    EXTERNAL-IP       PORT(S)   AGE</span><br><span class="line">loadbalancer   10.0.65.118   104.198.149.140   80&#x2F;TCP    5m</span><br><span class="line">$ curl 104.198.149.140</span><br><span class="line">CLIENT VALUES:</span><br><span class="line">client\_address&#x3D;10.240.0.5</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>      然而，如果你的集群运行在 Google Kubernetes Engine/GCE 上，设置 service.spec.externalTrafficPolicy 字段值为 Local 可以强制使没有 endpoints 的节点把他们自己从负载均衡流量的可选节点名单中删除。这是通过故意使它们健康检查失败达到的。</p>
<p>形象的：<br> <img src="/2020/09/21/Kubernetes%E4%B8%AD%E7%9A%84Source-Ip%E6%9C%BA%E5%88%B6/1526622380157076.png" alt="avatar"></p>
<p>你可以设置 annotation 来进行测试：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl patch svc loadbalancer -p &#39;&#123;&quot;spec&quot;:&#123;&quot;externalTrafficPolicy&quot;:&quot;Local&quot;&#125;&#125;&#39;</span><br></pre></td></tr></table></figure>

<p>你应该能够立即看到 Kubernetes 分配的 service.spec.healthCheckNodePort 字段：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl get svc loadbalancer -o yaml | grep -i healthCheckNodePort</span><br><span class="line">  healthCheckNodePort: 32122</span><br></pre></td></tr></table></figure>

<p>service.spec.healthCheckNodePort 字段指向每个节点在 /healthz 路径上提供的用于健康检查的端口。你可以这样测试：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl get pod -o wide -l run&#x3D;source-ip-app</span><br><span class="line">NAME                            READY     STATUS    RESTARTS   AGE       IP             NODE</span><br><span class="line">source-ip-app-826191075-qehz4   1&#x2F;1       Running   0          20h       10.180.1.136   kubernetes-minion-group-6jst</span><br><span class="line">kubernetes-minion-group-6jst $ curl localhost:32122&#x2F;healthz</span><br><span class="line">1 Service Endpoints found</span><br><span class="line">kubernetes-minion-group-jj1t $ curl localhost:32122&#x2F;healthz</span><br><span class="line">No Service Endpoints Found</span><br></pre></td></tr></table></figure>

<p>    主节点运行的 service 控制器负责分配 cloud loadbalancer。在这样做的同时，它也会分配指向每个节点的 HTTP 健康检查的 port/path。等待大约 10 秒钟之后，没有 endpoints 的两个节点的健康检查会失败，然后 curl 负载均衡器的 ip：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ curl 104.198.149.140</span><br><span class="line">CLIENT VALUES:</span><br><span class="line">client\_address&#x3D;104.132.1.79</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h2 id="跨平台支持"><a href="#跨平台支持" class="headerlink" title="跨平台支持"></a>跨平台支持</h2><p>     由于 Kubernetes 1.5 在类型为 Type=LoadBalancer 的 Services 中支持源 IP 保存的特性仅在 cloudproviders 的子集中实现（GCP and Azure）。你的集群运行的 cloudprovider 可能以某些不同的方式满足 loadbalancer 的要求：</p>
<p>1、使用一个代理终止客户端连接并打开一个到你的 nodes/endpoints 的新连接。在这种情况下，源 IP 地址将永远是云负载均衡器的地址而不是客户端的。</p>
<p>2、使用一个包转发器，因此从客户端发送到负载均衡器 VIP 的请求在拥有客户端源 IP 地址的节点终止，而不被中间代理。</p>
<p>      第一类负载均衡器必须使用一种它和后端之间约定的协议来和真实的客户端 IP 通信，例如 HTTP X-FORWARDED-FOR 头，或者 proxy 协议。 第二类负载均衡器可以通过简单的在保存于 Service 的 service.spec.healthCheckNodePort 字段上创建一个 HTTP 健康检查点来使用上面描述的特性。</p>
]]></content>
      <tags>
        <tag>kubernetes 网络</tag>
      </tags>
  </entry>
  <entry>
    <title>谈云计算与云原生</title>
    <url>/2020/12/05/%E8%B0%88%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B8%8E%E4%BA%91%E5%8E%9F%E7%94%9F/</url>
    <content><![CDATA[<h2 id="云计算中的IAAS-PAAS-SAAS"><a href="#云计算中的IAAS-PAAS-SAAS" class="headerlink" title="云计算中的IAAS/PAAS/SAAS"></a>云计算中的IAAS/PAAS/SAAS</h2><p>云计算的概念提出者是IBM，但是IBM并没有很好的落地的产品，对于在线图书商店AWS，却有可以落地的场景，买了大量服务器，但是在图书销售淡季，造成了资源的浪费，因此逐渐有了目前云计算的领导者AWS，对于云计算相关工作者来说，我们<br>对AWS最深的印象时公有云NO.1，尝尝会忽略人家盈利最多的在线商城。</p>
<p>云计算刚提出的时候是提出了三个层次，即IAAS、PAAS、SAAS，这三个层次我们可以认为是云计算能力不同范围的概括，如下图所示：</p>
<p><img src="/2020/12/05/%E8%B0%88%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B8%8E%E4%BA%91%E5%8E%9F%E7%94%9F/cloud1.png" alt="avatar"></p>
<a id="more"></a>
<p>但实际上这代表了云计算发展的三个阶段，更直白的说就是PAAS的发展需要在IAAS发展成熟的基础上，SAAS的发展需要在PAAS发展成熟的基础上，不可能并行发展，也不可能跳跃发展。当然对于细分领域的PAAS平台肯定就没有这个限制了，我这里主要还是指的通用的云平台，以公有云厂商的能力为准。</p>
<ol>
<li><p>IAAS的发展阶段，主要包括这样的内容</p>
<p> 1.1.各大厂商争相模仿AWS、自研底层虚拟化平台，比提供兼容AWS的接口，此时都以AWS作为需求开发的标准</p>
<p> 1.2.底层虚拟化软件除了商业版的Vmware，出现了越来越多的开源的虚拟化软件，例如XEN、KVM、libvirt等，定位与私有云平台厂商的产品开始基于这些虚拟化软件做二次开发</p>
<p> 1.3.出现了越来越多的不同厂家的云管理平台，以及开源的云平台，OpenStack/CloudStack/Zstack等，随后各个厂家开始基于OpenStack作为标准进行自家云平台的二次开发或深度定制，此时越来越多的云厂家基于利旧（充分发挥老旧服务器的作用）、平台不绑定、资源异构（计算资源异构、存储资源异构、网络资源异构）的标准进行产品定位和宣传</p>
<p> 1.4IAAS尝试提出为了解决资源利用率与降低成本，自动化运维进行市场宣传，传统厂商开始逐渐接受云的能力，并逐渐将自己业务迁移到公有云平台或者私有云平台</p>
<p> 1.6.此时，市场对PAAS的认可度不高，我觉得市场度认可不够的原因有两个，一个是技术成熟度，有基于虚拟机做的PAAS，但是不是很好用，另一方面，云厂商对这方面的市场宣传不多，大家还都是主要发力于底层IAAS建设</p>
</li>
<li><p>PAAS发展的阶段，包含这样的内容</p>
<p> 2.1 以虚拟机为代表的PAAS平台，自动编排虚拟机+应用+服务，这个其实我们在OpenStack的发展过程中就能看到，从只包含nova、neutron、cinder组件，到现在各种基于虚拟机的编排heat、sahara等，开始基于虚拟机的编排，来做服务的自动化创建，但是这种PAAS 很笨重，侧重于服务的自动化创建，距离应用的自动化管理有不少差距</p>
<p> 2.2以容器为代表的PAAS平台，这里的开源项目有docker、CloudFoundry+warden、Kubernetes，我做的第一个PAAS项目其实是基于CLoudFoundry+warden，这是有Privotal公司开源的业界第一个容器的PAAS平台，在当时来说还是非常先进的，但是受限于CloudFoundry中并没有像docker中镜像的概念来持久化打包应用，他里面是有一个叫buildpack的东西，需要对不同的开发语言版本、运行环境制作不同的buildpack，还是很麻烦的，跨平台迁移也比较费劲。现在最火的就是Kubernetes+docker和围绕他们的技术栈</p>
<p> 2.3.PAAS的定位也越来越清晰，以应用为中心，为应用的自动化运维提供支撑，例如应用需要的服务（数据库、缓存、消息队列）、运维管理（监控告警、弹性伸缩）等</p>
<p> 2.4.平台+生态，更多的服务能够集成到生态，传统厂商也希望基于云平台厂商的能力，来拿到更多的客户，逐渐兴起了平台+生态的概念，希望大的平台厂商能够给传统厂商带来客户</p>
<p> 2.5 随着iaas的成熟，这些年在不同的行业出现了不同的paas平台，不同的细分行业的技术平台积累，也都开始叫做XX PAAS云平台</p>
</li>
<li><p>SAAS的发展阶段，SAAS更多是属于应用的范围，需要应用来支持多租户，从而可以实现一个产品来支持多个客户，通常多租户有两种方案，一种是多实例部署，即不同的客户，我给你部署一个实例，还有一种方案是基于应用改造，即应用通过分库分表，在自己的业务层进行多租户的区分。这里云平台厂商目前提供的能力有限</p>
</li>
</ol>
<p><img src="/2020/12/05/%E8%B0%88%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B8%8E%E4%BA%91%E5%8E%9F%E7%94%9F/cloud2.png" alt="avatar"></p>
<h2 id="云原生"><a href="#云原生" class="headerlink" title="云原生"></a>云原生</h2><p>好多概念我们可以发现都是来自于互联网，我们先说一下传统应用与互联网应用的区别，</p>
<ol>
<li><p>对于传统应用通常具有以下特征,需求比较固定，是个项目，完成以后就是运维，用户访问量可以预测，较为固定，用户访问的并发量比较低，非在线业务，允许一定时间的业务停顿，此时的开发方式通常是瀑布式，当软件开发完成时，可能就交给运维部门了，然后就是会有些打补丁的工作，项目组开发人员也可能解散了。</p>
</li>
<li><p>但是对于互联网应用，需求是持续发展的，是一个产品，持续发展，版本特性不断累加和变化，用户访问量难以预测，用户访问的并发量是万级、十万、百万，属于在线业务，业务不能停顿，互联网应用需要24小时保持稳定可靠。对于该类应用的开发人员通常会一直围绕这个产品进行开发，需要一直对这个产品的功能、稳定性进行负责并持续优化。这里对技术就提出了更高的要求，你需要支持敏捷开发、弹性伸缩，强大的监控能力，支持海量并发，灰度发布等等。</p>
</li>
</ol>
<h3 id="传统应用的典型架构"><a href="#传统应用的典型架构" class="headerlink" title="传统应用的典型架构"></a>传统应用的典型架构</h3><p><img src="/2020/12/05/%E8%B0%88%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B8%8E%E4%BA%91%E5%8E%9F%E7%94%9F/cloud3.png" alt="avatar"></p>
<p>上图是一个常见的包含三层应用的架构，通常对于传统应用都会包含多个模块，每个模块都实现了一些功能，模块之间是紧耦合在一起的，通过对象的调用(函数级API的调用)，功能调用紧密的结合在一起。这种高耦合性最典型的表现就是，哪怕开发者改了一行代码，整个应用都要重新编译部署；应用有可能是有状态的，例如通常会在程序内存中保存一些业务数据或者在应用使用的本地存储持久化一些信息，还有例如spring中的有状态bean和无状态bean（有状态bena保存了会话信息）由于这种高耦合性以及有状态，对于提供应用服务的挑战在于，要保证应用服务的持续运行。在生产环境中，一般都是要实施HA的解决方案的，比如App的集群，数据库的HA等等，同时为了保证服务宕机的时候，要能够快速恢复服务。因此，数据库会进行定期的备份。</p>
<p>我们在开发传统应用时，通常会有这样的场景，在开发环境中可以运行的应用，在生产环境中会出现很多问题，因为基本上开发者是没有精力去维护一个复杂的高可用的和生产环境一样的开发环境。而对于运维人员，他们的任务是什么，不管是物理机还是虚机，都要全力保证物理机和虚机的运行。一旦物理机或虚机发生故障，对服务的影响也是灾难性的，往往需要一个手动恢复服务的过程。在开发人员和运维人员之间有一个gap。开发人员和运维人员不太喜欢进行产品的功能变更，带来的工作量很大。这里总结一下传统应用架构的问题，我觉得可以归为三类：故障运维、应用伸缩、需求变更</p>
<h3 id="云原生应用的典型架构"><a href="#云原生应用的典型架构" class="headerlink" title="云原生应用的典型架构"></a>云原生应用的典型架构</h3><p><img src="/2020/12/05/%E8%B0%88%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B8%8E%E4%BA%91%E5%8E%9F%E7%94%9F/cloud4.png" alt="avatar"></p>
<p>你可能不太懂云原生，但是我们在做架构设计的时候，可能已经潜意识的去这样做了，因为现在这个DevOps、微服务、容器太火了，不管IT的什么行业，我觉得都应该听过这几个名词。我们看到图中，角色并没有太大变化，仍然是有web，app，和db。这里要说明的一点，传统应用也许是部署在物理服务器或者虚拟化平台上，但是云原生应用一定是部署在云平台上的主要的变化包括：</p>
<p> 第一，应用被拆分成了几个小的应用，紧耦合变为松耦合；由模块变成线程级的微服务；</p>
<p> 第二，应用由有状态变为无状态的。大家也许会问，在业务逻辑中总是会有状态产生的，应该怎么办呢？这里重要的是对状态的一个管理，就是把状态保存在有状态服务中去。这些有状态服务包括缓存，比如memcache，数据库，比如mysql，mongodb，文件系统，消息对了等等。这些有状态服务以资源的形式提供给应用。这些资源在应用部署的时候，是以显性的依赖来声明的</p>
<p>第三，通过container技术，打包/隔离运行环境；在虚机和应用之间增加一层来隔离，在不同执行环境之间提供最大化的可移植性</p>
<p>对于传统应用，我们可以发现云原生应用的几个特点：微服务、无状态、弹性伸缩、DevOps</p>
<p>找到一张阿里云给云原生定义的图，如下，可以看出，云原生架构 可以理解为在进行软件架构设计时，就基于云平台的能力去设计，例如DevOps、微服务、容器，能够充分发挥云平态对应用的运维管理能力，即非业务功能交给云平台去处理。</p>
<p><img src="/2020/12/05/%E8%B0%88%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B8%8E%E4%BA%91%E5%8E%9F%E7%94%9F/cloud5.png" alt="avatar"></p>
<p>云原生定义的几个阶段</p>
<p><img src="/2020/12/05/%E8%B0%88%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B8%8E%E4%BA%91%E5%8E%9F%E7%94%9F/cloud6.png" alt="avatar"></p>
<h3 id="云原生十二要素"><a href="#云原生十二要素" class="headerlink" title="云原生十二要素"></a>云原生十二要素</h3><p>这里有一个云原生的十二要素，这个其实是最开始对云原生定义时，使用，虽然云原生的定义已经变化多次，但是这个十二要素可以作为我们进行软件设计的参考</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">1. 基准代码：一份基准代码，多份部署。基准代码和应用之间总是保持一一对应的关系。所有部署的基准代码相同，但每份部署可以使用其不同的版本。</span><br><span class="line">2. 依赖：显式声明依赖关系。应用程序一定通过依赖清单 ，确切地声明所有依赖项。</span><br><span class="line">3. 配置：在环境中存储配置。将应用的配置存储于环境变量中。环境变量可以非常方便地在不同的部署间做修改，却不动一行代码。</span><br><span class="line">4. 后端服务：把后端服务当作附加资源。应用不会区别对待本地或第三方服务。对应用程序而言，两种都是附加资源。</span><br><span class="line">5. 构建，发布，运行：严格区分构建，发布，运行这三个步骤。</span><br><span class="line">6. 进程：以一个或多个无状态进程运行应用。应用的进程必须无状态且无共享。</span><br><span class="line">7. 端口绑定：通过端口绑定提供服务。应用完全自我加载而不依赖于任何网络服务器就可以创建一个面向网络的服务。</span><br><span class="line">8. 并发：通过进程模型进行扩展。开发人员可以运用这个模型去设计应用架构，将不同的工作分配给不同的进程类型。</span><br><span class="line">9. 易处理：快速启动和优雅终止可最大化健壮性。应用的进程是可支配的，意思是说它们可以瞬间开启或停止。</span><br><span class="line">10. 开发环境与线上环境等价：尽可能保持开发、预发布、线上环境相同。应用想要做到持续部署就必须缩小本地与线上差异。</span><br><span class="line">11. 日志：把日志当作事件流。应用本身考虑存储自己的输出流。不应该试图去写或者管理日志文件。</span><br><span class="line">12. 管理进程：后台管理任务当作一次性进程运行。一次性管理进程应该和正常的常驻进程使用同样的环境。</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>云计算  云原生</tag>
      </tags>
  </entry>
  <entry>
    <title>kubernetes apps删除流程</title>
    <url>/2020/11/17/kubernetes-apps%E5%88%A0%E9%99%A4%E6%B5%81%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>最近遇到了好几个Kubernetes集群出现了删除Statefulset时，Pod未被删除的问题，经过定位是开发同事，基于farbric 的k8s api进行删除statefulset的操作<br>，调用了删除statefulset的接口后，又调用了删除pod的接口，但是都是使用的默认删除方式，非级联删除（Orphan策略），这在某些情况下，可能只是调用了删除statefulset的接口，但是未调用删除Pod的接口，就会<br>出现Pod未被删除的，此时Pod的metadat内可能仍然存在，但是kube-controller-manager中的garbargecollector会将该Pode的ownerreference移除，但是label中仍然带有controller-revision-hash和statefulset的信息，如下图所示<br><img src="/2020/11/17/kubernetes-apps%E5%88%A0%E9%99%A4%E6%B5%81%E7%A8%8B/pod1.png" alt="avatar"></p>
<p>对于正常的属于Statefulset的Pod标识如下所示：</p>
<p><img src="/2020/11/17/kubernetes-apps%E5%88%A0%E9%99%A4%E6%B5%81%E7%A8%8B/pod2.png" alt="avatar"></p>
<p>借此机会对Statefulset删除的源码进行了分析，原以为是由Statefulset-controller 进行控制，但是看了一下代码，发现Statefulset-controller只是用来控制副本数的变化，但是对于Statefulset的删除，并不做任何处理，statefulset-controller的如下代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; If the StatefulSet is being deleted, don&#39;t do anything other than updating</span><br><span class="line">&#x2F;&#x2F; status.</span><br><span class="line">if set.DeletionTimestamp !&#x3D; nil &#123;</span><br><span class="line">	return &amp;status, nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>##Kubernetes资源删除的方式<br>Kubernetes 在删除资源时，存在级联删除和非级联删除<br>###控制垃圾收集器删除 Dependent<br>####级联删除<br>当删除对象时，可以指定是否该对象的 Dependent 也自动删除掉。自动删除 Dependent 也称为级联删除。Kubernetes 中有两种级联删除的模式：background 模式和 foreground 模式。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl delete statefulset  -n de2ca8d1-94b4-4faa-8077-e9374ca9db4e 5bagk2rivkjno --cascade&#x3D;true</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Background 级联删除,在 background 级联删除 模式下，Kubernetes 会立即删除 Owner 对象，然后垃圾收集器会在后台删除这些 Dependent。<br>   <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">   curl -X DELETE 127.0.0.1:8080&#x2F;apis&#x2F;extensions&#x2F;v1beta1&#x2F;namespaces&#x2F;default&#x2F;replicasets&#x2F;my-repset \</span><br><span class="line">-d &#39;&#123;&quot;kind&quot;:&quot;DeleteOptions&quot;,&quot;apiVersion&quot;:&quot;v1&quot;,&quot;propagationPolicy&quot;:&quot;Background&quot;&#125;&#39; \</span><br><span class="line">-H &quot;Content-Type: application&#x2F;json&quot;</span><br></pre></td></tr></table></figure><br>Foreground 级联删除m在 foreground 级联删除 模式下，根对象首先进入 “删除中” 状态。该对象会设置deletionTimestamp 字段对象的 metadata.finalizers 字段包含了值 “foregroundDeletion”，对象仍然可以通过 REST API 可见，一旦被设置为 “删除中” 状态，垃圾收集器会删除对象的所有 Dependent。垃圾收集器删除了所有 “Blocking” 的 Dependent（对象的 ownerReference.blockOwnerDeletion=true）之后，它会删除 Owner 对象。<br>如果一个对象的ownerReferences 字段被一个 Controller（例如 Deployment 或 ReplicaSet）设置，blockOwnerDeletion 会被自动设置，没必要手动修改这个字段。</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -X DELETE localhost:8080&#x2F;apis&#x2F;extensions&#x2F;v1beta1&#x2F;namespaces&#x2F;default&#x2F;replicasets&#x2F;my-repset \</span><br><span class="line">-d &#39;&#123;&quot;kind&quot;:&quot;DeleteOptions&quot;,&quot;apiVersion&quot;:&quot;v1&quot;,&quot;propagationPolicy&quot;:&quot;Foreground&quot;&#125;&#39; \</span><br><span class="line">-H &quot;Content-Type: application&#x2F;json&quot;</span><br></pre></td></tr></table></figure>

<h4 id="非级联删除"><a href="#非级联删除" class="headerlink" title="非级联删除"></a>非级联删除</h4><p>如果删除对象时，不自动删除它的 Dependent，这些 Dependent 被称作是原对象的 孤儿(Orphan),可以使用以下命令实现</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl delete statefulset  -n de2ca8d1-94b4-4faa-8077-e9374ca9db4e 5bagk2rivkjno --cascade&#x3D;false</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -X DELETE 127.0.0.1:8080&#x2F;apis&#x2F;extensions&#x2F;v1beta1&#x2F;namespaces&#x2F;default&#x2F;replicasets&#x2F;my-repset \</span><br><span class="line">-d &#39;&#123;&quot;kind&quot;:&quot;DeleteOptions&quot;,&quot;apiVersion&quot;:&quot;v1&quot;,&quot;propagationPolicy&quot;:&quot;Orphan&quot;&#125;&#39; \</span><br><span class="line">-H &quot;Content-Type: application&#x2F;json&quot;</span><br></pre></td></tr></table></figure>
<h2 id="Kubernetes-删除apps流程分析"><a href="#Kubernetes-删除apps流程分析" class="headerlink" title="Kubernetes 删除apps流程分析"></a>Kubernetes 删除apps流程分析</h2><p>删除流程中几个重要的过程包括 kube-apiserver 提供的rest服务</p>
<ol>
<li><p>通过调用rest api实现etcd数据库中，app对象的状态更新，包括增加deletetimestamp和finalizer自带，触发更新事件</p>
</li>
<li><p>kube-controller-manager收到了apps状态的更新事件，通过更新内置的graph（集群内资源依赖附属关系的图）和garbagecollector进行资源极其附属的删除，这里是只在etcd数据库删除</p>
</li>
<li><p>kubelet收到第1步中的资源删除事件，进行底层资源的删除和回收</p>
</li>
</ol>
<p>###kube-apiserver<br>kube-apiserver在启动时会基于go-restful将rest服务的handler 进行加载，主要如下所示：<br>pkg/master/master.go</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; InstallAPIs will install the APIs for the restStorageProviders if they are enabled.</span><br><span class="line">func (m *Master) InstallAPIs(apiResourceConfigSource serverstorage.APIResourceConfigSource, restOptionsGetter generic.RESTOptionsGetter, restStorageProviders ...RESTStorageProvider) &#123;</span><br><span class="line">	apiGroupsInfo :&#x3D; []*genericapiserver.APIGroupInfo&#123;&#125;</span><br><span class="line"></span><br><span class="line">	for _, restStorageBuilder :&#x3D; range restStorageProviders &#123;</span><br><span class="line">		groupName :&#x3D; restStorageBuilder.GroupName()</span><br><span class="line">		if !apiResourceConfigSource.AnyVersionForGroupEnabled(groupName) &#123;</span><br><span class="line">			klog.V(1).Infof(&quot;Skipping disabled API group %q.&quot;, groupName)</span><br><span class="line">			continue</span><br><span class="line">		&#125;</span><br><span class="line">		apiGroupInfo, enabled :&#x3D; restStorageBuilder.NewRESTStorage(apiResourceConfigSource, restOptionsGetter)</span><br><span class="line">		if !enabled &#123;</span><br><span class="line">			klog.Warningf(&quot;Problem initializing API group %q, skipping.&quot;, groupName)</span><br><span class="line">			continue</span><br><span class="line">		&#125;</span><br><span class="line">		klog.V(1).Infof(&quot;Enabling API group %q.&quot;, groupName)</span><br><span class="line"></span><br><span class="line">		if postHookProvider, ok :&#x3D; restStorageBuilder.(genericapiserver.PostStartHookProvider); ok &#123;</span><br><span class="line">			name, hook, err :&#x3D; postHookProvider.PostStartHook()</span><br><span class="line">			if err !&#x3D; nil &#123;</span><br><span class="line">				klog.Fatalf(&quot;Error building PostStartHook: %v&quot;, err)</span><br><span class="line">			&#125;</span><br><span class="line">			m.GenericAPIServer.AddPostStartHookOrDie(name, hook)</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		apiGroupsInfo &#x3D; append(apiGroupsInfo, &amp;apiGroupInfo)</span><br><span class="line">	&#125;</span><br><span class="line">    #集成API</span><br><span class="line">	if err :&#x3D; m.GenericAPIServer.InstallAPIGroups(apiGroupsInfo...); err !&#x3D; nil &#123;</span><br><span class="line">		klog.Fatalf(&quot;Error in registering group versions: %v&quot;, err)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>主要的调用链：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">k8s.io&#x2F;apiserver&#x2F;pkg&#x2F;server&#x2F;genericapiserver.go:InstallAPIGroups()</span><br><span class="line">k8s.io&#x2F;apiserver&#x2F;pkg&#x2F;server&#x2F;genericapiserver.go:installAPIResources()</span><br><span class="line">k8s.io&#x2F;apiserver&#x2F;pkg&#x2F;endpoints&#x2F;groupversion.go:InstallREST()</span><br><span class="line">k8s.io&#x2F;apiserver&#x2F;pkg&#x2F;endpoints&#x2F;installer.go:Install()</span><br><span class="line">k8s.io&#x2F;apiserver&#x2F;pkg&#x2F;endpoints&#x2F;installer.go:registerResourceHandlers()</span><br></pre></td></tr></table></figure>
<p>rest注册的核心函数：将rest请求直接映射为etcd存储的操作</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">staging&#x2F;src&#x2F;k8s.io&#x2F;apiserver&#x2F;pkg&#x2F;endpoints&#x2F;installer.go:183  registerResourceHandlers()</span><br></pre></td></tr></table></figure>
<p>删除的rest请求对应的处理请求在这里</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">   .....</span><br><span class="line">actions &#x3D; appendIf(actions, action&#123;&quot;GET&quot;, itemPath, nameParams, namer, false&#125;, isGetter)</span><br><span class="line">	if getSubpath &#123;</span><br><span class="line">		actions &#x3D; appendIf(actions, action&#123;&quot;GET&quot;, itemPath + &quot;&#x2F;&#123;path:*&#125;&quot;, proxyParams, namer, false&#125;, isGetter)</span><br><span class="line">	&#125;</span><br><span class="line">	actions &#x3D; appendIf(actions, action&#123;&quot;PUT&quot;, itemPath, nameParams, namer, false&#125;, isUpdater)</span><br><span class="line">	actions &#x3D; appendIf(actions, action&#123;&quot;PATCH&quot;, itemPath, nameParams, namer, false&#125;, isPatcher)</span><br><span class="line">	#删除的处理函数</span><br><span class="line">	actions &#x3D; appendIf(actions, action&#123;&quot;DELETE&quot;, itemPath, nameParams, namer, false&#125;, isGracefulDeleter)</span><br><span class="line">	.....</span><br></pre></td></tr></table></figure>

<p>该接口的定义如下所示,即Delete函数可能直接删除数据，也可能异步删除资源</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; GracefulDeleter knows how to pass deletion options to allow delayed deletion of a</span><br><span class="line">&#x2F;&#x2F; RESTful object.</span><br><span class="line">type GracefulDeleter interface &#123;</span><br><span class="line">	&#x2F;&#x2F; Delete finds a resource in the storage and deletes it.</span><br><span class="line">	&#x2F;&#x2F; If options are provided, the resource will attempt to honor them or return an invalid</span><br><span class="line">	&#x2F;&#x2F; request error.</span><br><span class="line">	&#x2F;&#x2F; Although it can return an arbitrary error value, IsNotFound(err) is true for the</span><br><span class="line">	&#x2F;&#x2F; returned error value err when the specified resource is not found.</span><br><span class="line">	&#x2F;&#x2F; Delete *may* return the object that was deleted, or a status object indicating additional</span><br><span class="line">	&#x2F;&#x2F; information about deletion.</span><br><span class="line">	&#x2F;&#x2F; It also returns a boolean which is set to true if the resource was instantly</span><br><span class="line">	&#x2F;&#x2F; deleted or false if it will be deleted asynchronously.</span><br><span class="line">	Delete(ctx genericapirequest.Context, name string, options *metav1.DeleteOptions) (runtime.Object, bool, error)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里有个比较重要的Delete函数，用于在Delete之前做一些业务处理，就包括了我们前面重点提到的设置deletetimestamp 和finalizers字段，对于Statefulset特有的增删改查的预处理，代码都归档在了k8s.io\kubernetes\pkg\registry\apps\statefulset目录，但是对于通用的增删改查预处理操作<br>，代码被归档在了这里 k8s.io/kubernetes/staging/src/k8s.io/apiserver/pkg/registry/rest/,其中通用的BeforeDelete归档在了staging/src/k8s.io/apiserver/pkg/registry/rest/delete.go:BeforeDelete()<br>其中核心的Delete函数 在staging/src/k8s.io/apiserver/pkg/registry/generic/registry/store.go:Delete()，重点关注下面的代码段,设置删除策略：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">....</span><br><span class="line">var preconditions storage.Preconditions</span><br><span class="line">if options.Preconditions !&#x3D; nil &#123;</span><br><span class="line">	preconditions.UID &#x3D; options.Preconditions.UID</span><br><span class="line">	preconditions.ResourceVersion &#x3D; options.Preconditions.ResourceVersion</span><br><span class="line">&#125;</span><br><span class="line">#调用BeforeDelete获取是否需要graceful 进行删除</span><br><span class="line">graceful, pendingGraceful, err :&#x3D; rest.BeforeDelete(e.DeleteStrategy, ctx, obj, options)</span><br><span class="line">if err !&#x3D; nil &#123;</span><br><span class="line">	return nil, false, err</span><br><span class="line">&#125;</span><br><span class="line">......</span><br><span class="line">&#x2F;&#x2F; Handle combinations of graceful deletion and finalization by issuing</span><br><span class="line">&#x2F;&#x2F; the correct updates.</span><br><span class="line">#设置finalizer，为orphan或者foregroundDeletion策略</span><br><span class="line">shouldUpdateFinalizers, _ :&#x3D; deletionFinalizersForGarbageCollection(ctx, e, accessor, options)</span><br><span class="line">&#x2F;&#x2F; TODO: remove the check, because we support no-op updates now.</span><br><span class="line">if graceful || pendingFinalizers || shouldUpdateFinalizers &#123;</span><br><span class="line">    #在etcd数据库更新资源的metadata信息</span><br><span class="line">	err, ignoreNotFound, deleteImmediately, out, lastExisting &#x3D; e.updateForGracefulDeletionAndFinalizers(ctx, name, key, options, preconditions, obj)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; !deleteImmediately covers all cases where err !&#x3D; nil. We keep both to be future-proof.</span><br><span class="line">if !deleteImmediately || err !&#x3D; nil &#123;</span><br><span class="line">	return out, false, err</span><br><span class="line">&#125;</span><br><span class="line">.....</span><br></pre></td></tr></table></figure>

<p>###kube-controller-manager<br>kube-controller-manager内有一个GarbageCollector用于完成资源的清理删除工作，启动的时候首先会运行一个dependencyGraphBuilder 用于构建集群资源的依赖关系图谱，这个graphbuild 会获取集群的全部资源，并根根据资源的metadata信息构建关系图谱<br>，并基于事件监听更新 关系图谱</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pkg&#x2F;controller&#x2F;garbagecollector&#x2F;graph_builder.go:startMonitors()</span><br><span class="line">func (gb *GraphBuilder) startMonitors() &#123;</span><br><span class="line">	gb.monitorLock.Lock()</span><br><span class="line">	defer gb.monitorLock.Unlock()</span><br><span class="line"></span><br><span class="line">	if !gb.running &#123;</span><br><span class="line">		return</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; we&#39;re waiting until after the informer start that happens once all the controllers are initialized.  This ensures</span><br><span class="line">	&#x2F;&#x2F; that they don&#39;t get unexpected events on their work queues.</span><br><span class="line">	&lt;-gb.informersStarted</span><br><span class="line">    </span><br><span class="line">    #定义需要为哪些资源建立关系图谱，每个都基于informer进行监听，对于garbargecollect 中的graph，只是获取哪些允许进行删除的资源pkg&#x2F;controller&#x2F;garbagecollector&#x2F;garbagecollector.go:GetDeletableResources() </span><br><span class="line">	monitors :&#x3D; gb.monitors</span><br><span class="line">	started :&#x3D; 0</span><br><span class="line">	for _, monitor :&#x3D; range monitors &#123;</span><br><span class="line">		if monitor.stopCh &#x3D;&#x3D; nil &#123;</span><br><span class="line">			monitor.stopCh &#x3D; make(chan struct&#123;&#125;)</span><br><span class="line">			gb.sharedInformers.Start(gb.stopCh)</span><br><span class="line">			go monitor.Run()</span><br><span class="line">			started++</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">....</span><br></pre></td></tr></table></figure>
<p>graph_build 中会处理收到的资源状态更新事件，将产生事件的对象放到缓存队列内，主要pkg/controller/garbagecollector/graph_builder.go:processGraphChanges()</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; Dequeueing an event from graphChanges, updating graph, populating dirty_queue.</span><br><span class="line">func (gb *GraphBuilder) processGraphChanges() bool &#123;</span><br><span class="line">	item, quit :&#x3D; gb.graphChanges.Get()</span><br><span class="line">	....</span><br><span class="line">	case (event.eventType &#x3D;&#x3D; addEvent || event.eventType &#x3D;&#x3D; updateEvent) &amp;&amp; found:</span><br><span class="line">		&#x2F;&#x2F; handle changes in ownerReferences</span><br><span class="line">		added, removed, changed :&#x3D; referencesDiffs(existingNode.owners, accessor.GetOwnerReferences())</span><br><span class="line">		if len(added) !&#x3D; 0 || len(removed) !&#x3D; 0 || len(changed) !&#x3D; 0 &#123;</span><br><span class="line">			&#x2F;&#x2F; check if the changed dependency graph unblock owners that are</span><br><span class="line">			&#x2F;&#x2F; waiting for the deletion of their dependents.</span><br><span class="line">			gb.addUnblockedOwnersToDeleteQueue(removed, changed)</span><br><span class="line">			&#x2F;&#x2F; update the node itself</span><br><span class="line">			existingNode.owners &#x3D; accessor.GetOwnerReferences()</span><br><span class="line">			&#x2F;&#x2F; Add the node to its new owners&#39; dependent lists.</span><br><span class="line">			gb.addDependentToOwners(existingNode, added)</span><br><span class="line">			&#x2F;&#x2F; remove the node from the dependent list of node that are no longer in</span><br><span class="line">			&#x2F;&#x2F; the node&#39;s owners list.</span><br><span class="line">			gb.removeDependentFromOwners(existingNode, removed)</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		if beingDeleted(accessor) &#123;</span><br><span class="line">			existingNode.markBeingDeleted()</span><br><span class="line">		&#125;</span><br><span class="line">		gb.processTransitions(event.oldObj, accessor, existingNode)</span><br><span class="line">	case event.eventType &#x3D;&#x3D; deleteEvent:</span><br><span class="line">		if !found &#123;</span><br><span class="line">			klog.V(5).Infof(&quot;%v doesn&#39;t exist in the graph, this shouldn&#39;t happen&quot;, accessor.GetUID())</span><br><span class="line">			return true</span><br><span class="line">		&#125;</span><br><span class="line">		&#x2F;&#x2F; removeNode updates the graph</span><br><span class="line">		gb.removeNode(existingNode)</span><br><span class="line">		existingNode.dependentsLock.RLock()</span><br><span class="line">		defer existingNode.dependentsLock.RUnlock()</span><br><span class="line">		if len(existingNode.dependents) &gt; 0 &#123;</span><br><span class="line">			gb.absentOwnerCache.Add(accessor.GetUID())</span><br><span class="line">		&#125;</span><br><span class="line">		for dep :&#x3D; range existingNode.dependents &#123;</span><br><span class="line">		     #将需要删除的资源加入到attemptToDelete队列</span><br><span class="line">			gb.attemptToDelete.Add(dep)</span><br><span class="line">		&#125;</span><br><span class="line">		for _, owner :&#x3D; range existingNode.owners &#123;</span><br><span class="line">			ownerNode, found :&#x3D; gb.uidToNode.Read(owner.UID)</span><br><span class="line">			if !found || !ownerNode.isDeletingDependents() &#123;</span><br><span class="line">				continue</span><br><span class="line">			&#125;</span><br><span class="line">			&#x2F;&#x2F; this is to let attempToDeleteItem check if all the owner&#39;s</span><br><span class="line">			&#x2F;&#x2F; dependents are deleted, if so, the owner will be deleted.</span><br><span class="line">			#将需要删除的资源加入到attemptToDelete队列</span><br><span class="line">			gb.attemptToDelete.Add(ownerNode)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	return true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>pkg/controller/garbagecollector/garbagecollector.go:attemptToDeleteWorker() 处理每个删除对象的事件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func (gc *GarbageCollector) attemptToDeleteItem(item *node) error &#123;</span><br><span class="line">....</span><br><span class="line">   #在这里出进行处理，当发现需要删除Statefulset时，先判断是否需要进行删除该Statefulset的附属资源，先进行附属资源的删除</span><br><span class="line">	&#x2F;&#x2F; attemptToOrphanWorker() into attemptToDeleteItem() as well.</span><br><span class="line">	if item.isDeletingDependents() &#123;</span><br><span class="line">		return gc.processDeletingDependentsItem(item)</span><br><span class="line">	&#125;</span><br><span class="line">....</span><br><span class="line"></span><br><span class="line">		switch &#123;</span><br><span class="line">		case hasOrphanFinalizer(latest):</span><br><span class="line">			&#x2F;&#x2F; if an existing orphan finalizer is already on the object, honor it.</span><br><span class="line">			policy &#x3D; metav1.DeletePropagationOrphan</span><br><span class="line">		case hasDeleteDependentsFinalizer(latest):</span><br><span class="line">			&#x2F;&#x2F; if an existing foreground finalizer is already on the object, honor it.</span><br><span class="line">			policy &#x3D; metav1.DeletePropagationForeground</span><br><span class="line">		default:</span><br><span class="line">			&#x2F;&#x2F; otherwise, default to background.</span><br><span class="line">			policy &#x3D; metav1.DeletePropagationBackground</span><br><span class="line">		&#125;</span><br><span class="line">		#这里会将Statefulset的POd 在数据库中直接删除</span><br><span class="line">		klog.V(2).Infof(&quot;delete object %s with propagation policy %s&quot;, item.identity, policy)</span><br><span class="line">		return gc.deleteObject(item.identity, &amp;policy)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#完成附属资源的删除</span><br><span class="line">&#x2F;&#x2F; process item that&#39;s waiting for its dependents to be deleted</span><br><span class="line">func (gc *GarbageCollector) processDeletingDependentsItem(item *node) error &#123;</span><br><span class="line">	blockingDependents :&#x3D; item.blockingDependents()</span><br><span class="line">	if len(blockingDependents) &#x3D;&#x3D; 0 &#123;</span><br><span class="line">		klog.V(2).Infof(&quot;remove DeleteDependents finalizer for item %s&quot;, item.identity)</span><br><span class="line">		#在etcd内移除pod的finakuzed字段，会同时将该资源在数据库删除</span><br><span class="line">		return gc.removeFinalizer(item, metav1.FinalizerDeleteDependents)</span><br><span class="line">	&#125;</span><br><span class="line">	for _, dep :&#x3D; range blockingDependents &#123;</span><br><span class="line">		if !dep.isDeletingDependents() &#123;</span><br><span class="line">			klog.V(2).Infof(&quot;adding %s to attemptToDelete, because its owner %s is deletingDependents&quot;, dep.identity, item.identity)</span><br><span class="line">			gc.attemptToDelete.Add(dep)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	return nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>##kubelet<br>kubelet主要完成资源的释放,主要的删除Pod的处理逻辑，在kubelet的主函数syncpod中，当发现是删除pod的事件时，立即处理</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func (kl *Kubelet) syncPod(o syncPodOptions) error &#123;</span><br><span class="line">	&#x2F;&#x2F; pull out the required options</span><br><span class="line">	pod :&#x3D; o.pod</span><br><span class="line">	mirrorPod :&#x3D; o.mirrorPod</span><br><span class="line">	podStatus :&#x3D; o.podStatus</span><br><span class="line">	updateType :&#x3D; o.updateType</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; if we want to kill a pod, do it now!</span><br><span class="line">	if updateType &#x3D;&#x3D; kubetypes.SyncPodKill &#123;</span><br><span class="line">		killPodOptions :&#x3D; o.killPodOptions</span><br><span class="line">		if killPodOptions &#x3D;&#x3D; nil || killPodOptions.PodStatusFunc &#x3D;&#x3D; nil &#123;</span><br><span class="line">			return fmt.Errorf(&quot;kill pod options are required if update type is kill&quot;)</span><br><span class="line">		&#125;</span><br><span class="line">		apiPodStatus :&#x3D; killPodOptions.PodStatusFunc(pod, podStatus)</span><br><span class="line">		kl.statusManager.SetPodStatus(pod, apiPodStatus)</span><br><span class="line">		&#x2F;&#x2F; we kill the pod with the specified grace period since this is a termination</span><br><span class="line">		if err :&#x3D; kl.killPod(pod, nil, podStatus, killPodOptions.PodTerminationGracePeriodSecondsOverride); err !&#x3D; nil &#123;</span><br><span class="line">			kl.recorder.Eventf(pod, v1.EventTypeWarning, events.FailedToKillPod, &quot;error killing pod: %v&quot;, err)</span><br><span class="line">			&#x2F;&#x2F; there was an error killing the pod, so we return that error directly</span><br><span class="line">			utilruntime.HandleError(err)</span><br><span class="line">			return err</span><br><span class="line">		&#125;</span><br><span class="line">		return nil</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>docker</tag>
        <tag>Kuberentes</tag>
        <tag>云原生</tag>
      </tags>
  </entry>
  <entry>
    <title>docker 默认的Container名称生成</title>
    <url>/2020/09/21/Docker-%E9%BB%98%E8%AE%A4%E7%9A%84Container%E5%90%8D%E7%A7%B0%E7%94%9F%E6%88%90/</url>
    <content><![CDATA[<p>        当基于docker创建Container时，如果不指定容器名称，docker Damon会默认生成容器名称，这个名称看着是个真实的名称，找了一下docker的代码，发现了生成名称的机制，代码文件：<a href="https://github.com/docker/docker" target="_blank" rel="noopener">docker</a>/<a href="https://github.com/docker/docker/tree/master/pkg" target="_blank" rel="noopener">pkg</a>/<a href="https://github.com/docker/docker/tree/master/pkg/namesgenerator" target="_blank" rel="noopener">namesgenerator</a>/names-generator.go。查看代码，发现这些名称都是一些名人的名称，我只想说一句，docker 好任性。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package namesgenerator</span><br><span class="line"></span><br><span class="line">import (</span><br><span class="line">	&quot;fmt&quot;</span><br><span class="line"></span><br><span class="line">	&quot;github.com&#x2F;docker&#x2F;docker&#x2F;pkg&#x2F;random&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">var (</span><br><span class="line">	left &#x3D; \[...\]string&#123;</span><br><span class="line">		&quot;admiring&quot;,</span><br><span class="line">		&quot;adoring&quot;,</span><br><span class="line">		&quot;agitated&quot;,</span><br><span class="line">		&quot;amazing&quot;,</span><br><span class="line">		&quot;angry&quot;,</span><br><span class="line">		&quot;awesome&quot;,</span><br><span class="line">		&quot;backstabbing&quot;,</span><br><span class="line">		&quot;berserk&quot;,</span><br><span class="line">		&quot;big&quot;,</span><br><span class="line">		&quot;boring&quot;,</span><br><span class="line">		&quot;clever&quot;,</span><br><span class="line">		&quot;cocky&quot;,</span><br><span class="line">		&quot;compassionate&quot;,</span><br><span class="line">		&quot;condescending&quot;,</span><br><span class="line">		&quot;cranky&quot;,</span><br><span class="line">		&quot;desperate&quot;,</span><br><span class="line">		&quot;determined&quot;,</span><br><span class="line">		&quot;distracted&quot;,</span><br><span class="line">		&quot;dreamy&quot;,</span><br><span class="line">		&quot;drunk&quot;,</span><br><span class="line">		&quot;ecstatic&quot;,</span><br><span class="line">		&quot;elated&quot;,</span><br><span class="line">		&quot;elegant&quot;,</span><br><span class="line">		&quot;evil&quot;,</span><br><span class="line">		&quot;fervent&quot;,</span><br><span class="line">		&quot;focused&quot;,</span><br><span class="line">		&quot;furious&quot;,</span><br><span class="line">		&quot;gigantic&quot;,</span><br><span class="line">		&quot;gloomy&quot;,</span><br><span class="line">		&quot;goofy&quot;,</span><br><span class="line">		&quot;grave&quot;,</span><br><span class="line">		&quot;happy&quot;,</span><br><span class="line">		&quot;high&quot;,</span><br><span class="line">		&quot;hopeful&quot;,</span><br><span class="line">		&quot;hungry&quot;,</span><br><span class="line">		&quot;infallible&quot;,</span><br><span class="line">		&quot;jolly&quot;,</span><br><span class="line">		&quot;jovial&quot;,</span><br><span class="line">		&quot;kickass&quot;,</span><br><span class="line">		&quot;lonely&quot;,</span><br><span class="line">		&quot;loving&quot;,</span><br><span class="line">		&quot;mad&quot;,</span><br><span class="line">		&quot;modest&quot;,</span><br><span class="line">		&quot;naughty&quot;,</span><br><span class="line">		&quot;nauseous&quot;,</span><br><span class="line">		&quot;nostalgic&quot;,</span><br><span class="line">		&quot;peaceful&quot;,</span><br><span class="line">		&quot;pedantic&quot;,</span><br><span class="line">		&quot;pensive&quot;,</span><br><span class="line">		&quot;prickly&quot;,</span><br><span class="line">		&quot;reverent&quot;,</span><br><span class="line">		&quot;romantic&quot;,</span><br><span class="line">		&quot;sad&quot;,</span><br><span class="line">		&quot;serene&quot;,</span><br><span class="line">		&quot;sharp&quot;,</span><br><span class="line">		&quot;sick&quot;,</span><br><span class="line">		&quot;silly&quot;,</span><br><span class="line">		&quot;sleepy&quot;,</span><br><span class="line">		&quot;small&quot;,</span><br><span class="line">		&quot;stoic&quot;,</span><br><span class="line">		&quot;stupefied&quot;,</span><br><span class="line">		&quot;suspicious&quot;,</span><br><span class="line">		&quot;tender&quot;,</span><br><span class="line">		&quot;thirsty&quot;,</span><br><span class="line">		&quot;tiny&quot;,</span><br><span class="line">		&quot;trusting&quot;,</span><br><span class="line">		&quot;zen&quot;,</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; docker, starting from 0.7.x, generates names from notable scientists and hackers.</span><br><span class="line">	&#x2F;&#x2F; Please, for any amazing man that you add to the list, consider adding an equally amazing woman to it, and vice versa.</span><br><span class="line">	right &#x3D; \[...\]string&#123;</span><br><span class="line">		&#x2F;&#x2F; Muhammad ibn Jābir al-Ḥarrānī al-Battānī was a founding father of astronomy. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mu%E1%B8%A5ammad\_ibn\_J%C4%81bir\_al-%E1%B8%A4arr%C4%81n%C4%AB\_al-Batt%C4%81n%C4%AB</span><br><span class="line">		&quot;albattani&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Frances E. Allen, became the first female IBM Fellow in 1989. In 2006, she became the first female recipient of the ACM&#39;s Turing Award. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Frances\_E.\_Allen</span><br><span class="line">		&quot;allen&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; June Almeida - Scottish virologist who took the first pictures of the rubella virus - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;June\_Almeida</span><br><span class="line">		&quot;almeida&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Maria Gaetana Agnesi - Italian mathematician, philosopher, theologian and humanitarian. She was the first woman to write a mathematics handbook and the first woman appointed as a Mathematics Professor at a University. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Maria\_Gaetana\_Agnesi</span><br><span class="line">		&quot;agnesi&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Archimedes was a physicist, engineer and mathematician who invented too many things to list them here. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Archimedes</span><br><span class="line">		&quot;archimedes&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Maria Ardinghelli - Italian translator, mathematician and physicist - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Maria\_Ardinghelli</span><br><span class="line">		&quot;ardinghelli&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Aryabhata - Ancient Indian mathematician-astronomer during 476-550 CE https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Aryabhata</span><br><span class="line">		&quot;aryabhata&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Wanda Austin - Wanda Austin is the President and CEO of The Aerospace Corporation, a leading architect for the US security space programs. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Wanda\_Austin</span><br><span class="line">		&quot;austin&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Charles Babbage invented the concept of a programmable computer. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Charles\_Babbage.</span><br><span class="line">		&quot;babbage&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Stefan Banach - Polish mathematician, was one of the founders of modern functional analysis. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Stefan\_Banach</span><br><span class="line">		&quot;banach&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; John Bardeen co-invented the transistor - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;John\_Bardeen</span><br><span class="line">		&quot;bardeen&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Jean Bartik, born Betty Jean Jennings, was one of the original programmers for the ENIAC computer. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Jean\_Bartik</span><br><span class="line">		&quot;bartik&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Laura Bassi, the world&#39;s first female professor https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Laura\_Bassi</span><br><span class="line">		&quot;bassi&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Alexander Graham Bell - an eminent Scottish-born scientist, inventor, engineer and innovator who is credited with inventing the first practical telephone - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Alexander\_Graham\_Bell</span><br><span class="line">		&quot;bell&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Homi J Bhabha - was an Indian nuclear physicist, founding director, and professor of physics at the Tata Institute of Fundamental Research. Colloquially known as &quot;father of Indian nuclear programme&quot;- https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Homi\_J.\_Bhabha</span><br><span class="line">		&quot;bhabha&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Bhaskara II - Ancient Indian mathematician-astronomer whose work on calculus predates Newton and Leibniz by over half a millennium - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Bh%C4%81skara\_II#Calculus</span><br><span class="line">		&quot;bhaskara&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Elizabeth Blackwell - American doctor and first American woman to receive a medical degree - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Elizabeth\_Blackwell</span><br><span class="line">		&quot;blackwell&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Niels Bohr is the father of quantum theory. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Niels\_Bohr.</span><br><span class="line">		&quot;bohr&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Kathleen Booth, she&#39;s credited with writing the first assembly language. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Kathleen\_Booth</span><br><span class="line">		&quot;booth&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Anita Borg - Anita Borg was the founding director of the Institute for Women and Technology (IWT). https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Anita\_Borg</span><br><span class="line">		&quot;borg&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Satyendra Nath Bose - He provided the foundation for Bose–Einstein statistics and the theory of the Bose–Einstein condensate. - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Satyendra\_Nath\_Bose</span><br><span class="line">		&quot;bose&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Evelyn Boyd Granville - She was one of the first African-American woman to receive a Ph.D. in mathematics; she earned it in 1949 from Yale University. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Evelyn\_Boyd\_Granville</span><br><span class="line">		&quot;boyd&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Brahmagupta - Ancient Indian mathematician during 598-670 CE who gave rules to compute with zero - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Brahmagupta#Zero</span><br><span class="line">		&quot;brahmagupta&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Walter Houser Brattain co-invented the transistor - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Walter\_Houser\_Brattain</span><br><span class="line">		&quot;brattain&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Emmett Brown invented time travel. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Emmett\_Brown (thanks Brian Goff)</span><br><span class="line">		&quot;brown&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Rachel Carson - American marine biologist and conservationist, her book Silent Spring and other writings are credited with advancing the global environmental movement. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Rachel\_Carson</span><br><span class="line">		&quot;carson&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Subrahmanyan Chandrasekhar - Astrophysicist known for his mathematical theory on different stages and evolution in structures of the stars. He has won nobel prize for physics - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Subrahmanyan\_Chandrasekhar</span><br><span class="line">		&quot;chandrasekhar&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F;Claude Shannon - The father of information theory and founder of digital circuit design theory. (https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Claude\_Shannon)</span><br><span class="line">		&quot;shannon&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Jane Colden - American botanist widely considered the first female American botanist - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Jane\_Colden</span><br><span class="line">		&quot;colden&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Gerty Theresa Cori - American biochemist who became the third woman—and first American woman—to win a Nobel Prize in science, and the first woman to be awarded the Nobel Prize in Physiology or Medicine. Cori was born in Prague. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Gerty\_Cori</span><br><span class="line">		&quot;cori&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Seymour Roger Cray was an American electrical engineer and supercomputer architect who designed a series of computers that were the fastest in the world for decades. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Seymour\_Cray</span><br><span class="line">		&quot;cray&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; This entry reflects a husband and wife team who worked together:</span><br><span class="line">		&#x2F;&#x2F; Joan Curran was a Welsh scientist who developed radar and invented chaff, a radar countermeasure. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Joan\_Curran</span><br><span class="line">		&#x2F;&#x2F; Samuel Curran was an Irish physicist who worked alongside his wife during WWII and invented the proximity fuse. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Samuel\_Curran</span><br><span class="line">		&quot;curran&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Marie Curie discovered radioactivity. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Marie\_Curie.</span><br><span class="line">		&quot;curie&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Charles Darwin established the principles of natural evolution. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Charles\_Darwin.</span><br><span class="line">		&quot;darwin&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Leonardo Da Vinci invented too many things to list here. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Leonardo\_da\_Vinci.</span><br><span class="line">		&quot;davinci&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Edsger Wybe Dijkstra was a Dutch computer scientist and mathematical scientist. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Edsger\_W.\_Dijkstra.</span><br><span class="line">		&quot;dijkstra&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Donna Dubinsky - played an integral role in the development of personal digital assistants (PDAs) serving as CEO of Palm, Inc. and co-founding Handspring. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Donna\_Dubinsky</span><br><span class="line">		&quot;dubinsky&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Annie Easley - She was a leading member of the team which developed software for the Centaur rocket stage and one of the first African-Americans in her field. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Annie\_Easley</span><br><span class="line">		&quot;easley&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Thomas Alva Edison, prolific inventor https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Thomas\_Edison</span><br><span class="line">		&quot;edison&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Albert Einstein invented the general theory of relativity. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Albert\_Einstein</span><br><span class="line">		&quot;einstein&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Gertrude Elion - American biochemist, pharmacologist and the 1988 recipient of the Nobel Prize in Medicine - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Gertrude\_Elion</span><br><span class="line">		&quot;elion&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Douglas Engelbart gave the mother of all demos: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Douglas\_Engelbart</span><br><span class="line">		&quot;engelbart&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Euclid invented geometry. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Euclid</span><br><span class="line">		&quot;euclid&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Leonhard Euler invented large parts of modern mathematics. https:&#x2F;&#x2F;de.wikipedia.org&#x2F;wiki&#x2F;Leonhard\_Euler</span><br><span class="line">		&quot;euler&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Pierre de Fermat pioneered several aspects of modern mathematics. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Pierre\_de\_Fermat</span><br><span class="line">		&quot;fermat&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Enrico Fermi invented the first nuclear reactor. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Enrico\_Fermi.</span><br><span class="line">		&quot;fermi&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Richard Feynman was a key contributor to quantum mechanics and particle physics. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Richard\_Feynman</span><br><span class="line">		&quot;feynman&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Benjamin Franklin is famous for his experiments in electricity and the invention of the lightning rod.</span><br><span class="line">		&quot;franklin&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Galileo was a founding father of modern astronomy, and faced politics and obscurantism to establish scientific truth.  https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Galileo\_Galilei</span><br><span class="line">		&quot;galileo&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; William Henry &quot;Bill&quot; Gates III is an American business magnate, philanthropist, investor, computer programmer, and inventor. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Bill\_Gates</span><br><span class="line">		&quot;gates&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Adele Goldberg, was one of the designers and developers of the Smalltalk language. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Adele\_Goldberg\_(computer\_scientist)</span><br><span class="line">		&quot;goldberg&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Adele Goldstine, born Adele Katz, wrote the complete technical description for the first electronic digital computer, ENIAC. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Adele\_Goldstine</span><br><span class="line">		&quot;goldstine&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Shafi Goldwasser is a computer scientist known for creating theoretical foundations of modern cryptography. Winner of 2012 ACM Turing Award. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Shafi\_Goldwasser</span><br><span class="line">		&quot;goldwasser&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; James Golick, all around gangster.</span><br><span class="line">		&quot;golick&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Jane Goodall - British primatologist, ethologist, and anthropologist who is considered to be the world&#39;s foremost expert on chimpanzees - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Jane\_Goodall</span><br><span class="line">		&quot;goodall&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Margaret Hamilton - Director of the Software Engineering Division of the MIT Instrumentation Laboratory, which developed on-board flight software for the Apollo space program. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Margaret\_Hamilton\_(scientist)</span><br><span class="line">		&quot;hamilton&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Stephen Hawking pioneered the field of cosmology by combining general relativity and quantum mechanics. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Stephen\_Hawking</span><br><span class="line">		&quot;hawking&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Werner Heisenberg was a founding father of quantum mechanics. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Werner\_Heisenberg</span><br><span class="line">		&quot;heisenberg&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Jaroslav Heyrovský was the inventor of the polarographic method, father of the electroanalytical method, and recipient of the Nobel Prize in 1959. His main field of work was polarography. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Jaroslav\_Heyrovsk%C3%BD</span><br><span class="line">		&quot;heyrovsky&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Dorothy Hodgkin was a British biochemist, credited with the development of protein crystallography. She was awarded the Nobel Prize in Chemistry in 1964. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Dorothy\_Hodgkin</span><br><span class="line">		&quot;hodgkin&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Erna Schneider Hoover revolutionized modern communication by inventing a computerized telephone switching method. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Erna\_Schneider\_Hoover</span><br><span class="line">		&quot;hoover&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Grace Hopper developed the first compiler for a computer programming language and  is credited with popularizing the term &quot;debugging&quot; for fixing computer glitches. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Grace\_Hopper</span><br><span class="line">		&quot;hopper&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Frances Hugle, she was an American scientist, engineer, and inventor who contributed to the understanding of semiconductors, integrated circuitry, and the unique electrical principles of microscopic materials. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Frances\_Hugle</span><br><span class="line">		&quot;hugle&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Hypatia - Greek Alexandrine Neoplatonist philosopher in Egypt who was one of the earliest mothers of mathematics - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hypatia</span><br><span class="line">		&quot;hypatia&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Yeong-Sil Jang was a Korean scientist and astronomer during the Joseon Dynasty; he invented the first metal printing press and water gauge. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Jang\_Yeong-sil</span><br><span class="line">		&quot;jang&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Betty Jennings - one of the original programmers of the ENIAC. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;ENIAC - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Jean\_Bartik</span><br><span class="line">		&quot;jennings&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Mary Lou Jepsen, was the founder and chief technology officer of One Laptop Per Child (OLPC), and the founder of Pixel Qi. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mary\_Lou\_Jepsen</span><br><span class="line">		&quot;jepsen&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Irène Joliot-Curie - French scientist who was awarded the Nobel Prize for Chemistry in 1935. Daughter of Marie and Pierre Curie. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ir%C3%A8ne\_Joliot-Curie</span><br><span class="line">		&quot;joliot&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Karen Spärck Jones came up with the concept of inverse document frequency, which is used in most search engines today. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Karen\_Sp%C3%A4rck\_Jones</span><br><span class="line">		&quot;jones&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; A. P. J. Abdul Kalam - is an Indian scientist aka Missile Man of India for his work on the development of ballistic missile and launch vehicle technology - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;A.\_P.\_J.\_Abdul\_Kalam</span><br><span class="line">		&quot;kalam&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Susan Kare, created the icons and many of the interface elements for the original Apple Macintosh in the 1980s, and was an original employee of NeXT, working as the Creative Director. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Susan\_Kare</span><br><span class="line">		&quot;kare&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Mary Kenneth Keller, Sister Mary Kenneth Keller became the first American woman to earn a PhD in Computer Science in 1965. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mary\_Kenneth\_Keller</span><br><span class="line">		&quot;keller&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Har Gobind Khorana - Indian-American biochemist who shared the 1968 Nobel Prize for Physiology - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Har\_Gobind\_Khorana</span><br><span class="line">		&quot;khorana&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Jack Kilby invented silicone integrated circuits and gave Silicon Valley its name. - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Jack\_Kilby</span><br><span class="line">		&quot;kilby&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Maria Kirch - German astronomer and first woman to discover a comet - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Maria\_Margarethe\_Kirch</span><br><span class="line">		&quot;kirch&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Donald Knuth - American computer scientist, author of &quot;The Art of Computer Programming&quot; and creator of the TeX typesetting system. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Donald\_Knuth</span><br><span class="line">		&quot;knuth&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Sophie Kowalevski - Russian mathematician responsible for important original contributions to analysis, differential equations and mechanics - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Sofia\_Kovalevskaya</span><br><span class="line">		&quot;kowalevski&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Marie-Jeanne de Lalande - French astronomer, mathematician and cataloguer of stars - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Marie-Jeanne\_de\_Lalande</span><br><span class="line">		&quot;lalande&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Hedy Lamarr - Actress and inventor. The principles of her work are now incorporated into modern Wi-Fi, CDMA and Bluetooth technology. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hedy\_Lamarr</span><br><span class="line">		&quot;lamarr&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Leslie B. Lamport - American computer scientist. Lamport is best known for his seminal work in distributed systems and was the winner of the 2013 Turing Award. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Leslie\_Lamport</span><br><span class="line">		&quot;lamport&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Mary Leakey - British paleoanthropologist who discovered the first fossilized Proconsul skull - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mary\_Leakey</span><br><span class="line">		&quot;leakey&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Henrietta Swan Leavitt - she was an American astronomer who discovered the relation between the luminosity and the period of Cepheid variable stars. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Henrietta\_Swan\_Leavitt</span><br><span class="line">		&quot;leavitt&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Ruth Lichterman - one of the original programmers of the ENIAC. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;ENIAC - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ruth\_Teitelbaum</span><br><span class="line">		&quot;lichterman&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Barbara Liskov - co-developed the Liskov substitution principle. Liskov was also the winner of the Turing Prize in 2008. - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Barbara\_Liskov</span><br><span class="line">		&quot;liskov&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Ada Lovelace invented the first algorithm. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ada\_Lovelace (thanks James Turnbull)</span><br><span class="line">		&quot;lovelace&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Auguste and Louis Lumière - the first filmmakers in history - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Auguste\_and\_Louis\_Lumi%C3%A8re</span><br><span class="line">		&quot;lumiere&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Mahavira - Ancient Indian mathematician during 9th century AD who discovered basic algebraic identities - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mah%C4%81v%C4%ABra\_(mathematician)</span><br><span class="line">		&quot;mahavira&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Maria Mayer - American theoretical physicist and Nobel laureate in Physics for proposing the nuclear shell model of the atomic nucleus - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Maria\_Mayer</span><br><span class="line">		&quot;mayer&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; John McCarthy invented LISP: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;John\_McCarthy\_(computer\_scientist)</span><br><span class="line">		&quot;mccarthy&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Barbara McClintock - a distinguished American cytogeneticist, 1983 Nobel Laureate in Physiology or Medicine for discovering transposons. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Barbara\_McClintock</span><br><span class="line">		&quot;mcclintock&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Malcolm McLean invented the modern shipping container: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Malcom\_McLean</span><br><span class="line">		&quot;mclean&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Kay McNulty - one of the original programmers of the ENIAC. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;ENIAC - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Kathleen\_Antonelli</span><br><span class="line">		&quot;mcnulty&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Lise Meitner - Austrian&#x2F;Swedish physicist who was involved in the discovery of nuclear fission. The element meitnerium is named after her - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Lise\_Meitner</span><br><span class="line">		&quot;meitner&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Carla Meninsky, was the game designer and programmer for Atari 2600 games Dodge &#39;Em and Warlords. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Carla\_Meninsky</span><br><span class="line">		&quot;meninsky&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Johanna Mestorf - German prehistoric archaeologist and first female museum director in Germany - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Johanna\_Mestorf</span><br><span class="line">		&quot;mestorf&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Marvin Minsky - Pioneer in Artificial Intelligence, co-founder of the MIT&#39;s AI Lab, won the Turing Award in 1969. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Marvin\_Minsky</span><br><span class="line">		&quot;minsky&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Maryam Mirzakhani - an Iranian mathematician and the first woman to win the Fields Medal. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Maryam\_Mirzakhani</span><br><span class="line">		&quot;mirzakhani&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Samuel Morse - contributed to the invention of a single-wire telegraph system based on European telegraphs and was a co-developer of the Morse code - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Samuel\_Morse</span><br><span class="line">		&quot;morse&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Ian Murdock - founder of the Debian project - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ian\_Murdock</span><br><span class="line">		&quot;murdock&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Isaac Newton invented classic mechanics and modern optics. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Isaac\_Newton</span><br><span class="line">		&quot;newton&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Florence Nightingale, more prominently known as a nurse, was also the first female member of the Royal Statistical Society and a pioneer in statistical graphics https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Florence\_Nightingale#Statistics\_and\_sanitary\_reform</span><br><span class="line">		&quot;nightingale&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Alfred Nobel - a Swedish chemist, engineer, innovator, and armaments manufacturer (inventor of dynamite) - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Alfred\_Nobel</span><br><span class="line">		&quot;nobel&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Emmy Noether, German mathematician. Noether&#39;s Theorem is named after her. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Emmy\_Noether</span><br><span class="line">		&quot;noether&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Poppy Northcutt. Poppy Northcutt was the first woman to work as part of NASA’s Mission Control. http:&#x2F;&#x2F;www.businessinsider.com&#x2F;poppy-northcutt-helped-apollo-astronauts-2014-12?op&#x3D;1</span><br><span class="line">		&quot;northcutt&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Robert Noyce invented silicone integrated circuits and gave Silicon Valley its name. - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Robert\_Noyce</span><br><span class="line">		&quot;noyce&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Panini - Ancient Indian linguist and grammarian from 4th century CE who worked on the world&#39;s first formal system - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;P%C4%81%E1%B9%87ini#Comparison\_with\_modern\_formal\_systems</span><br><span class="line">		&quot;panini&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Ambroise Pare invented modern surgery. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ambroise\_Par%C3%A9</span><br><span class="line">		&quot;pare&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Louis Pasteur discovered vaccination, fermentation and pasteurization. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Louis\_Pasteur.</span><br><span class="line">		&quot;pasteur&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Cecilia Payne-Gaposchkin was an astronomer and astrophysicist who, in 1925, proposed in her Ph.D. thesis an explanation for the composition of stars in terms of the relative abundances of hydrogen and helium. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cecilia\_Payne-Gaposchkin</span><br><span class="line">		&quot;payne&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Radia Perlman is a software designer and network engineer and most famous for her invention of the spanning-tree protocol (STP). https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Radia\_Perlman</span><br><span class="line">		&quot;perlman&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Rob Pike was a key contributor to Unix, Plan 9, the X graphic system, utf-8, and the Go programming language. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Rob\_Pike</span><br><span class="line">		&quot;pike&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Henri Poincaré made fundamental contributions in several fields of mathematics. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Henri\_Poincar%C3%A9</span><br><span class="line">		&quot;poincare&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Laura Poitras is a director and producer whose work, made possible by open source crypto tools, advances the causes of truth and freedom of information by reporting disclosures by whistleblowers such as Edward Snowden. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Laura\_Poitras</span><br><span class="line">		&quot;poitras&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Claudius Ptolemy - a Greco-Egyptian writer of Alexandria, known as a mathematician, astronomer, geographer, astrologer, and poet of a single epigram in the Greek Anthology - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ptolemy</span><br><span class="line">		&quot;ptolemy&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; C. V. Raman - Indian physicist who won the Nobel Prize in 1930 for proposing the Raman effect. - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;C.\_V.\_Raman</span><br><span class="line">		&quot;raman&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Srinivasa Ramanujan - Indian mathematician and autodidact who made extraordinary contributions to mathematical analysis, number theory, infinite series, and continued fractions. - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Srinivasa\_Ramanujan</span><br><span class="line">		&quot;ramanujan&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Sally Kristen Ride was an American physicist and astronaut. She was the first American woman in space, and the youngest American astronaut. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Sally\_Ride</span><br><span class="line">		&quot;ride&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Rita Levi-Montalcini - Won Nobel Prize in Physiology or Medicine jointly with colleague Stanley Cohen for the discovery of nerve growth factor (https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Rita\_Levi-Montalcini)</span><br><span class="line">		&quot;montalcini&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Dennis Ritchie - co-creator of UNIX and the C programming language. - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Dennis\_Ritchie</span><br><span class="line">		&quot;ritchie&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Wilhelm Conrad Röntgen - German physicist who was awarded the first Nobel Prize in Physics in 1901 for the discovery of X-rays (Röntgen rays). https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Wilhelm\_R%C3%B6ntgen</span><br><span class="line">		&quot;roentgen&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Rosalind Franklin - British biophysicist and X-ray crystallographer whose research was critical to the understanding of DNA - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Rosalind\_Franklin</span><br><span class="line">		&quot;rosalind&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Meghnad Saha - Indian astrophysicist best known for his development of the Saha equation, used to describe chemical and physical conditions in stars - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Meghnad\_Saha</span><br><span class="line">		&quot;saha&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Jean E. Sammet developed FORMAC, the first widely used computer language for symbolic manipulation of mathematical formulas. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Jean\_E.\_Sammet</span><br><span class="line">		&quot;sammet&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Carol Shaw - Originally an Atari employee, Carol Shaw is said to be the first female video game designer. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Carol\_Shaw\_(video\_game\_designer)</span><br><span class="line">		&quot;shaw&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Dame Stephanie &quot;Steve&quot; Shirley - Founded a software company in 1962 employing women working from home. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Steve\_Shirley</span><br><span class="line">		&quot;shirley&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; William Shockley co-invented the transistor - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;William\_Shockley</span><br><span class="line">		&quot;shockley&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Françoise Barré-Sinoussi - French virologist and Nobel Prize Laureate in Physiology or Medicine; her work was fundamental in identifying HIV as the cause of AIDS. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fran%C3%A7oise\_Barr%C3%A9-Sinoussi</span><br><span class="line">		&quot;sinoussi&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Betty Snyder - one of the original programmers of the ENIAC. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;ENIAC - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Betty\_Holberton</span><br><span class="line">		&quot;snyder&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Frances Spence - one of the original programmers of the ENIAC. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;ENIAC - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Frances\_Spence</span><br><span class="line">		&quot;spence&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Richard Matthew Stallman - the founder of the Free Software movement, the GNU project, the Free Software Foundation, and the League for Programming Freedom. He also invented the concept of copyleft to protect the ideals of this movement, and enshrined this concept in the widely-used GPL (General Public License) for software. https:&#x2F;&#x2F;en.wikiquote.org&#x2F;wiki&#x2F;Richard\_Stallman</span><br><span class="line">		&quot;stallman&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Michael Stonebraker is a database research pioneer and architect of Ingres, Postgres, VoltDB and SciDB. Winner of 2014 ACM Turing Award. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Michael\_Stonebraker</span><br><span class="line">		&quot;stonebraker&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Janese Swanson (with others) developed the first of the Carmen Sandiego games. She went on to found Girl Tech. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Janese\_Swanson</span><br><span class="line">		&quot;swanson&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Aaron Swartz was influential in creating RSS, Markdown, Creative Commons, Reddit, and much of the internet as we know it today. He was devoted to freedom of information on the web. https:&#x2F;&#x2F;en.wikiquote.org&#x2F;wiki&#x2F;Aaron\_Swartz</span><br><span class="line">		&quot;swartz&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Bertha Swirles was a theoretical physicist who made a number of contributions to early quantum theory. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Bertha\_Swirles</span><br><span class="line">		&quot;swirles&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Nikola Tesla invented the AC electric system and every gadget ever used by a James Bond villain. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Nikola\_Tesla</span><br><span class="line">		&quot;tesla&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Ken Thompson - co-creator of UNIX and the C programming language - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ken\_Thompson</span><br><span class="line">		&quot;thompson&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Linus Torvalds invented Linux and Git. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Linus\_Torvalds</span><br><span class="line">		&quot;torvalds&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Alan Turing was a founding father of computer science. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Alan\_Turing.</span><br><span class="line">		&quot;turing&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Varahamihira - Ancient Indian mathematician who discovered trigonometric formulae during 505-587 CE - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Var%C4%81hamihira#Contributions</span><br><span class="line">		&quot;varahamihira&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Sir Mokshagundam Visvesvaraya - is a notable Indian engineer.  He is a recipient of the Indian Republic&#39;s highest honour, the Bharat Ratna, in 1955. On his birthday, 15 September is celebrated as Engineer&#39;s Day in India in his memory - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Visvesvaraya</span><br><span class="line">		&quot;visvesvaraya&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Christiane Nüsslein-Volhard - German biologist, won Nobel Prize in Physiology or Medicine in 1995 for research on the genetic control of embryonic development. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Christiane\_N%C3%BCsslein-Volhard</span><br><span class="line">		&quot;volhard&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Marlyn Wescoff - one of the original programmers of the ENIAC. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;ENIAC - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Marlyn\_Meltzer</span><br><span class="line">		&quot;wescoff&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Andrew Wiles - Notable British mathematician who proved the enigmatic Fermat&#39;s Last Theorem - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Andrew\_Wiles</span><br><span class="line">		&quot;wiles&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Roberta Williams, did pioneering work in graphical adventure games for personal computers, particularly the King&#39;s Quest series. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Roberta\_Williams</span><br><span class="line">		&quot;williams&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Sophie Wilson designed the first Acorn Micro-Computer and the instruction set for ARM processors. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Sophie\_Wilson</span><br><span class="line">		&quot;wilson&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Jeannette Wing - co-developed the Liskov substitution principle. - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Jeannette\_Wing</span><br><span class="line">		&quot;wing&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Steve Wozniak invented the Apple I and Apple II. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Steve\_Wozniak</span><br><span class="line">		&quot;wozniak&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; The Wright brothers, Orville and Wilbur - credited with inventing and building the world&#39;s first successful airplane and making the first controlled, powered and sustained heavier-than-air human flight - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Wright\_brothers</span><br><span class="line">		&quot;wright&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Rosalyn Sussman Yalow - Rosalyn Sussman Yalow was an American medical physicist, and a co-winner of the 1977 Nobel Prize in Physiology or Medicine for development of the radioimmunoassay technique. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Rosalyn\_Sussman\_Yalow</span><br><span class="line">		&quot;yalow&quot;,</span><br><span class="line"></span><br><span class="line">		&#x2F;&#x2F; Ada Yonath - an Israeli crystallographer, the first woman from the Middle East to win a Nobel prize in the sciences. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ada\_Yonath</span><br><span class="line">		&quot;yonath&quot;,</span><br><span class="line">	&#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; GetRandomName generates a random name from the list of adjectives and surnames in this package</span><br><span class="line">&#x2F;&#x2F; formatted as &quot;adjective\_surname&quot;. For example &#39;focused\_turing&#39;. If retry is non-zero, a random</span><br><span class="line">&#x2F;&#x2F; integer between 0 and 10 will be added to the end of the name, e.g \&#96;focused\_turing3\&#96;</span><br><span class="line">func GetRandomName(retry int) string &#123;</span><br><span class="line">	rnd :&#x3D; random.Rand</span><br><span class="line">begin:</span><br><span class="line">	name :&#x3D; fmt.Sprintf(&quot;%s\_%s&quot;, left\[rnd.Intn(len(left))\], right\[rnd.Intn(len(right))\])</span><br><span class="line">	if name &#x3D;&#x3D; &quot;boring\_wozniak&quot; &#x2F;\* Steve Wozniak is not boring \*&#x2F; &#123;</span><br><span class="line">		goto begin</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if retry &gt; 0 &#123;</span><br><span class="line">		name &#x3D; fmt.Sprintf(&quot;%s%d&quot;, name, rnd.Intn(10))</span><br><span class="line">	&#125;</span><br><span class="line">	return name</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title>nvidia-docker 配置GPU</title>
    <url>/2020/12/21/nvidia-docker-%E9%85%8D%E7%BD%AEGPU/</url>
    <content><![CDATA[<p>docker  hook 的 doPrestart<br><a href="https://github.com/opencontainers/runtime-spec" target="_blank" rel="noopener">https://github.com/opencontainers/runtime-spec</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Prestart</span><br><span class="line">The prestart hooks MUST be called after the start operation is called but before the user-specified program command is executed. On Linux, for example, they are called after the container namespaces are created, so they provide an opportunity to customize the container (e.g. the network namespace could be specified in this hook).</span><br><span class="line">Note: prestart hooks were deprecated in favor of createRuntime, createContainer and startContainer hooks, which allow more granular hook control during the create and start phase.</span><br><span class="line">The prestart hooks&#39; path MUST resolve in the runtime namespace. The prestart hooks MUST be executed in the runtime namespace.</span><br></pre></td></tr></table></figure>
<p>Hook:<br>可以通过与外部应用程序挂钩来扩展容器的生命周期，从而扩展OCI兼容运行时的功能。用例示例包括复杂的网络配置，垃圾信息搜集等</p>
<h3 id="nvidia-container-toolkit-项目："><a href="#nvidia-container-toolkit-项目：" class="headerlink" title="nvidia-container-toolkit 项目："></a>nvidia-container-toolkit 项目：</h3><p>新版本的nvidia-docker增加了这个项目，主要是用来实现hook函数，并将GPU相关的参数传递给nvidia-container-cli 进行容器的GPU配置,具体的参数如下所示，在创建、重启容器时，都会执行这样的操作<br><font size="8"> /usr/bin/nvidia-container-cli  –load-kmods  –debug=/var/log/nvidia-container-toolkit.log  configure –ldconfig=@/sbin/ldconfig –device=all –compute –utility  –pid=78717  /var/lib/docker/overlay2/6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b/merged </font></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">func doPrestart() &#123;</span><br><span class="line">	var err error</span><br><span class="line"></span><br><span class="line">	defer exit()</span><br><span class="line">	log.SetFlags(0)</span><br><span class="line"></span><br><span class="line">	hook := getHookConfig()</span><br><span class="line">	cli := hook.NvidiaContainerCLI</span><br><span class="line">    //查询容器的配置参数</span><br><span class="line">	container := getContainerConfig(hook)</span><br><span class="line">    //获取GPU相关的配置参数</span><br><span class="line">	nvidia := container.Nvidia</span><br><span class="line">	if nvidia == nil &#123;</span><br><span class="line">		// Not a GPU container, nothing to do.</span><br><span class="line">		return</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	rootfs := getRootfsPath(container)</span><br><span class="line">    //获得nvidia-container-cli 的安装路径，使用该命令进行容器的GPU 相关配置，下面的全都是为这个cli 构造参数</span><br><span class="line">	args := []string&#123;getCLIPath(cli)&#125;</span><br><span class="line">	if cli.Root != nil &#123;</span><br><span class="line">		args = append(args, fmt.Sprintf("--root=%s", *cli.Root))</span><br><span class="line">	&#125;</span><br><span class="line">	if cli.LoadKmods &#123;</span><br><span class="line">		args = append(args, "--load-kmods")</span><br><span class="line">	&#125;</span><br><span class="line">	if cli.NoPivot &#123;</span><br><span class="line">		args = append(args, "--no-pivot")</span><br><span class="line">	&#125;</span><br><span class="line">	if *debugflag &#123;</span><br><span class="line">		args = append(args, "--debug=/dev/stderr")</span><br><span class="line">	&#125; else if cli.Debug != nil &#123;</span><br><span class="line">		args = append(args, fmt.Sprintf("--debug=%s", *cli.Debug))</span><br><span class="line">	&#125;</span><br><span class="line">	if cli.Ldcache != nil &#123;</span><br><span class="line">		args = append(args, fmt.Sprintf("--ldcache=%s", *cli.Ldcache))</span><br><span class="line">	&#125;</span><br><span class="line">	if cli.User != nil &#123;</span><br><span class="line">		args = append(args, fmt.Sprintf("--user=%s", *cli.User))</span><br><span class="line">	&#125;</span><br><span class="line">	args = append(args, "configure")</span><br><span class="line"></span><br><span class="line">	if cli.Ldconfig != nil &#123;</span><br><span class="line">		args = append(args, fmt.Sprintf("--ldconfig=%s", *cli.Ldconfig))</span><br><span class="line">	&#125;</span><br><span class="line">	if cli.NoCgroups &#123;</span><br><span class="line">		args = append(args, "--no-cgroups")</span><br><span class="line">	&#125;</span><br><span class="line">    //将设置的GPU 环境变量或者挂载转变为device</span><br><span class="line">	if len(nvidia.Devices) &gt; 0 &#123;</span><br><span class="line">		args = append(args, fmt.Sprintf("--device=%s", nvidia.Devices))</span><br><span class="line">	&#125;</span><br><span class="line">    //mig 配置</span><br><span class="line">	if len(nvidia.MigConfigDevices) &gt; 0 &#123;</span><br><span class="line">		args = append(args, fmt.Sprintf("--mig-config=%s", nvidia.MigConfigDevices))</span><br><span class="line">	&#125;</span><br><span class="line">	if len(nvidia.MigMonitorDevices) &gt; 0 &#123;</span><br><span class="line">		args = append(args, fmt.Sprintf("--mig-monitor=%s", nvidia.MigMonitorDevices))</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	for _, cap := range strings.Split(nvidia.DriverCapabilities, ",") &#123;</span><br><span class="line">		if len(cap) == 0 &#123;</span><br><span class="line">			break</span><br><span class="line">		&#125;</span><br><span class="line">		args = append(args, capabilityToCLI(cap))</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if !hook.DisableRequire &amp;&amp; !nvidia.DisableRequire &#123;</span><br><span class="line">		for _, req := range nvidia.Requirements &#123;</span><br><span class="line">			args = append(args, fmt.Sprintf("--require=%s", req))</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	args = append(args, fmt.Sprintf("--pid=%s", strconv.FormatUint(uint64(container.Pid), 10)))</span><br><span class="line">	args = append(args, rootfs)</span><br><span class="line">  </span><br><span class="line">   	env := append(os.Environ(), cli.Environment...)</span><br><span class="line">	//这里的参数通常是这样的：</span><br><span class="line">	// &lt;font size=8&gt; /usr/bin/nvidia-container-cli  --load-kmods  --debug=/var/log/nvidia-container-toolkit.log  configure --ldconfig=@/sbin/ldconfig --device=all --compute --utility  --pid=78717  /var/lib/docker/overlay2/6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b/merged &lt;/font&gt;</span><br><span class="line">	err = syscall.Exec(args[0], args, env)</span><br><span class="line">	log.Panicln("exec failed:", err)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从环境变量获取GPU 信息，先查询envSwarmGPU，再查询envVars，如果都未设置，则获取镜像中的设置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func getDevicesFromEnvvar(env map[string]string, legacyImage bool) *string &#123;</span><br><span class="line">	&#x2F;&#x2F; Build a list of envvars to consider.</span><br><span class="line">	envVars :&#x3D; []string&#123;envNVVisibleDevices&#125;</span><br><span class="line">	if envSwarmGPU !&#x3D; nil &#123;</span><br><span class="line">		&#x2F;&#x2F; The Swarm envvar has higher precedence.</span><br><span class="line">		envVars &#x3D; append([]string&#123;*envSwarmGPU&#125;, envVars...)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; Grab a reference to devices from the first envvar</span><br><span class="line">	&#x2F;&#x2F; in the list that actually exists in the environment.</span><br><span class="line">	var devices *string</span><br><span class="line">	for _, envVar :&#x3D; range envVars &#123;</span><br><span class="line">		if devs, ok :&#x3D; env[envVar]; ok &#123;</span><br><span class="line">			devices &#x3D; &amp;devs</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; Environment variable unset with legacy image: default to &quot;all&quot;.</span><br><span class="line">	if devices &#x3D;&#x3D; nil &amp;&amp; legacyImage &#123;</span><br><span class="line">		all :&#x3D; &quot;all&quot;</span><br><span class="line">		return &amp;all</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; Environment variable unset or empty or &quot;void&quot;: return nil</span><br><span class="line">	if devices &#x3D;&#x3D; nil || len(*devices) &#x3D;&#x3D; 0 || *devices &#x3D;&#x3D; &quot;void&quot; &#123;</span><br><span class="line">		return nil</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; Environment variable set to &quot;none&quot;: reset to &quot;&quot;.</span><br><span class="line">	if *devices &#x3D;&#x3D; &quot;none&quot; &#123;</span><br><span class="line">		empty :&#x3D; &quot;&quot;</span><br><span class="line">		return &amp;empty</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; Any other value.</span><br><span class="line">	return devices</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="nvidia-contaienr-runtime-项目"><a href="#nvidia-contaienr-runtime-项目" class="headerlink" title="nvidia-contaienr-runtime 项目"></a>nvidia-contaienr-runtime 项目</h3><p>对接OCI runtime，将hook函数注入</p>
<p>该项目会将nvidia-container-toolkit中的preStart函数作为hook加入到runtime</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func addNVIDIAHook(spec *specs.Spec) error &#123;</span><br><span class="line">	path, err :&#x3D; exec.LookPath(&quot;nvidia-container-runtime-hook&quot;)</span><br><span class="line">	if err !&#x3D; nil &#123;</span><br><span class="line">		path &#x3D; hookDefaultFilePath</span><br><span class="line">		_, err &#x3D; os.Stat(path)</span><br><span class="line">		if err !&#x3D; nil &#123;</span><br><span class="line">			return err</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	if fileLogger !&#x3D; nil &#123;</span><br><span class="line">		fileLogger.Printf(&quot;prestart hook path: %s\n&quot;, path)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	args :&#x3D; []string&#123;path&#125;</span><br><span class="line">	if spec.Hooks &#x3D;&#x3D; nil &#123;</span><br><span class="line">		spec.Hooks &#x3D; &amp;specs.Hooks&#123;&#125;</span><br><span class="line">	&#125; else if len(spec.Hooks.Prestart) !&#x3D; 0 &#123;</span><br><span class="line">		for _, hook :&#x3D; range spec.Hooks.Prestart &#123;</span><br><span class="line">			if !strings.Contains(hook.Path, &quot;nvidia-container-runtime-hook&quot;) &#123;</span><br><span class="line">				continue</span><br><span class="line">			&#125;</span><br><span class="line">			if fileLogger !&#x3D; nil &#123;</span><br><span class="line">				fileLogger.Println(&quot;existing nvidia prestart hook in OCI spec file&quot;)</span><br><span class="line">			&#125;</span><br><span class="line">			return nil</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">    &#x2F;&#x2F;加入hook</span><br><span class="line">	spec.Hooks.Prestart &#x3D; append(spec.Hooks.Prestart, specs.Hook&#123;</span><br><span class="line">		Path: path,</span><br><span class="line">		Args: append(args, &quot;prestart&quot;),</span><br><span class="line">	&#125;)</span><br><span class="line"></span><br><span class="line">	return nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h3 id="项目libnvidia-container-项目"><a href="#项目libnvidia-container-项目" class="headerlink" title="项目libnvidia-container 项目"></a>项目libnvidia-container 项目</h3><p>nvidia-docker 的核心项目，用于将GPU驱动、相关的so库，容器可见的GPU 挂载到容器内，该项目中的 cli 相关的代码是用来使用封装nvidia-container-cli 客户端操作，项目libcontainer-toolkit 项目会使用这个cli工具进行配置。</p>
<p>挂载GPU驱动相关</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">configure_command()&#123;</span><br><span class="line"></span><br><span class="line">	....</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;挂载驱动</span><br><span class="line">        if (nvc_driver_mount(nvc, cnt, drv) &lt; 0) &#123;</span><br><span class="line">                warnx(&quot;mount error: %s&quot;, nvc_error(nvc));</span><br><span class="line">                goto fail;</span><br><span class="line">        &#125;</span><br><span class="line">        &#x2F;&#x2F;挂载设备</span><br><span class="line">        for (size_t i &#x3D; 0; i &lt; devices.ngpus; ++i) &#123;</span><br><span class="line">                if (nvc_device_mount(nvc, cnt, devices.gpus[i]) &lt; 0) &#123;</span><br><span class="line">                        warnx(&quot;mount error: %s&quot;, nvc_error(nvc));</span><br><span class="line">                        goto fail;</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">		....</span><br><span class="line"></span><br><span class="line">		&#125;</span><br></pre></td></tr></table></figure>


<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">int</span><br><span class="line">nvc_driver_mount(struct nvc_context *ctx, const struct nvc_container *cnt, const struct nvc_driver_info *info)</span><br><span class="line">&#123;</span><br><span class="line">        const char **mnt, **ptr, **tmp;</span><br><span class="line">        size_t nmnt;</span><br><span class="line">        int rv &#x3D; -1;</span><br><span class="line"></span><br><span class="line">        if (validate_context(ctx) &lt; 0)</span><br><span class="line">                return (-1);</span><br><span class="line">        if (validate_args(ctx, cnt !&#x3D; NULL &amp;&amp; info !&#x3D; NULL) &lt; 0)</span><br><span class="line">                return (-1);</span><br><span class="line"></span><br><span class="line">        if (ns_enter(&amp;ctx-&gt;err, cnt-&gt;mnt_ns, CLONE_NEWNS) &lt; 0)</span><br><span class="line">                return (-1);</span><br><span class="line"></span><br><span class="line">        nmnt &#x3D; 2 + info-&gt;nbins + info-&gt;nlibs + cnt-&gt;nlibs + info-&gt;nlibs32 + info-&gt;nipcs + info-&gt;ndevs;</span><br><span class="line">        mnt &#x3D; ptr &#x3D; (const char **)array_new(&amp;ctx-&gt;err, nmnt);</span><br><span class="line">        if (mnt &#x3D;&#x3D; NULL)</span><br><span class="line">                goto fail;</span><br><span class="line"></span><br><span class="line">        &#x2F;* Procfs mount *&#x2F;</span><br><span class="line">		&#x2F;&#x2F; 将proc 文件系统挂载到容器</span><br><span class="line">        if (ctx-&gt;dxcore.initialized)</span><br><span class="line">                log_warn(&quot;skipping procfs mount on WSL&quot;);</span><br><span class="line">        else if ((*ptr++ &#x3D; mount_procfs(&amp;ctx-&gt;err, ctx-&gt;cfg.root, cnt)) &#x3D;&#x3D; NULL)</span><br><span class="line">                goto fail;</span><br><span class="line"></span><br><span class="line">        &#x2F;* Application profile mount *&#x2F;</span><br><span class="line">        if (cnt-&gt;flags &amp; OPT_GRAPHICS_LIBS) &#123;</span><br><span class="line">                if (ctx-&gt;dxcore.initialized)</span><br><span class="line">                        log_warn(&quot;skipping app profile mount on WSL&quot;);</span><br><span class="line">                else if ((*ptr++ &#x3D; mount_app_profile(&amp;ctx-&gt;err, cnt)) &#x3D;&#x3D; NULL)</span><br><span class="line">                        goto fail;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        &#x2F;* Host binary and library mounts *&#x2F;</span><br><span class="line">        if (info-&gt;bins !&#x3D; NULL &amp;&amp; info-&gt;nbins &gt; 0) &#123;</span><br><span class="line">                if ((tmp &#x3D; (const char **)mount_files(&amp;ctx-&gt;err, ctx-&gt;cfg.root, cnt, cnt-&gt;cfg.bins_dir, info-&gt;bins, info-&gt;nbins)) &#x3D;&#x3D; NULL)</span><br><span class="line">                        goto fail;</span><br><span class="line">                ptr &#x3D; array_append(ptr, tmp, array_size(tmp));</span><br><span class="line">                free(tmp);</span><br><span class="line">        &#125;</span><br><span class="line">        if (info-&gt;libs !&#x3D; NULL &amp;&amp; info-&gt;nlibs &gt; 0) &#123;</span><br><span class="line">                if ((tmp &#x3D; (const char **)mount_files(&amp;ctx-&gt;err, ctx-&gt;cfg.root, cnt, cnt-&gt;cfg.libs_dir, info-&gt;libs, info-&gt;nlibs)) &#x3D;&#x3D; NULL)</span><br><span class="line">                        goto fail;</span><br><span class="line">    </span><br><span class="line">    .............</span><br><span class="line"></span><br><span class="line">  &#x2F;* Device mounts *&#x2F;</span><br><span class="line">        for (size_t i &#x3D; 0; i &lt; info-&gt;ndevs; ++i) &#123;</span><br><span class="line">                &#x2F;* XXX Only compute libraries require specific devices (e.g. UVM). *&#x2F;</span><br><span class="line">                if (!(cnt-&gt;flags &amp; OPT_COMPUTE_LIBS) &amp;&amp; major(info-&gt;devs[i].id) !&#x3D; NV_DEVICE_MAJOR)</span><br><span class="line">                        continue;</span><br><span class="line">                &#x2F;* XXX Only display capability requires the modeset device. *&#x2F;</span><br><span class="line">                if (!(cnt-&gt;flags &amp; OPT_DISPLAY) &amp;&amp; minor(info-&gt;devs[i].id) &#x3D;&#x3D; NV_MODESET_DEVICE_MINOR)</span><br><span class="line">                        continue;</span><br><span class="line">                if (!(cnt-&gt;flags &amp; OPT_NO_DEVBIND)) &#123;</span><br><span class="line">                        if ((*ptr++ &#x3D; mount_device(&amp;ctx-&gt;err, ctx-&gt;cfg.root, cnt, &amp;info-&gt;devs[i])) &#x3D;&#x3D; NULL)</span><br><span class="line">                                goto fail;</span><br><span class="line">                &#125;</span><br><span class="line">                if (!(cnt-&gt;flags &amp; OPT_NO_CGROUPS)) &#123;</span><br><span class="line">                        if (setup_cgroup(&amp;ctx-&gt;err, cnt-&gt;dev_cg, info-&gt;devs[i].id) &lt; 0)</span><br><span class="line">                                goto fail;</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        rv &#x3D; 0;</span><br></pre></td></tr></table></figure>

<h3 id="调试"><a href="#调试" class="headerlink" title="调试"></a>调试</h3><p>在节点安装完docker、nvidia-docker相关软件后，可以通过修改/etc/nvidia-container-runtime/config.toml,nvidia-container-toolkit的debug日志，如下所示</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">disable-require &#x3D; false</span><br><span class="line">#swarm-resource &#x3D; &quot;docker_RESOURCE_GPU&quot;</span><br><span class="line">#accept-nvidia-visible-devices-envvar-when-unprivileged &#x3D; true</span><br><span class="line">#accept-nvidia-visible-devices-as-volume-mounts &#x3D; false</span><br><span class="line"></span><br><span class="line">[nvidia-container-cli]</span><br><span class="line">#root &#x3D; &quot;&#x2F;run&#x2F;nvidia&#x2F;driver&quot;</span><br><span class="line">path &#x3D; &quot;&#x2F;usr&#x2F;bin&#x2F;nvidia-container-cli&quot;</span><br><span class="line">environment &#x3D; []</span><br><span class="line">debug &#x3D; &quot;&#x2F;var&#x2F;log&#x2F;nvidia-container-toolkit.log&quot;</span><br><span class="line">#ldcache &#x3D; &quot;&#x2F;etc&#x2F;ld.so.cache&quot;</span><br><span class="line">load-kmods &#x3D; true</span><br><span class="line">#no-cgroups &#x3D; false</span><br><span class="line">#user &#x3D; &quot;root:video&quot;</span><br><span class="line">ldconfig &#x3D; &quot;@&#x2F;sbin&#x2F;ldconfig&quot;</span><br><span class="line"></span><br><span class="line">[nvidia-container-runtime]</span><br><span class="line">#debug &#x3D; &quot;&#x2F;var&#x2F;log&#x2F;nvidia-container-runtime.log&quot;</span><br></pre></td></tr></table></figure>
<p>我们通过命令行 运行一个使用GPU卡的容器，可以在/var/log/nvidia-container-toolkit.log 看到以下日志,虽然比较长，但是详细的看到挂载过程</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -it --env NVIDIA_VISIBLE_DEVICES&#x3D;GPU-2fb041ff-6df3-4d00-772d-efb3139a17a1  tensorflow:1.14-cuda10-py36 bash</span><br></pre></td></tr></table></figure>
<p>具体的日志信息：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">-- WARNING, the following logs are for debugging purposes only --</span><br><span class="line"></span><br><span class="line">I1222 07:23:32.708870 78755 nvc.c:282] initializing library context (version&#x3D;1.3.0, build&#x3D;16315ebdf4b9728e899f615e208b50c41d7a5d15)</span><br><span class="line">I1222 07:23:32.709176 78755 nvc.c:256] using root &#x2F;</span><br><span class="line">I1222 07:23:32.709208 78755 nvc.c:257] using ldcache &#x2F;etc&#x2F;ld.so.cache</span><br><span class="line">I1222 07:23:32.709230 78755 nvc.c:258] using unprivileged user 65534:65534</span><br><span class="line">I1222 07:23:32.709284 78755 nvc.c:299] attempting to load dxcore to see if we are running under Windows Subsystem for Linux (WSL)</span><br><span class="line">I1222 07:23:32.709595 78755 nvc.c:301] dxcore initialization failed, continuing assuming a non-WSL environment</span><br><span class="line">I1222 07:23:32.719348 78759 nvc.c:192] loading kernel module nvidia</span><br><span class="line">I1222 07:23:32.720360 78759 nvc.c:204] loading kernel module nvidia_uvm</span><br><span class="line">I1222 07:23:32.720862 78759 nvc.c:212] loading kernel module nvidia_modeset</span><br><span class="line">I1222 07:23:32.721604 78760 driver.c:101] starting driver service</span><br><span class="line">I1222 07:23:33.987396 78755 nvc_container.c:364] configuring container with &#39;compute utility supervised&#39;</span><br><span class="line">I1222 07:23:33.988276 78755 nvc_container.c:212] selecting &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;usr&#x2F;local&#x2F;cuda-10.1&#x2F;compat&#x2F;libcuda.so.418.87.00</span><br><span class="line">I1222 07:23:33.988497 78755 nvc_container.c:212] selecting &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;usr&#x2F;local&#x2F;cuda-10.1&#x2F;compat&#x2F;libnvidia-fatbinaryloader.so.418.87.00</span><br><span class="line">I1222 07:23:33.988619 78755 nvc_container.c:212] selecting &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;usr&#x2F;local&#x2F;cuda-10.1&#x2F;compat&#x2F;libnvidia-ptxjitcompiler.so.418.87.00</span><br><span class="line">I1222 07:23:33.989099 78755 nvc_container.c:384] setting pid to 78717</span><br><span class="line">I1222 07:23:33.989130 78755 nvc_container.c:385] setting rootfs to &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged</span><br><span class="line">I1222 07:23:33.989153 78755 nvc_container.c:386] setting owner to 0:0</span><br><span class="line">I1222 07:23:33.989175 78755 nvc_container.c:387] setting bins directory to &#x2F;usr&#x2F;bin</span><br><span class="line">I1222 07:23:33.989197 78755 nvc_container.c:388] setting libs directory to &#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu</span><br><span class="line">I1222 07:23:33.989218 78755 nvc_container.c:389] setting libs32 directory to &#x2F;usr&#x2F;lib&#x2F;i386-linux-gnu</span><br><span class="line">I1222 07:23:33.989240 78755 nvc_container.c:390] setting cudart directory to &#x2F;usr&#x2F;local&#x2F;cuda</span><br><span class="line">I1222 07:23:33.989261 78755 nvc_container.c:391] setting ldconfig to @&#x2F;sbin&#x2F;ldconfig (host relative)</span><br><span class="line">I1222 07:23:33.989283 78755 nvc_container.c:392] setting mount namespace to &#x2F;proc&#x2F;78717&#x2F;ns&#x2F;mnt</span><br><span class="line">I1222 07:23:33.989305 78755 nvc_container.c:394] setting devices cgroup to &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;devices&#x2F;system.slice&#x2F;docker-dd3c4f0a0409255fba62518899d9e59fda64172f730513b788001e06d594ba8f.scope</span><br><span class="line">I1222 07:23:33.989356 78755 nvc_info.c:680] requesting driver information with &#39;&#39;</span><br><span class="line">I1222 07:23:33.993981 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;vdpau&#x2F;libvdpau_nvidia.so.455.23.05</span><br><span class="line">I1222 07:23:33.994516 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libnvoptix.so.455.23.05</span><br><span class="line">I1222 07:23:33.994732 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libnvidia-tls.so.455.23.05</span><br><span class="line">I1222 07:23:33.994866 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libnvidia-rtcore.so.455.23.05</span><br><span class="line">I1222 07:23:33.995003 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libnvidia-ptxjitcompiler.so.455.23.05</span><br><span class="line">I1222 07:23:33.995213 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libnvidia-opticalflow.so.455.23.05</span><br><span class="line">I1222 07:23:33.995409 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libnvidia-opencl.so.455.23.05</span><br><span class="line">I1222 07:23:33.995538 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libnvidia-ngx.so.455.23.05</span><br><span class="line">I1222 07:23:33.995666 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libnvidia-ml.so.455.23.05</span><br><span class="line">I1222 07:23:33.995855 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libnvidia-ifr.so.455.23.05</span><br><span class="line">I1222 07:23:33.996048 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libnvidia-glvkspirv.so.455.23.05</span><br><span class="line">I1222 07:23:33.996180 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libnvidia-glsi.so.455.23.05</span><br><span class="line">I1222 07:23:33.996302 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libnvidia-glcore.so.455.23.05</span><br><span class="line">I1222 07:23:33.996429 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libnvidia-fbc.so.455.23.05</span><br><span class="line">I1222 07:23:33.996630 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libnvidia-encode.so.455.23.05</span><br><span class="line">I1222 07:23:33.996811 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libnvidia-eglcore.so.455.23.05</span><br><span class="line">I1222 07:23:33.996942 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libnvidia-compiler.so.455.23.05</span><br><span class="line">I1222 07:23:33.997068 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libnvidia-cfg.so.455.23.05</span><br><span class="line">I1222 07:23:33.997266 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libnvidia-cbl.so.455.23.05</span><br><span class="line">I1222 07:23:33.997385 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libnvidia-allocator.so.455.23.05</span><br><span class="line">I1222 07:23:33.997581 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libnvcuvid.so.455.23.05</span><br><span class="line">I1222 07:23:33.998475 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libcuda.so.455.23.05</span><br><span class="line">I1222 07:23:33.998854 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libGLX_nvidia.so.455.23.05</span><br><span class="line">I1222 07:23:33.998982 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libGLESv2_nvidia.so.455.23.05</span><br><span class="line">I1222 07:23:33.999116 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libGLESv1_CM_nvidia.so.455.23.05</span><br><span class="line">I1222 07:23:33.999244 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib64&#x2F;libEGL_nvidia.so.455.23.05</span><br><span class="line">I1222 07:23:33.999392 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib&#x2F;vdpau&#x2F;libvdpau_nvidia.so.455.23.05</span><br><span class="line">I1222 07:23:33.999540 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib&#x2F;libnvidia-tls.so.455.23.05</span><br><span class="line">I1222 07:23:33.999672 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib&#x2F;libnvidia-ptxjitcompiler.so.455.23.05</span><br><span class="line">I1222 07:23:33.999868 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib&#x2F;libnvidia-opticalflow.so.455.23.05</span><br><span class="line">I1222 07:23:34.000055 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib&#x2F;libnvidia-opencl.so.455.23.05</span><br><span class="line">I1222 07:23:34.000199 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib&#x2F;libnvidia-ml.so.455.23.05</span><br><span class="line">I1222 07:23:34.000387 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib&#x2F;libnvidia-ifr.so.455.23.05</span><br><span class="line">I1222 07:23:34.000577 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib&#x2F;libnvidia-glvkspirv.so.455.23.05</span><br><span class="line">I1222 07:23:34.000697 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib&#x2F;libnvidia-glsi.so.455.23.05</span><br><span class="line">I1222 07:23:34.000813 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib&#x2F;libnvidia-glcore.so.455.23.05</span><br><span class="line">I1222 07:23:34.000941 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib&#x2F;libnvidia-fbc.so.455.23.05</span><br><span class="line">I1222 07:23:34.001149 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib&#x2F;libnvidia-encode.so.455.23.05</span><br><span class="line">I1222 07:23:34.001337 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib&#x2F;libnvidia-eglcore.so.455.23.05</span><br><span class="line">I1222 07:23:34.001458 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib&#x2F;libnvidia-compiler.so.455.23.05</span><br><span class="line">I1222 07:23:34.001597 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib&#x2F;libnvidia-allocator.so.455.23.05</span><br><span class="line">I1222 07:23:34.001814 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib&#x2F;libnvcuvid.so.455.23.05</span><br><span class="line">I1222 07:23:34.002011 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib&#x2F;libcuda.so.455.23.05</span><br><span class="line">I1222 07:23:34.002221 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib&#x2F;libGLX_nvidia.so.455.23.05</span><br><span class="line">I1222 07:23:34.002350 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib&#x2F;libGLESv2_nvidia.so.455.23.05</span><br><span class="line">I1222 07:23:34.002475 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib&#x2F;libGLESv1_CM_nvidia.so.455.23.05</span><br><span class="line">I1222 07:23:34.002599 78755 nvc_info.c:169] selecting &#x2F;usr&#x2F;lib&#x2F;libEGL_nvidia.so.455.23.05</span><br><span class="line">W1222 07:23:34.002655 78755 nvc_info.c:350] missing library libnvidia-fatbinaryloader.so</span><br><span class="line">W1222 07:23:34.002679 78755 nvc_info.c:354] missing compat32 library libnvidia-cfg.so</span><br><span class="line">W1222 07:23:34.002701 78755 nvc_info.c:354] missing compat32 library libnvidia-fatbinaryloader.so</span><br><span class="line">W1222 07:23:34.002722 78755 nvc_info.c:354] missing compat32 library libnvidia-ngx.so</span><br><span class="line">W1222 07:23:34.002744 78755 nvc_info.c:354] missing compat32 library libnvidia-rtcore.so</span><br><span class="line">W1222 07:23:34.002765 78755 nvc_info.c:354] missing compat32 library libnvoptix.so</span><br><span class="line">W1222 07:23:34.002786 78755 nvc_info.c:354] missing compat32 library libnvidia-cbl.so</span><br><span class="line">I1222 07:23:34.004155 78755 nvc_info.c:276] selecting &#x2F;usr&#x2F;bin&#x2F;nvidia-smi</span><br><span class="line">I1222 07:23:34.004247 78755 nvc_info.c:276] selecting &#x2F;usr&#x2F;bin&#x2F;nvidia-debugdump</span><br><span class="line">I1222 07:23:34.004332 78755 nvc_info.c:276] selecting &#x2F;usr&#x2F;bin&#x2F;nvidia-persistenced</span><br><span class="line">I1222 07:23:34.004418 78755 nvc_info.c:276] selecting &#x2F;usr&#x2F;bin&#x2F;nvidia-cuda-mps-control</span><br><span class="line">I1222 07:23:34.004504 78755 nvc_info.c:276] selecting &#x2F;usr&#x2F;bin&#x2F;nvidia-cuda-mps-server</span><br><span class="line">I1222 07:23:34.004625 78755 nvc_info.c:438] listing device &#x2F;dev&#x2F;nvidiactl</span><br><span class="line">I1222 07:23:34.004648 78755 nvc_info.c:438] listing device &#x2F;dev&#x2F;nvidia-uvm</span><br><span class="line">I1222 07:23:34.004669 78755 nvc_info.c:438] listing device &#x2F;dev&#x2F;nvidia-uvm-tools</span><br><span class="line">I1222 07:23:34.004690 78755 nvc_info.c:438] listing device &#x2F;dev&#x2F;nvidia-modeset</span><br><span class="line">W1222 07:23:34.004790 78755 nvc_info.c:321] missing ipc &#x2F;var&#x2F;run&#x2F;nvidia-persistenced&#x2F;socket</span><br><span class="line">W1222 07:23:34.004856 78755 nvc_info.c:321] missing ipc &#x2F;tmp&#x2F;nvidia-mps</span><br><span class="line">I1222 07:23:34.004879 78755 nvc_info.c:745] requesting device information with &#39;&#39;</span><br><span class="line">I1222 07:23:34.012276 78755 nvc_info.c:628] listing device &#x2F;dev&#x2F;nvidia0 (GPU-2fb041ff-6df3-4d00-772d-efb3139a17a1 at 00000000:3b:00.0)</span><br><span class="line">I1222 07:23:34.020861 78755 nvc_info.c:628] listing device &#x2F;dev&#x2F;nvidia1 (GPU-a15f4c20-0f41-68ab-3782-bd66d8fda9e4 at 00000000:af:00.0)</span><br><span class="line">I1222 07:23:34.021102 78755 nvc_mount.c:344] mounting tmpfs at &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;proc&#x2F;driver&#x2F;nvidia</span><br><span class="line">I1222 07:23:34.022322 78755 nvc_mount.c:112] mounting &#x2F;usr&#x2F;bin&#x2F;nvidia-smi at &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;usr&#x2F;bin&#x2F;nvidia-smi</span><br><span class="line">I1222 07:23:34.022504 78755 nvc_mount.c:112] mounting &#x2F;usr&#x2F;bin&#x2F;nvidia-debugdump at &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;usr&#x2F;bin&#x2F;nvidia-debugdump</span><br><span class="line">I1222 07:23:34.022664 78755 nvc_mount.c:112] mounting &#x2F;usr&#x2F;bin&#x2F;nvidia-persistenced at &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;usr&#x2F;bin&#x2F;nvidia-persistenced</span><br><span class="line">I1222 07:23:34.022825 78755 nvc_mount.c:112] mounting &#x2F;usr&#x2F;bin&#x2F;nvidia-cuda-mps-control at &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;usr&#x2F;bin&#x2F;nvidia-cuda-mps-control</span><br><span class="line">I1222 07:23:34.022983 78755 nvc_mount.c:112] mounting &#x2F;usr&#x2F;bin&#x2F;nvidia-cuda-mps-server at &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;usr&#x2F;bin&#x2F;nvidia-cuda-mps-server</span><br><span class="line">I1222 07:23:34.023745 78755 nvc_mount.c:112] mounting &#x2F;usr&#x2F;lib64&#x2F;libnvidia-ml.so.455.23.05 at &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libnvidia-ml.so.455.23.05</span><br><span class="line">I1222 07:23:34.023960 78755 nvc_mount.c:112] mounting &#x2F;usr&#x2F;lib64&#x2F;libnvidia-cfg.so.455.23.05 at &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libnvidia-cfg.so.455.23.05</span><br><span class="line">I1222 07:23:34.024203 78755 nvc_mount.c:112] mounting &#x2F;usr&#x2F;lib64&#x2F;libcuda.so.455.23.05 at &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libcuda.so.455.23.05</span><br><span class="line">I1222 07:23:34.024411 78755 nvc_mount.c:112] mounting &#x2F;usr&#x2F;lib64&#x2F;libnvidia-opencl.so.455.23.05 at &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libnvidia-opencl.so.455.23.05</span><br><span class="line">I1222 07:23:34.024615 78755 nvc_mount.c:112] mounting &#x2F;usr&#x2F;lib64&#x2F;libnvidia-ptxjitcompiler.so.455.23.05 at &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libnvidia-ptxjitcompiler.so.455.23.05</span><br><span class="line">I1222 07:23:34.024815 78755 nvc_mount.c:112] mounting &#x2F;usr&#x2F;lib64&#x2F;libnvidia-allocator.so.455.23.05 at &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libnvidia-allocator.so.455.23.05</span><br><span class="line">I1222 07:23:34.040552 78755 nvc_mount.c:112] mounting &#x2F;usr&#x2F;lib64&#x2F;libnvidia-compiler.so.455.23.05 at &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libnvidia-compiler.so.455.23.05</span><br><span class="line">I1222 07:23:34.040717 78755 nvc_mount.c:524] creating symlink &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libcuda.so -&gt; libcuda.so.1</span><br><span class="line">I1222 07:23:34.041181 78755 nvc_mount.c:112] mounting &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;usr&#x2F;local&#x2F;cuda-10.1&#x2F;compat&#x2F;libcuda.so.418.87.00 at &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libcuda.so.418.87.00</span><br><span class="line">I1222 07:23:34.041439 78755 nvc_mount.c:112] mounting &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;usr&#x2F;local&#x2F;cuda-10.1&#x2F;compat&#x2F;libnvidia-fatbinaryloader.so.418.87.00 at &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libnvidia-fatbinaryloader.so.418.87.00</span><br><span class="line">I1222 07:23:34.041662 78755 nvc_mount.c:112] mounting &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;usr&#x2F;local&#x2F;cuda-10.1&#x2F;compat&#x2F;libnvidia-ptxjitcompiler.so.418.87.00 at &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libnvidia-ptxjitcompiler.so.418.87.00</span><br><span class="line">I1222 07:23:34.041871 78755 nvc_mount.c:208] mounting &#x2F;dev&#x2F;nvidiactl at &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;dev&#x2F;nvidiactl</span><br><span class="line">I1222 07:23:34.041959 78755 nvc_mount.c:499] whitelisting device node 195:255</span><br><span class="line">I1222 07:23:34.042196 78755 nvc_mount.c:208] mounting &#x2F;dev&#x2F;nvidia-uvm at &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;dev&#x2F;nvidia-uvm</span><br><span class="line">I1222 07:23:34.042283 78755 nvc_mount.c:499] whitelisting device node 234:0</span><br><span class="line">I1222 07:23:34.042474 78755 nvc_mount.c:208] mounting &#x2F;dev&#x2F;nvidia-uvm-tools at &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;dev&#x2F;nvidia-uvm-tools</span><br><span class="line">I1222 07:23:34.042552 78755 nvc_mount.c:499] whitelisting device node 234:1</span><br><span class="line">I1222 07:23:34.042781 78755 nvc_mount.c:208] mounting &#x2F;dev&#x2F;nvidia0 at &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;dev&#x2F;nvidia0</span><br><span class="line">I1222 07:23:34.043137 78755 nvc_mount.c:412] mounting &#x2F;proc&#x2F;driver&#x2F;nvidia&#x2F;gpus&#x2F;0000:3b:00.0 at &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged&#x2F;proc&#x2F;driver&#x2F;nvidia&#x2F;gpus&#x2F;0000:3b:00.0</span><br><span class="line">I1222 07:23:34.043225 78755 nvc_mount.c:499] whitelisting device node 195:0</span><br><span class="line">I1222 07:23:34.043317 78755 nvc_ldcache.c:359] executing &#x2F;sbin&#x2F;ldconfig from host at &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b&#x2F;merged</span><br><span class="line">W1222 07:23:34.070874 78755 utils.c:121] &#x2F;sbin&#x2F;ldconfig: File &#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libcuda.so is empty, not checked.</span><br><span class="line">W1222 07:23:34.070939 78755 utils.c:121] &#x2F;sbin&#x2F;ldconfig: File &#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libcuda.so.1 is empty, not checked.</span><br><span class="line">W1222 07:23:34.070962 78755 utils.c:121] &#x2F;sbin&#x2F;ldconfig: File &#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libcuda.so.418.67 is empty, not checked.</span><br><span class="line">W1222 07:23:34.072833 78755 utils.c:121] &#x2F;sbin&#x2F;ldconfig: File &#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libnvidia-cfg.so.1 is empty, not checked.</span><br><span class="line">W1222 07:23:34.072864 78755 utils.c:121] &#x2F;sbin&#x2F;ldconfig: File &#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libnvidia-cfg.so.418.67 is empty, not checked.</span><br><span class="line">W1222 07:23:34.072909 78755 utils.c:121] &#x2F;sbin&#x2F;ldconfig: File &#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libnvidia-compiler.so.418.67 is empty, not checked.</span><br><span class="line">W1222 07:23:34.072952 78755 utils.c:121] &#x2F;sbin&#x2F;ldconfig: File &#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libnvidia-fatbinaryloader.so.418.67 is empty, not checked.</span><br><span class="line">W1222 07:23:34.073004 78755 utils.c:121] &#x2F;sbin&#x2F;ldconfig: File &#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libnvidia-ml.so.1 is empty, not checked.</span><br><span class="line">W1222 07:23:34.073038 78755 utils.c:121] &#x2F;sbin&#x2F;ldconfig: File &#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libnvidia-ml.so.418.67 is empty, not checked.</span><br><span class="line">W1222 07:23:34.073127 78755 utils.c:121] &#x2F;sbin&#x2F;ldconfig: File &#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libnvidia-opencl.so.1 is empty, not checked.</span><br><span class="line">W1222 07:23:34.073158 78755 utils.c:121] &#x2F;sbin&#x2F;ldconfig: File &#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libnvidia-opencl.so.418.67 is empty, not checked.</span><br><span class="line">W1222 07:23:34.073219 78755 utils.c:121] &#x2F;sbin&#x2F;ldconfig: File &#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libnvidia-ptxjitcompiler.so.1 is empty, not checked.</span><br><span class="line">W1222 07:23:34.073259 78755 utils.c:121] &#x2F;sbin&#x2F;ldconfig: File &#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libnvidia-ptxjitcompiler.so.418.67 is empty, not checked.</span><br><span class="line">I1222 07:23:34.114387 78755 nvc.c:337] shutting down library context</span><br><span class="line">I1222 07:23:34.618210 78760 driver.c:156] terminating driver service</span><br><span class="line">I1222 07:23:34.618980 78755 driver.c:196] driver service terminated successfully</span><br></pre></td></tr></table></figure>

<p>重点是这一步 挂载某个GPU</p>
<font size="5">
I1222 07:23:34.043137 78755 nvc_mount.c:412] mounting /proc/driver/nvidia/gpus/0000:3b:00.0 at /var/lib/docker/overlay2/6ac97e95475e9df0f32f7e2f7251ca053651c62292d1a5127c71d33e55904d2b/merged/proc/driver/nvidia/gpus/0000:3b:00.0


<p>I1222 07:23:34.043225 78755 nvc_mount.c:499] whitelisting device node 195:0<br></p></font><p></p>
<p>使用的是这个函数</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">static char *</span><br><span class="line">mount_procfs_gpu(<span class="keyword">struct</span> error *err, <span class="keyword">const</span> char *root, <span class="keyword">const</span> <span class="keyword">struct</span> nvc_container *cnt, <span class="keyword">const</span> char *busid)</span><br><span class="line">&#123;</span><br><span class="line">		char src[PATH_MAX];</span><br><span class="line">		char dst[PATH_MAX] = &#123;<span class="number">0</span>&#125;;</span><br><span class="line">		char *gpu = NULL;</span><br><span class="line">		char *mnt = NULL;</span><br><span class="line">		mode_t mode;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> off = <span class="number">0</span>;; off += <span class="number">4</span>) &#123;</span><br><span class="line">				<span class="comment">/* XXX Check if the driver procfs uses 32-bit or 16-bit PCI domain */</span></span><br><span class="line">				<span class="keyword">if</span> (xasprintf(err, &amp;gpu, <span class="string">"%s/gpus/%s"</span>, NV_PROC_DRIVER, busid + off) &lt; <span class="number">0</span>)</span><br><span class="line">						<span class="keyword">return</span> (NULL);</span><br><span class="line">				<span class="keyword">if</span> (path_join(err, src, root, gpu) &lt; <span class="number">0</span>)</span><br><span class="line">						<span class="keyword">goto</span> fail;</span><br><span class="line">				<span class="keyword">if</span> (path_resolve_full(err, dst, cnt-&gt;cfg.rootfs, gpu) &lt; <span class="number">0</span>)</span><br><span class="line">						<span class="keyword">goto</span> fail;</span><br><span class="line">				<span class="keyword">if</span> (file_mode(err, src, &amp;mode) == <span class="number">0</span>)</span><br><span class="line">						<span class="keyword">break</span>;</span><br><span class="line">				<span class="keyword">if</span> (err-&gt;code != ENOENT || off != <span class="number">0</span>)</span><br><span class="line">						<span class="keyword">goto</span> fail;</span><br><span class="line">				*dst = <span class="string">'\0'</span>;</span><br><span class="line">				free(gpu);</span><br><span class="line">				gpu = NULL;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> (file_create(err, dst, NULL, cnt-&gt;uid, cnt-&gt;gid, mode) &lt; <span class="number">0</span>)</span><br><span class="line">				<span class="keyword">goto</span> fail;</span><br><span class="line"></span><br><span class="line">		log_infof(<span class="string">"mounting %s at %s"</span>, src, dst);</span><br><span class="line">		<span class="keyword">if</span> (xmount(err, src, dst, NULL, MS_BIND, NULL) &lt; <span class="number">0</span>)</span><br><span class="line">				<span class="keyword">goto</span> fail;</span><br><span class="line">		<span class="keyword">if</span> (xmount(err, NULL, dst, NULL, MS_BIND|MS_REMOUNT | MS_RDONLY|MS_NODEV|MS_NOSUID|MS_NOEXEC, NULL) &lt; <span class="number">0</span>)</span><br><span class="line">				<span class="keyword">goto</span> fail;</span><br><span class="line">		<span class="keyword">if</span> ((mnt = xstrdup(err, dst)) == NULL)</span><br><span class="line">				<span class="keyword">goto</span> fail;</span><br><span class="line">		free(gpu);</span><br><span class="line">		<span class="keyword">return</span> (mnt);</span><br><span class="line"></span><br><span class="line">fail:</span><br><span class="line">		free(gpu);</span><br><span class="line">		unmount(dst);</span><br><span class="line">		<span class="keyword">return</span> (NULL);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="proc-文件系统"><a href="#proc-文件系统" class="headerlink" title="proc 文件系统"></a>proc 文件系统</h3><p>Linux系统上的/proc目录是一种文件系统，即proc文件系统。与其它常见的文件系统不同的是，/proc是一种伪文件系统（也即虚拟文件系统），存储的是当前内核运行状态的一系列特殊文件，用户可以通过这些文件查看有关系统硬件及当前正在运行进程的信息，甚至可以通过更改其中某些文件来改变内核的运行状态。 </p>
<p>基于/proc文件系统如上所述的特殊性，其内的文件也常被称作虚拟文件，并具有一些独特的特点。例如，其中有些文件虽然使用查看命令查看时会返回大量信息，但文件本身的大小却会显示为0字节。此外，这些特殊文件中大多数文件的时间及日期属性通常为当前系统时间和日期，这跟它们随时会被刷新（存储于RAM中）有关。 </p>
<p>为了查看及使用上的方便，这些文件通常会按照相关性进行分类存储于不同的目录甚至子目录中，如/proc/scsi目录中存储的就是当前系统上所有SCSI设备的相关信息，/proc/N中存储的则是系统当前正在运行的进程的相关信息，其中N为正在运行的进程（可以想象得到，在某进程结束后其相关目录则会消失）。 </p>
<p>大多数虚拟文件可以使用文件查看命令如cat、more或者less进行查看，有些文件信息表述的内容可以一目了然，但也有文件的信息却不怎么具有可读性。不过，这些可读性较差的文件在使用一些命令如apm、free、lspci或top查看时却可以有着不错的表现。 </p>
<h2 id="proc-文件系统原理"><a href="#proc-文件系统原理" class="headerlink" title="proc 文件系统原理"></a>proc 文件系统原理</h2><p>proc文件系统是一个伪文件系统，它只存在于内存中，不在外存存储。proc提供了访问系统内核信息的接口。用户和应用程序可以通过proc访问系统信息。用户和应用程序可以通过proc改变内核的某些参数。由于进程等系统信息是动态改变的，所以proc系统动态从系统内核读出所需信息，并提交给读取它的用户和应用程序。</p>
<p>是否可以动态修改这个文件系统呢？</p>
<h3 id="三个项目的关系"><a href="#三个项目的关系" class="headerlink" title="三个项目的关系"></a>三个项目的关系</h3><p>包含三个项目<br> libnvidia-container项目（核心项目，挂载GPU驱动）、nvidia-container-runtime 项目、nvidia-container-toolkit项目<br> 其中 nvidia-container-toolkit 和libnvidia-container 两个项目时必须安装的，对于nvidia-container-runtime 只是为了方便docker run 直接使用，增加hook 函数使用<br>nvidia-container-runtime 为 构造OCI 的hook，hook的具体实现为nvidia-container-toolkit项目，nvidia-container-toolkit项目会最终调用libnvidia-container项目的cli进行具体的配置<br>三个项目的调用顺序<br> docker runc -&gt;  nvidia-container-runtime-&gt; nvidia-container-toolkit -&gt;libnvidia-container</p>
<h3 id="Command-line-创建挂载GPU的容器"><a href="#Command-line-创建挂载GPU的容器" class="headerlink" title="Command line 创建挂载GPU的容器"></a>Command line 创建挂载GPU的容器</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Setup a new set of namespaces </span></span><br><span class="line"><span class="comment">#建立暂存文件夹，并在其创建rootfs目录</span></span><br><span class="line"><span class="built_in">cd</span> $(mktemp -d) &amp;&amp; mkdir rootfs</span><br><span class="line"><span class="comment"># 对于mount pid 命名空间 与parent 的命名空间隔离,</span></span><br><span class="line"><span class="comment">#--fork  Fork the specified program as a child process of unshare rather than running it directly.   This  is  useful  when creating a new pid namespace</span></span><br><span class="line"><span class="comment">#man unshare</span></span><br><span class="line">sudo unshare --mount --pid --fork</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup a rootfs based on Ubuntu 16.04 inside the new namespaces</span></span><br><span class="line"><span class="comment">#在新的命名空间下载一个rootfs 文件</span></span><br><span class="line">curl http://cdimage.ubuntu.com/ubuntu-base/releases/16.04/release/ubuntu-base-16.04.6-base-amd64.tar.gz | tar -C rootfs -xz</span><br><span class="line"></span><br><span class="line"><span class="comment">#在rootfs 目录增加user，使用该目录的配置文件，指定用户和用户组ID，指定shell</span></span><br><span class="line">useradd -R $(realpath rootfs) -U -u 1000 -s /bin/bash nvidia</span><br><span class="line"><span class="comment">#将前一个目录挂载到后一个目录上，所有对后一个目录的访问其实都是对前一个目录的访问</span></span><br><span class="line">mount --<span class="built_in">bind</span> rootfs rootfs</span><br><span class="line"><span class="comment">#改变挂载类型为私有</span></span><br><span class="line">mount --make-private rootfs</span><br><span class="line"><span class="built_in">cd</span> rootfs</span><br><span class="line"></span><br><span class="line"><span class="comment"># Mount standard filesystems</span></span><br><span class="line"><span class="comment">#将虚拟的proc 文件系统挂载到proc 目录，这里把节点的全部GPU信息挂载到了容器</span></span><br><span class="line">mount -t proc none proc</span><br><span class="line"></span><br><span class="line"><span class="comment">#将sysfs 文件系统挂载到 sys目录</span></span><br><span class="line">mount -t sysfs none sys</span><br><span class="line">mount -t tmpfs none tmp</span><br><span class="line">mount -t tmpfs none run</span><br><span class="line"></span><br><span class="line"><span class="comment"># Isolate the first GPU device along with basic utilities</span></span><br><span class="line">nvidia-container-cli --load-kmods configure  --no-cgroups --utility --device 0 $(<span class="built_in">pwd</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Change into the new rootfs</span></span><br><span class="line"><span class="comment"># pivot_root new_root put_old </span></span><br><span class="line"><span class="comment"># pivot_root把当前进程的root文件系统放到put_old目录，而使new_root成为新的root文件系统</span></span><br><span class="line">pivot_root . mnt</span><br><span class="line"><span class="built_in">exec</span> chroot --userspec 1000:1000 . env -i bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run nvidia-smi from within the container</span></span><br><span class="line">nvidia-smi -L</span><br></pre></td></tr></table></figure>

<p>尝试在不同的shell 终端挂载不同的GPU，但是都是只能显示一个GPU<br>在同样的rootfs 目录，执行挂载主机的0号GPU卡，如下图所示，此时只能查看到一张卡<br><img src="/2020/12/21/nvidia-docker-%E9%85%8D%E7%BD%AEGPU/configgpu0.png" alt="avatar"></p>
<p>然后在同样的rootfs目录，执行挂载主机的1号GPU卡，如下图所示，此时仍然只能查看到一张卡<br><img src="/2020/12/21/nvidia-docker-%E9%85%8D%E7%BD%AEGPU/configgpu1.png" alt="avatar"></p>
<p>这里的proc 文件系统是关键，执行nvidia-container-cli 在proc 文件系统内就只能查看到指定的GPU 卡了，只能对运行态容器的proc 进行处理.(proc 文件系统是内核提供的映射文件)，新挂载的是无法获取到 运行态容器的proc信息</p>
]]></content>
  </entry>
  <entry>
    <title>OpenShift基础功能测试和验证</title>
    <url>/2020/09/21/OpenShift%E5%9F%BA%E7%A1%80%E5%8A%9F%E8%83%BD%E6%B5%8B%E8%AF%95%E5%92%8C%E9%AA%8C%E8%AF%81/</url>
    <content><![CDATA[<h1 id="OpenShift"><a href="#OpenShift" class="headerlink" title="OpenShift"></a>OpenShift</h1><h2 id="OpenShift-分布式部署"><a href="#OpenShift-分布式部署" class="headerlink" title="OpenShift 分布式部署"></a>OpenShift 分布式部署</h2><h3 id="OpenShift-Slave节点配置"><a href="#OpenShift-Slave节点配置" class="headerlink" title="OpenShift Slave节点配置"></a>OpenShift Slave节点配置</h3><p>0、 节点ssh互信设置</p>
<p>Maste节点执行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh-keygen</span><br><span class="line"># for host in master.example.com \\</span><br><span class="line">    node1.example.com \\</span><br><span class="line">    node2.example.com; \\</span><br><span class="line">    do ssh-copy-id -i ~&#x2F;.ssh&#x2F;id\_rsa.pub $host; \\</span><br><span class="line">    done</span><br></pre></td></tr></table></figure>

<p>1、 每个节点都需要安装docker，手动安装</p>
<p>2、设置每个节点的docker 存储，使用数据盘做为docker的存储</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\[root@origin-master member\]# cat &#x2F;etc&#x2F;sysconfig&#x2F;docker-storage-setup</span><br><span class="line"> Edit this file to override any configuration options specified in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;docker-storage-setup&#x2F;docker-storage-setup.</span><br><span class="line"></span><br><span class="line">For more details refer to &quot;man docker-storage-setup&quot;</span><br><span class="line">DEVS&#x3D;&#x2F;dev&#x2F;vdb</span><br><span class="line">VG&#x3D;docker-vg</span><br><span class="line"> </span><br><span class="line">docker-storage-setup</span><br><span class="line"> </span><br><span class="line">systemctl stop docker</span><br><span class="line">rm -rf &#x2F;var&#x2F;lib&#x2F;docker&#x2F;\*</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure>

<p>3、</p>
<p>设置每个节点的docker 可信镜像地址/etc/sysconfig/docker（这一操作，可以在部署完成openshift后，进行修改，其中172.30.0.0/16为ansible配置，10.110.17.138:5000为外部的docker镜像源）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">OPTIONS&#x3D;&#39;--insecure-registry&#x3D;10.110.17.138:5000 --insecure-registry&#x3D;172.30.0.0&#x2F;16    &#39;</span><br></pre></td></tr></table></figure>





<p>4、在DNS为每个Node的配置</p>
<p> A记录参考配置:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@origin-dns:&#x2F;etc&#x2F;bind# cat &#x2F;etc&#x2F;bind&#x2F;named.conf.local</span><br><span class="line">&#x2F;&#x2F;</span><br><span class="line">&#x2F;&#x2F; Do any local configuration here</span><br><span class="line">&#x2F;&#x2F;</span><br><span class="line"> </span><br><span class="line">&#x2F;&#x2F; Consider adding the 1918 zones here, if they are not used in your</span><br><span class="line">&#x2F;&#x2F; organization</span><br><span class="line">&#x2F;&#x2F;include &quot;&#x2F;etc&#x2F;bind&#x2F;zones.rfc1918&quot;;</span><br><span class="line">zone &quot;novalocal&quot; &#123;</span><br><span class="line">        type master;</span><br><span class="line">        file &quot;&#x2F;etc&#x2F;bind&#x2F;db.novalocal&quot;;</span><br><span class="line">&#125;;</span><br><span class="line"> </span><br><span class="line">root@origin-dns:&#x2F;etc&#x2F;bind# cat db.novalocal</span><br><span class="line">$TTL    604800</span><br><span class="line">@       IN      SOA     novalocal. root.novalocal. (</span><br><span class="line">                              1         ; Serial</span><br><span class="line">                         604800         ; Refresh</span><br><span class="line">                          86400         ; Retry</span><br><span class="line">                        2419200         ; Expire</span><br><span class="line">                          86400 )       ; Negative Cache TTL</span><br><span class="line">;</span><br><span class="line">@       IN      NS      novalocal.</span><br><span class="line">@       IN      A       192.168.10.143</span><br><span class="line">origin-master  IN      A       192.168.10.143</span><br><span class="line">origin-slave1  IN      A       192.168.10.149</span><br><span class="line">origin-slave2  IN      A       192.168.10.145</span><br><span class="line">origin-slave3  IN      A       192.168.10.147</span><br></pre></td></tr></table></figure>



<h3 id="OpenShift-Master节点配置"><a href="#OpenShift-Master节点配置" class="headerlink" title="OpenShift Master节点配置"></a>OpenShift Master节点配置</h3><p>1、ansible-openshift 的配置文件/etc/ansible/hosts 增加一下配置，完成OpenShift节点的定义</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[OSEv3:children]</span><br><span class="line">masters</span><br><span class="line">nodes</span><br><span class="line">[OSEv3:vars]</span><br><span class="line">ansible_ssh_user&#x3D;root</span><br><span class="line">deployment_type&#x3D;origin</span><br><span class="line">openshift\_master\_identity\_providers&#x3D;\[&#123;&#39;name&#39;: &#39;htpasswd\_auth&#39;, &#39;login&#39;: &#39;true&#39;, &#39;challenge&#39;: &#39;true&#39;, &#39;kind&#39;: &#39;HTPasswdPasswordIdentityProvider&#39;, &#39;filename&#39;: &#39;&#x2F;etc&#x2F;origin&#x2F;htpasswd&#39;&#125;\]</span><br><span class="line">os\_sdn\_network\_plugin\_name&#x3D;redhat&#x2F;openshift-ovs-multitenant</span><br><span class="line">openshift\_master\_portal\_net&#x3D;172.30.0.0&#x2F;16</span><br><span class="line">openshift\_master\_session\_name&#x3D;ssn</span><br><span class="line">openshift\_master\_session\_max\_seconds&#x3D;3600</span><br><span class="line">openshift\_master\_session\_auth\_secrets&#x3D;\[&#39;DONT+USE+THIS+SECRET+b4NV+pmZNSO&#39;\]</span><br><span class="line">openshift\_master\_session\_encryption\_secrets&#x3D;\[&#39;DONT+USE+THIS+SECRET+b4NV+pmZNSO&#39;\]</span><br><span class="line"> </span><br><span class="line">\[masters\]</span><br><span class="line">origin-master.novalocal openshift\_public\_ip&#x3D;10.110.17.139 openshift\_public\_hostname&#x3D;origin-master.novalocal</span><br><span class="line">\[nodes\]</span><br><span class="line">origin-slave1.novalocal openshift\_node\_labels&#x3D;&quot;&#123;&#39;region&#39;: &#39;primary&#39;, &#39;zone&#39;: &#39;east&#39;&#125;&quot;</span><br><span class="line">origin-slave2.novalocal openshift\_node\_labels&#x3D;&quot;&#123;&#39;region&#39;: &#39;primary&#39;, &#39;zone&#39;: &#39;east&#39;&#125;&quot;</span><br><span class="line">origin-slave3.novalocal openshift\_node\_labels&#x3D;&quot;&#123;&#39;region&#39;: &#39;primary&#39;, &#39;zone&#39;: &#39;east&#39;&#125;&quot;</span><br><span class="line">origin-master.novalocal openshift\_node\_labels&#x3D;&quot;&#123;&#39;region&#39;:&#39;infra&#39;,&#39;zone&#39;:&#39;default&#39;&#125;&quot; openshift\_schedulable&#x3D;false</span><br></pre></td></tr></table></figure>



<p>2、</p>
<p>搭建NFS服务器：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\[root@oc-master ~\]yum install nfs-utils</span><br><span class="line">\[root@oc-master ~\]cat &#x2F;etc&#x2F;exports</span><br><span class="line">&#x2F;opt&#x2F;docker-registry 192.168.10.0&#x2F;24(rw,sync,no\_root\_squash,no\_all\_squash)</span><br><span class="line">&#96;&#96;&#96;&#96; </span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">配置服务端访问策略：</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;&#96;(python)</span><br><span class="line">cat  &#x2F;etc&#x2F;sysconfig&#x2F;iptables</span><br><span class="line">-A OS\_FIREWALL\_ALLOW -m state --state NEW  -p udp -s 192.168.10.0&#x2F;24 --dport 111 -j ACCEPT</span><br><span class="line">-A OS\_FIREWALL\_ALLOW -m state --state NEW  -p tcp -s 192.168.10.0&#x2F;24 --dport 111 -j ACCEPT</span><br><span class="line">-A OS\_FIREWALL\_ALLOW -m state --state NEW  -p tcp -s 192.168.10.0&#x2F;24 --dport 20048 -j ACCEPT</span><br><span class="line">-A OS\_FIREWALL\_ALLOW -m state --state NEW  -p udp -s 192.168.6.0&#x2F;24 --dport 20048 -j ACCEPT</span><br><span class="line">-A OS\_FIREWALL\_ALLOW -m state --state NEW  -p udp -s 192.168.6.0&#x2F;24 --dport 2049 -j ACCEPT</span><br><span class="line">-A OS\_FIREWALL\_ALLOW -m state --state NEW  -p tcp -s 192.168.6.0&#x2F;24 --dport 2049 -j ACCEPT</span><br><span class="line">-A OS\_FIREWALL\_ALLOW -m state --state NEW  -p tcp -s 192.168.6.0&#x2F;24 --dport 20048 -j ACCEPT</span><br><span class="line">-A OS\_FIREWALL\_ALLOW -m state --state NEW  -p udp -s 192.168.6.0&#x2F;24 --dport 20048 -j ACCEPT</span><br><span class="line">-A OS\_FIREWALL\_ALLOW -m state --state NEW  -p udp -s 192.168.6.0&#x2F;24 --dport 49493 -j ACCEPT</span><br><span class="line">-A OS\_FIREWALL\_ALLOW -m state --state NEW  -p tcp -s 192.168.6.0&#x2F;24 --dport 49493 -j ACCEPT</span><br><span class="line">-A OS\_FIREWALL\_ALLOW -m state --state NEW  -p udp -s 192.168.6.0&#x2F;24 --dport 54932 -j ACCEPT</span><br><span class="line">-A OS\_FIREWALL\_ALLOW -m state --state NEW  -p tcp -s 192.168.6.0&#x2F;24 --dport 46120 -j ACCEPT</span><br><span class="line">-A OS\_FIREWALL\_ALLOW -m state --state NEW  -p udp -s 192.168.6.0&#x2F;24 --dport 37588 -j ACCEPT</span><br></pre></td></tr></table></figure>



<p>重启NFS服务 systemctl restart nfs-server.service</p>
<p>客户端挂载</p>
<p>mount -t nfs 192.168.6.7:/opt/docker-registry/ /opt/docker-registry/</p>
<h3 id="执行安装"><a href="#执行安装" class="headerlink" title="执行安装"></a>执行安装</h3><p>在master节点操作</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、执行安装：ansible-playbook ~&#x2F;openshift-ansible&#x2F;playbooks&#x2F;byo&#x2F;config.yml</span><br></pre></td></tr></table></figure>

<p>2、执行卸载：ansible-playbook openshift-ansible/playbooks/adhoc/uninstall.yml</p>
<h3 id="部署docker-Registry"><a href="#部署docker-Registry" class="headerlink" title="部署docker-Registry"></a>部署docker-Registry</h3><p>Master节点配置nfs</p>
<p>注意：部署完成docker-registry后，不能再讲该服务进行删除，因为服务地址已经更新到etcd，该地址目前看来，无法实时更新</p>
<p>在master节点操作</p>
<p>oadm registry –config=/etc/origin/master/admin.kubeconfig  –credentials=/etc/origin/master/openshift-registry.kubeconfig –service-account=registry  –mount-host=/opt/docker-registry</p>
<h3 id="部署监控metrics"><a href="#部署监控metrics" class="headerlink" title="部署监控metrics"></a>部署监控metrics</h3><p>1 使用 openshift-infra工程</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc project openshift-infra</span><br></pre></td></tr></table></figure>
<p>2、</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc secrets new metrics-deployer nothing&#x3D;&#x2F;dev&#x2F;null</span><br></pre></td></tr></table></figure>

<p>3、<br>oc process -f metrics-deployer.yaml -v HAWKULAR_METRICS_HOSTNAME=hawkular-metrics.devops.inspur,USE_PERSISTENT_STORAGE=false | oc create -f –</p>
<p>参考demo</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">#</span><br><span class="line"># Copyright 2014-2015 Red Hat, Inc. and&#x2F;or its affiliates</span><br><span class="line"># and other contributors as indicated by the @author tags.</span><br><span class="line">#</span><br><span class="line"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="line"># you may not use this file except in compliance with the License.</span><br><span class="line"># You may obtain a copy of the License at</span><br><span class="line">#</span><br><span class="line">#    http:&#x2F;&#x2F;www.apache.org&#x2F;licenses&#x2F;LICENSE-2.0</span><br><span class="line">#</span><br><span class="line"># Unless required by applicable law or agreed to in writing, software</span><br><span class="line"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="line"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line"># See the License for the specific language governing permissions and</span><br><span class="line"># limitations under the License.</span><br><span class="line">#</span><br><span class="line"> </span><br><span class="line">apiVersion: &quot;v1&quot;</span><br><span class="line">kind: &quot;Template&quot;</span><br><span class="line">metadata:</span><br><span class="line">  name: metrics-deployer-template</span><br><span class="line">  annotations:</span><br><span class="line">    description: &quot;Template for deploying the required Metrics integration. Requires cluster-admin &#39;metrics-deployer&#39; service account and &#39;metrics-deployer&#39; secret.&quot;</span><br><span class="line">    tags: &quot;infrastructure&quot;</span><br><span class="line">labels:</span><br><span class="line">  metrics-infra: deployer</span><br><span class="line">  provider: openshift</span><br><span class="line">  component: deployer</span><br><span class="line">objects:</span><br><span class="line">-</span><br><span class="line">  apiVersion: v1</span><br><span class="line">  kind: Pod</span><br><span class="line">  metadata:</span><br><span class="line">    generateName: metrics-deployer-</span><br><span class="line">  spec:</span><br><span class="line">    containers:</span><br><span class="line">    - image: $&#123;IMAGE\_PREFIX&#125;metrics-deployer:$&#123;IMAGE\_VERSION&#125;</span><br><span class="line">      name: deployer</span><br><span class="line">      volumeMounts:</span><br><span class="line">      - name: secret</span><br><span class="line">        mountPath: &#x2F;secret</span><br><span class="line">        readOnly: true</span><br><span class="line">      - name: empty</span><br><span class="line">        mountPath: &#x2F;etc&#x2F;deploy</span><br><span class="line">      env:</span><br><span class="line">        - name: PROJECT</span><br><span class="line">          valueFrom:</span><br><span class="line">            fieldRef:</span><br><span class="line">              fieldPath: metadata.namespace</span><br><span class="line">        - name: IMAGE\_PREFIX</span><br><span class="line">          value: $&#123;IMAGE\_PREFIX&#125;</span><br><span class="line">        - name: IMAGE\_VERSION</span><br><span class="line">          value: $&#123;IMAGE\_VERSION&#125;</span><br><span class="line">        - name: MASTER\_URL</span><br><span class="line">          value: $&#123;MASTER\_URL&#125;</span><br><span class="line">        - name: REDEPLOY</span><br><span class="line">          value: $&#123;REDEPLOY&#125;</span><br><span class="line">        - name: USE\_PERSISTENT\_STORAGE</span><br><span class="line">          value: $&#123;USE\_PERSISTENT\_STORAGE&#125;</span><br><span class="line">        - name: HAWKULAR\_METRICS\_HOSTNAME</span><br><span class="line">          value: $&#123;HAWKULAR\_METRICS\_HOSTNAME&#125;</span><br><span class="line">        - name: CASSANDRA\_NODES</span><br><span class="line">          value: $&#123;CASSANDRA\_NODES&#125;</span><br><span class="line">        - name: CASSANDRA\_PV\_SIZE</span><br><span class="line">          value: $&#123;CASSANDRA\_PV\_SIZE&#125;</span><br><span class="line">        - name: METRIC\_DURATION</span><br><span class="line">          value: $&#123;METRIC\_DURATION&#125;</span><br><span class="line">    dnsPolicy: ClusterFirst</span><br><span class="line">    restartPolicy: Never</span><br><span class="line">    serviceAccount: metrics-deployer</span><br><span class="line">    volumes:</span><br><span class="line">    - name: empty</span><br><span class="line">      emptyDir: &#123;&#125;</span><br><span class="line">    - name: secret</span><br><span class="line">      secret:</span><br><span class="line">        secretName: metrics-deployer</span><br><span class="line">parameters:</span><br><span class="line">-</span><br><span class="line">  description: &#39;Specify prefix for metrics components; e.g. for &quot;openshift&#x2F;origin-metrics-deployer:latest&quot;, set prefix &quot;openshift&#x2F;origin-&quot;&#39;</span><br><span class="line">  name: IMAGE\_PREFIX</span><br><span class="line">  value: &quot;10.110.17.138:5000&#x2F;library&#x2F;origin-&quot;</span><br><span class="line">-</span><br><span class="line">  description: &#39;Specify version for metrics components; e.g. for &quot;openshift&#x2F;origin-metrics-deployer:latest&quot;, set version &quot;latest&quot;&#39;</span><br><span class="line">  name: IMAGE\_VERSION</span><br><span class="line">  value: &quot;latest&quot;</span><br><span class="line">-</span><br><span class="line">  description: &quot;Internal URL for the master, for authentication retrieval&quot;</span><br><span class="line">  name: MASTER\_URL</span><br><span class="line">  value: &quot;https:&#x2F;&#x2F;oc-master.novalocal:8443&quot;</span><br><span class="line">-</span><br><span class="line">  description: &quot;External hostname where clients will reach Hawkular Metrics&quot;</span><br><span class="line">  name: HAWKULAR\_METRICS\_HOSTNAME</span><br><span class="line">  required: true</span><br><span class="line">  value: &quot;hawkular-metrics.devops.inspur&quot;</span><br><span class="line">-</span><br><span class="line">  description: &quot;If set to true the deployer will try and delete all the existing components before trying to redeploy.&quot;</span><br><span class="line">  name: REDEPLOY</span><br><span class="line">  value: &quot;false&quot;</span><br><span class="line">-</span><br><span class="line">  description: &quot;Set to true for persistent storage, set to false to use non persistent storage&quot;</span><br><span class="line">  name: USE\_PERSISTENT\_STORAGE</span><br><span class="line">  value: &quot;false&quot;</span><br><span class="line">-</span><br><span class="line">  description: &quot;The number of Cassandra Nodes to deploy for the initial cluster&quot;</span><br><span class="line">  name: CASSANDRA\_NODES</span><br><span class="line">  value: &quot;1&quot;</span><br><span class="line">-</span><br><span class="line">  description: &quot;The persistent volume size for each of the Cassandra nodes&quot;</span><br><span class="line">  name: CASSANDRA\_PV\_SIZE</span><br><span class="line">  value: &quot;10Gi&quot;</span><br><span class="line">-</span><br><span class="line">  description: &quot;How many days metrics should be stored for.&quot;</span><br><span class="line">  name: METRIC\_DURATION</span><br><span class="line">  value: &quot;7&quot;</span><br></pre></td></tr></table></figure>



<p>当pod运行成功后，还需要修改/etc/origin/master/master-config.yaml文件，增加metric配置</p>
<p>通过浏览器访问控制台时，也会出现无法访问监控信息的情况，需要确认</p>
<p>（1） 浏览器能够解析hawkular-metrics.devops.inspur地址</p>
<p>（2） 使用浏览器访问改地址<a href="https://hawkular-metrics.devops.inspur/hawkular/metrics%EF%BC%8C%E5%8A%A0%E8%BD%BDhttps%E8%AF%81%E4%B9%A6" target="_blank" rel="noopener">https://hawkular-metrics.devops.inspur/hawkular/metrics，加载https证书</a></p>
<h3 id="部署Route"><a href="#部署Route" class="headerlink" title="部署Route"></a>部署Route</h3><p>在master节点操作</p>
<p>oadm router haproxy-router –replicas=1 –credentials=/etc/origin/master/openshift-router.kubeconfig –service-account=router</p>
<p>增加用户：htpasswd /etc/origin/htpasswd admin</p>
<p>普通用户登录;oc login</p>
<p>系统管理员登录：</p>
<p>export KUBECONFIG=/etc/origin/master/admin.kubeconfig</p>
<p>oc login -u system:admin -n default</p>
<p>此时，整个环境搭建完成，</p>
<h2 id="外部docker-Registry搭建"><a href="#外部docker-Registry搭建" class="headerlink" title="外部docker-Registry搭建"></a>外部docker-Registry搭建</h2><p>搭建一个V2版本的docker-registry</p>
<p>使用一台新的虚拟机，部署docker,部署docker registry</p>
<p>docker run -d -p 5000:5000 –name registry registry:2</p>
<p>注意：在该registry上传镜像时，需要制定子目录：例如例如10.110.17.138:5000/library/postgresql</p>
<h2 id="管理OpenShift"><a href="#管理OpenShift" class="headerlink" title="管理OpenShift"></a>管理OpenShift</h2><h3 id="导入镜像"><a href="#导入镜像" class="headerlink" title="导入镜像"></a>导入镜像</h3><p>导入的镜像都存放到了 openshift的内部镜像</p>
<h4 id="1、从第三方仓库导入镜像"><a href="#1、从第三方仓库导入镜像" class="headerlink" title="1、从第三方仓库导入镜像"></a>1、从第三方仓库导入镜像</h4><p>从第三方仓库导入的镜像，只是在OpenShift的内部镜像仓库中，保存了索引信息，真正使用的时候，还是要去第三方仓库下载，将外部镜像导入到OpenShift，可以指定命名空间进行导入</p>
<p>进行导入：oc create <strong>-**f image-streams-centos7-python-postgresql</strong>.**json **-**n demo</p>
<p>导入镜像使用的文件参考参考image-streams-centos7-python-postgresql.json</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;kind&quot;: &quot;ImageStreamList&quot;,</span><br><span class="line">  &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">  &quot;items&quot;: \[</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;kind&quot;: &quot;ImageStream&quot;,</span><br><span class="line">      &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">          &quot;name&quot;: &quot;python&quot;,</span><br><span class="line">          &quot;annotations&quot;: &#123;</span><br><span class="line">               &quot;openshift.io&#x2F;image.insecureRepository&quot;: &quot;true&quot;</span><br><span class="line">             &#125;</span><br><span class="line">       &#125;,</span><br><span class="line">      &quot;spec&quot;: &#123;</span><br><span class="line">         &quot;dockerImageRepository&quot;: &quot;10.110.17.138:5000&#x2F;library&#x2F;python&quot;</span><br><span class="line">       &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;kind&quot;: &quot;ImageStream&quot;,</span><br><span class="line">      &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">       &quot;metadata&quot;: &#123;</span><br><span class="line">           &quot;name&quot;: &quot;postgresql&quot;,</span><br><span class="line">           &quot;annotations&quot;: &#123;</span><br><span class="line">               &quot;openshift.io&#x2F;image.insecureRepository&quot;: &quot;true&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">       &quot;spec&quot;: &#123;</span><br><span class="line">          &quot;dockerImageRepository&quot;: &quot;10.110.17.138:5000&#x2F;library&#x2F;postgresql&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;\]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>注意：外部的私有docker-registry 的镜像存储目录必须有子目录：例如10.110.17.138:5000/library/postgresql</p>
<h4 id="2、登录OpenShift-内部docker-registry，导入镜像"><a href="#2、登录OpenShift-内部docker-registry，导入镜像" class="headerlink" title="2、登录OpenShift 内部docker-registry，导入镜像"></a>2、登录OpenShift 内部docker-registry，导入镜像</h4><p>  1、在master节点获取，docker-registry服务的service ip</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> \[root@origin-master image-streams\]# oc get svc</span><br><span class="line">NAME              CLUSTER\_IP      EXTERNAL\_IP   PORT(S)                 SELECTOR                  AGE</span><br><span class="line">docker-registry   172.30.90.102   &lt;none&gt;        5000&#x2F;TCP                docker-registry&#x3D;default   20h</span><br><span class="line">haproxy-router    172.30.95.6     &lt;none&gt;        80&#x2F;TCP                  router&#x3D;haproxy-router     20h</span><br><span class="line">kubernetes        172.30.0.1      &lt;none&gt;        443&#x2F;TCP,53&#x2F;UDP,53&#x2F;TCP   &lt;none&gt;                    22h</span><br></pre></td></tr></table></figure>



<p>2、查看OpenShift内部docker-registry所在的节点，并登录</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">  root@origin-slave3 ~\]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE                                                                                                           COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">40a2a7f9c5f0        openshift&#x2F;origin-docker-registry:v1.1.0.1                                                                       &quot;&#x2F;bin&#x2F;sh -c &#39;REGISTRY&quot;   5 hours ago         Up 5 hours                              k8s\_registry.afeb0b36\_docker-registry-1-2wsvm\_default\_fa5e59e4-af5a-11e5-8632-fa163efe8294\_4fbf4ffa</span><br><span class="line">b29287d1a00c        10.110.17.138:5000&#x2F;library&#x2F;postgresql@sha256:11dbc16d7d84da0dfb42782ff1f64b0e263d9f8686fe4347f2d02a665582e945   &quot;container-entrypoint&quot;   5 hours ago         Up 5 hours                              k8s\_postgresql.5134f420\_postgresql-1-eun94\_demo\_7e990eb5-af62-11e5-8632-fa163efe8294\_155dadb8</span><br><span class="line">c217ccc5c319        openshift&#x2F;origin-pod:v1.1.0.1                                                                                   &quot;&#x2F;pod&quot;                   5 hours ago         Up 5 hours                              k8s\_POD.18d9fe1e\_postgresql-1-eun94\_demo\_7e990eb5-af62-11e5-8632-fa163efe8294\_257ba619</span><br><span class="line">bbc34e05ca92        openshift&#x2F;origin-pod:v1.1.0.1                                                                                   &quot;&#x2F;pod&quot;                   5 hours ago         Up 5 hours                              k8s\_POD.7c1fe15\_docker-registry-1-2wsvm\_default\_fa5e59e4-af5a-11e5-8632-fa163efe8294\_7a1bd148</span><br></pre></td></tr></table></figure>



<p>3、 以普通用户登录openshift，获取tocker</p>
<p><strong>[**root@origin</strong>-<strong>slave</strong>3** ~**]**# oc whoami **-**t</p>
<p>YAiqVCwCIhMT6FoVXfhpnga4UBiud0Mwzz84-sW3Om8</p>
<p>4、</p>
<p><strong>[**root@origin</strong>-<strong>slave</strong>3** ~<strong>]**# docker login **-**u admin **-**e admin@inspur</strong>.<strong>com **-**p YAiqVCwCIhMT6FoVXfhpnga4UBiud0Mwzz84-sW3Om8 **172.30.90.102:5000</strong></p>
<p>WARNING**:** login credentials saved in <strong>/**root</strong>/.<strong>docker</strong>/config.**json</p>
<p>Login Succeeded</p>
<p>5、 上传镜像</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\[root@origin-slave3 ~\]# docker tag 10.110.17.138:5000&#x2F;library&#x2F;hello-openshift 172.30.90.102:5000&#x2F;demo&#x2F;hello-openshift</span><br><span class="line">\[root@origin-slave3 ~\]# docker push 172.30.90.102:5000&#x2F;demo&#x2F;hello-openshift</span><br><span class="line">The push refers to a repository \[172.30.90.102:5000&#x2F;demo&#x2F;hello-openshift\] (len: 1)</span><br><span class="line">bcfa6006862b: Pushed</span><br><span class="line">bbc202431232: Pushed</span><br><span class="line">eb19dbec24c6: Pushed</span><br><span class="line">0055f04883dd: Pushed</span><br><span class="line">latest: digest: sha256:724411548d3c1ea88402288b2045275cd3fd0488f6d6500f4f6974b278f27f39 size: 6982</span><br></pre></td></tr></table></figure>

<h3 id="部署Template"><a href="#部署Template" class="headerlink" title="部署Template"></a>部署Template</h3><p>Template定义了一套部署应用的完成流程，包含打包、发布等，供开发者使用</p>
<p>部署template</p>
<p>oc create-f django-postgres.json -n openshif</p>
<p>Template 参考文件django-postgres.json，特别注意镜像的使用方法</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;kind&quot;: &quot;Template&quot;,</span><br><span class="line">  &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">  &quot;metadata&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &quot;django-psql-example&quot;,</span><br><span class="line">    &quot;annotations&quot;: &#123;</span><br><span class="line">      &quot;description&quot;: &quot;An example Django application with a PostgreSQL database&quot;,</span><br><span class="line">      &quot;tags&quot;: &quot;instant-app,python,django,postgresql&quot;,</span><br><span class="line">      &quot;iconClass&quot;: &quot;icon-python&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;labels&quot;: &#123;</span><br><span class="line">    &quot;template&quot;: &quot;django-psql-example&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;objects&quot;: \[</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;kind&quot;: &quot;Service&quot;,</span><br><span class="line">      &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;django-psql-example&quot;,</span><br><span class="line">        &quot;annotations&quot;: &#123;</span><br><span class="line">          &quot;description&quot;: &quot;Exposes and load balances the application pods&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;spec&quot;: &#123;</span><br><span class="line">        &quot;ports&quot;: \[</span><br><span class="line">          &#123;</span><br><span class="line">            &quot;name&quot;: &quot;web&quot;,</span><br><span class="line">            &quot;port&quot;: 8080,</span><br><span class="line">            &quot;targetPort&quot;: 8080</span><br><span class="line">          &#125;</span><br><span class="line">        \],</span><br><span class="line">        &quot;selector&quot;: &#123;</span><br><span class="line">          &quot;name&quot;: &quot;django-psql-example&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;kind&quot;: &quot;Route&quot;,</span><br><span class="line">      &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;django-psql-example&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;spec&quot;: &#123;</span><br><span class="line">        &quot;host&quot;: &quot;$&#123;APPLICATION\_DOMAIN&#125;&quot;,</span><br><span class="line">        &quot;to&quot;: &#123;</span><br><span class="line">          &quot;kind&quot;: &quot;Service&quot;,</span><br><span class="line">          &quot;name&quot;: &quot;django-psql-example&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;kind&quot;: &quot;ImageStream&quot;,</span><br><span class="line">      &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;django-psql-example&quot;,</span><br><span class="line">        &quot;annotations&quot;: &#123;</span><br><span class="line">          &quot;description&quot;: &quot;Keeps track of changes in the application image&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;kind&quot;: &quot;BuildConfig&quot;,</span><br><span class="line">      &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;django-psql-example&quot;,</span><br><span class="line">        &quot;annotations&quot;: &#123;</span><br><span class="line">          &quot;description&quot;: &quot;Defines how to build the application&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;spec&quot;: &#123;</span><br><span class="line">        &quot;source&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;Git&quot;,</span><br><span class="line">          &quot;git&quot;: &#123;</span><br><span class="line">            &quot;uri&quot;: &quot;$&#123;SOURCE\_REPOSITORY\_URL&#125;&quot;,</span><br><span class="line">            &quot;ref&quot;: &quot;$&#123;SOURCE\_REPOSITORY\_REF&#125;&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;contextDir&quot;: &quot;$&#123;CONTEXT\_DIR&#125;&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;strategy&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;Source&quot;,</span><br><span class="line">          &quot;sourceStrategy&quot;: &#123;</span><br><span class="line">            &quot;from&quot;: &#123;</span><br><span class="line">              &quot;kind&quot;: &quot;ImageStreamTag&quot;,</span><br><span class="line">              &quot;namespace&quot;: &quot;openshift&quot;,</span><br><span class="line">              &quot;name&quot;: &quot;python&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;output&quot;: &#123;</span><br><span class="line">          &quot;to&quot;: &#123;</span><br><span class="line">            &quot;kind&quot;: &quot;ImageStreamTag&quot;,</span><br><span class="line">            &quot;name&quot;: &quot;django-psql-example:latest&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;triggers&quot;: \[</span><br><span class="line">          &#123;</span><br><span class="line">            &quot;type&quot;: &quot;ImageChange&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &#123;</span><br><span class="line">            &quot;type&quot;: &quot;ConfigChange&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &#123;</span><br><span class="line">            &quot;type&quot;: &quot;GitHub&quot;,</span><br><span class="line">            &quot;github&quot;: &#123;</span><br><span class="line">              &quot;secret&quot;: &quot;$&#123;GITHUB\_WEBHOOK\_SECRET&#125;&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        \]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;kind&quot;: &quot;DeploymentConfig&quot;,</span><br><span class="line">      &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;django-psql-example&quot;,</span><br><span class="line">        &quot;annotations&quot;: &#123;</span><br><span class="line">          &quot;description&quot;: &quot;Defines how to deploy the application server&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;spec&quot;: &#123;</span><br><span class="line">        &quot;strategy&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;Rolling&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;triggers&quot;: \[</span><br><span class="line">          &#123;</span><br><span class="line">            &quot;type&quot;: &quot;ImageChange&quot;,</span><br><span class="line">            &quot;imageChangeParams&quot;: &#123;</span><br><span class="line">              &quot;automatic&quot;: true,</span><br><span class="line">              &quot;containerNames&quot;: \[</span><br><span class="line">                &quot;django-psql-example&quot;</span><br><span class="line">              \],</span><br><span class="line">              &quot;from&quot;: &#123;</span><br><span class="line">                &quot;kind&quot;: &quot;ImageStreamTag&quot;,</span><br><span class="line">                &quot;name&quot;: &quot;django-psql-example:latest&quot;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;,</span><br><span class="line">          &#123;</span><br><span class="line">            &quot;type&quot;: &quot;ConfigChange&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        \],</span><br><span class="line">        &quot;replicas&quot;: 1,</span><br><span class="line">        &quot;selector&quot;: &#123;</span><br><span class="line">          &quot;name&quot;: &quot;django-psql-example&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;template&quot;: &#123;</span><br><span class="line">          &quot;metadata&quot;: &#123;</span><br><span class="line">            &quot;name&quot;: &quot;django-psql-example&quot;,</span><br><span class="line">            &quot;labels&quot;: &#123;</span><br><span class="line">              &quot;name&quot;: &quot;django-psql-example&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;spec&quot;: &#123;</span><br><span class="line">            &quot;containers&quot;: \[</span><br><span class="line">              &#123;</span><br><span class="line">                &quot;name&quot;: &quot;django-psql-example&quot;,</span><br><span class="line">                &quot;image&quot;: &quot;django-psql-example&quot;,</span><br><span class="line">                &quot;ports&quot;: \[</span><br><span class="line">                  &#123;</span><br><span class="line">                    &quot;containerPort&quot;: 8080</span><br><span class="line">                  &#125;</span><br><span class="line">                \],</span><br><span class="line">                &quot;env&quot;: \[</span><br><span class="line">                  &#123;</span><br><span class="line">                    &quot;name&quot;: &quot;DATABASE\_SERVICE\_NAME&quot;,</span><br><span class="line">                    &quot;value&quot;: &quot;$&#123;DATABASE\_SERVICE\_NAME&#125;&quot;</span><br><span class="line">                  &#125;,</span><br><span class="line">                  &#123;</span><br><span class="line">                    &quot;name&quot;: &quot;DATABASE\_ENGINE&quot;,</span><br><span class="line">                    &quot;value&quot;: &quot;$&#123;DATABASE\_ENGINE&#125;&quot;</span><br><span class="line">                  &#125;,</span><br><span class="line">                  &#123;</span><br><span class="line">                    &quot;name&quot;: &quot;DATABASE\_NAME&quot;,</span><br><span class="line">                    &quot;value&quot;: &quot;$&#123;DATABASE\_NAME&#125;&quot;</span><br><span class="line">                  &#125;,</span><br><span class="line">                  &#123;</span><br><span class="line">                    &quot;name&quot;: &quot;DATABASE\_USER&quot;,</span><br><span class="line">                    &quot;value&quot;: &quot;$&#123;DATABASE\_USER&#125;&quot;</span><br><span class="line">                  &#125;,</span><br><span class="line">                  &#123;</span><br><span class="line">                    &quot;name&quot;: &quot;DATABASE\_PASSWORD&quot;,</span><br><span class="line">                    &quot;value&quot;: &quot;$&#123;DATABASE\_PASSWORD&#125;&quot;</span><br><span class="line">                  &#125;,</span><br><span class="line">                  &#123;</span><br><span class="line">                    &quot;name&quot;: &quot;APP\_CONFIG&quot;,</span><br><span class="line">                    &quot;value&quot;: &quot;$&#123;APP\_CONFIG&#125;&quot;</span><br><span class="line">                  &#125;,</span><br><span class="line">                  &#123;</span><br><span class="line">                    &quot;name&quot;: &quot;DJANGO\_SECRET\_KEY&quot;,</span><br><span class="line">                    &quot;value&quot;: &quot;$&#123;DJANGO\_SECRET\_KEY&#125;&quot;</span><br><span class="line">                  &#125;</span><br><span class="line">                \]</span><br><span class="line">              &#125;</span><br><span class="line">            \]</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;kind&quot;: &quot;Service&quot;,</span><br><span class="line">      &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;$&#123;DATABASE\_SERVICE\_NAME&#125;&quot;,</span><br><span class="line">        &quot;annotations&quot;: &#123;</span><br><span class="line">          &quot;description&quot;: &quot;Exposes the database server&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;spec&quot;: &#123;</span><br><span class="line">        &quot;ports&quot;: \[</span><br><span class="line">          &#123;</span><br><span class="line">            &quot;name&quot;: &quot;postgresql&quot;,</span><br><span class="line">            &quot;port&quot;: 5432,</span><br><span class="line">            &quot;targetPort&quot;: 5432</span><br><span class="line">          &#125;</span><br><span class="line">        \],</span><br><span class="line">        &quot;selector&quot;: &#123;</span><br><span class="line">          &quot;name&quot;: &quot;$&#123;DATABASE\_SERVICE\_NAME&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;kind&quot;: &quot;DeploymentConfig&quot;,</span><br><span class="line">      &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;$&#123;DATABASE\_SERVICE\_NAME&#125;&quot;,</span><br><span class="line">        &quot;annotations&quot;: &#123;</span><br><span class="line">          &quot;description&quot;: &quot;Defines how to deploy the database&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;spec&quot;: &#123;</span><br><span class="line">        &quot;strategy&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;Recreate&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;triggers&quot;: \[</span><br><span class="line">          &#123;</span><br><span class="line">            &quot;type&quot;: &quot;ImageChange&quot;,</span><br><span class="line">            &quot;imageChangeParams&quot;: &#123;</span><br><span class="line">              &quot;automatic&quot;: false,</span><br><span class="line">              &quot;containerNames&quot;: \[</span><br><span class="line">                &quot;postgresql&quot;</span><br><span class="line">              \],</span><br><span class="line">              &quot;from&quot;: &#123;</span><br><span class="line">                &quot;kind&quot;: &quot;ImageStreamTag&quot;,</span><br><span class="line">                &quot;namespace&quot;: &quot;openshift&quot;,</span><br><span class="line">                &quot;name&quot;: &quot;postgresql&quot;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;,</span><br><span class="line">          &#123;</span><br><span class="line">            &quot;type&quot;: &quot;ConfigChange&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        \],</span><br><span class="line">        &quot;replicas&quot;: 1,</span><br><span class="line">        &quot;selector&quot;: &#123;</span><br><span class="line">          &quot;name&quot;: &quot;$&#123;DATABASE\_SERVICE\_NAME&#125;&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;template&quot;: &#123;</span><br><span class="line">          &quot;metadata&quot;: &#123;</span><br><span class="line">            &quot;name&quot;: &quot;$&#123;DATABASE\_SERVICE\_NAME&#125;&quot;,</span><br><span class="line">            &quot;labels&quot;: &#123;</span><br><span class="line">              &quot;name&quot;: &quot;$&#123;DATABASE\_SERVICE\_NAME&#125;&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;spec&quot;: &#123;</span><br><span class="line">            &quot;containers&quot;: \[</span><br><span class="line">              &#123;</span><br><span class="line">                &quot;name&quot;: &quot;postgresql&quot;,</span><br><span class="line">                &quot;image&quot;: &quot;postgresql&quot;,</span><br><span class="line">                &quot;ports&quot;: \[</span><br><span class="line">                  &#123;</span><br><span class="line">                    &quot;containerPort&quot;: 5432</span><br><span class="line">                  &#125;</span><br><span class="line">                \],</span><br><span class="line">                &quot;env&quot;: \[</span><br><span class="line">                  &#123;</span><br><span class="line">                    &quot;name&quot;: &quot;POSTGRESQL\_USER&quot;,</span><br><span class="line">                    &quot;value&quot;: &quot;$&#123;DATABASE\_USER&#125;&quot;</span><br><span class="line">                  &#125;,</span><br><span class="line">                  &#123;</span><br><span class="line">                    &quot;name&quot;: &quot;POSTGRESQL\_PASSWORD&quot;,</span><br><span class="line">                    &quot;value&quot;: &quot;$&#123;DATABASE\_PASSWORD&#125;&quot;</span><br><span class="line">                  &#125;,</span><br><span class="line">                  &#123;</span><br><span class="line">                    &quot;name&quot;: &quot;POSTGRESQL\_DATABASE&quot;,</span><br><span class="line">                    &quot;value&quot;: &quot;$&#123;DATABASE\_NAME&#125;&quot;</span><br><span class="line">                  &#125;</span><br><span class="line">                \]</span><br><span class="line">              &#125;</span><br><span class="line">            \]</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  \],</span><br><span class="line">  &quot;parameters&quot;: \[</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;SOURCE\_REPOSITORY\_URL&quot;,</span><br><span class="line">      &quot;description&quot;: &quot;The URL of the repository with your application source code&quot;,</span><br><span class="line">      &quot;value&quot;: &quot;https:&#x2F;&#x2F;github.com&#x2F;openshift&#x2F;django-ex.git&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;SOURCE\_REPOSITORY\_REF&quot;,</span><br><span class="line">      &quot;description&quot;: &quot;Set this to a branch name, tag or other ref of your repository if you are not using the default branch&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;CONTEXT\_DIR&quot;,</span><br><span class="line">      &quot;description&quot;: &quot;Set this to the relative path to your project if it is not in the root of your repository&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;APPLICATION\_DOMAIN&quot;,</span><br><span class="line">      &quot;description&quot;: &quot;The exposed hostname that will route to the Django service, if left blank a value will be defaulted.&quot;,</span><br><span class="line">      &quot;value&quot;: &quot;&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;GITHUB\_WEBHOOK\_SECRET&quot;,</span><br><span class="line">      &quot;description&quot;: &quot;A secret string used to configure the GitHub webhook&quot;,</span><br><span class="line">      &quot;generate&quot;: &quot;expression&quot;,</span><br><span class="line">      &quot;from&quot;: &quot;\[a-zA-Z0-9\]&#123;40&#125;&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;DATABASE\_SERVICE\_NAME&quot;,</span><br><span class="line">      &quot;description&quot;: &quot;Database service name&quot;,</span><br><span class="line">      &quot;value&quot;: &quot;postgresql&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;DATABASE\_ENGINE&quot;,</span><br><span class="line">      &quot;description&quot;: &quot;Database engine: postgresql, mysql or sqlite (default)&quot;,</span><br><span class="line">      &quot;value&quot;: &quot;postgresql&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;DATABASE\_NAME&quot;,</span><br><span class="line">      &quot;description&quot;: &quot;Database name&quot;,</span><br><span class="line">      &quot;value&quot;: &quot;default&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;DATABASE\_USER&quot;,</span><br><span class="line">      &quot;description&quot;: &quot;Database user name&quot;,</span><br><span class="line">      &quot;value&quot;: &quot;django&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;DATABASE\_PASSWORD&quot;,</span><br><span class="line">      &quot;description&quot;: &quot;Database user password&quot;,</span><br><span class="line">      &quot;generate&quot;: &quot;expression&quot;,</span><br><span class="line">      &quot;from&quot;: &quot;\[a-zA-Z0-9\]&#123;16&#125;&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;APP\_CONFIG&quot;,</span><br><span class="line">      &quot;description&quot;: &quot;Relative path to Gunicorn configuration file (optional)&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;DJANGO\_SECRET\_KEY&quot;,</span><br><span class="line">      &quot;description&quot;: &quot;Set this to a long random string&quot;,</span><br><span class="line">      &quot;generate&quot;: &quot;expression&quot;,</span><br><span class="line">      &quot;from&quot;: &quot;\[\\\\w\]&#123;50&#125;&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  \]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>应用管理：</p>
<p>创建应用：基于源码（首先将源码build成镜像），基于镜像，基于模板</p>
<p>基于源码创建：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc new-app myproject&#x2F;my-ruby~https:&#x2F;&#x2F;github.com&#x2F;openshift&#x2F;ruby-hello-world.git （failed）</span><br><span class="line"> oc new-app &#x2F;home&#x2F;user&#x2F;code&#x2F;myapp --strategy&#x3D;docker</span><br></pre></td></tr></table></figure>
<p>基于镜像创建：</p>
<p>使用本地镜像创建：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc new-app 10.110.17.138:5000&#x2F;centos  --insecure-registry&#x3D;true</span><br></pre></td></tr></table></figure>
<p>ImageStreamTag</p>
<h3 id="Deployment"><a href="#Deployment" class="headerlink" title="Deployment"></a>Deployment</h3><p>文件定义一个部署，例如，可以使用内部的镜像，也可以使用外部的镜像</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ReplicationController</span><br><span class="line">metadata:</span><br><span class="line">  name: frontend-1</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    name: frontend</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        name: frontend</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: 172.30.90.102:5000&#x2F;demo&#x2F;hello-openshift</span><br><span class="line">        name: helloworld</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 8080</span><br><span class="line">          protocol: TCP</span><br><span class="line">      restartPolicy: Always</span><br></pre></td></tr></table></figure>

<h3 id="持久化存储-PersistentVolume"><a href="#持久化存储-PersistentVolume" class="headerlink" title="持久化存储 PersistentVolume "></a>持久化存储 PersistentVolume </h3><p>搭建NFS服务器，只支持NFSV4</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">**\[**root@oc**\-**master example**\]**\# cat **&#x2F;**etc**&#x2F;**exports</span><br><span class="line"></span><br><span class="line">**&#x2F;**opt**&#x2F;**docker-registry **192.168.6.0&#x2F;**24**(**rw**,**sync**,**no\_root\_squash**,**no\_all\_squash**)**</span><br><span class="line"></span><br><span class="line">**&#x2F;**openshift-pv **\*(**rw**,**all\_squash**)**</span><br><span class="line"></span><br><span class="line">**\[**root@oc**\-**master example**\]**\# mkdir **&#x2F;**openshift-pv</span><br><span class="line"></span><br><span class="line">**\[**root@oc**\-**master example**\]**\# chown **\-**R nfsnobody**:**nfsnobody &#x2F;openshift-pv</span><br><span class="line"></span><br><span class="line">**\[**root@oc**\-**master example**\]**\# chmod **777** **&#x2F;**opt**&#x2F;**openshift-pv**&#x2F;**</span><br></pre></td></tr></table></figure>

<p>创建PV:persistentvolume</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">**&#123;**</span><br><span class="line"></span><br><span class="line">  &quot;apiVersion&quot;**:** &quot;v1&quot;**,**</span><br><span class="line"></span><br><span class="line">  &quot;kind&quot;**:** &quot;PersistentVolume&quot;**,**</span><br><span class="line"></span><br><span class="line">  &quot;metadata&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">    &quot;name&quot;**:** &quot;jenkins&quot;</span><br><span class="line"></span><br><span class="line">  **&#125;,**</span><br><span class="line"></span><br><span class="line">  &quot;spec&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">    &quot;capacity&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">        &quot;storage&quot;**:** &quot;5Gi&quot;</span><br><span class="line"></span><br><span class="line">    **&#125;,**</span><br><span class="line"></span><br><span class="line">    &quot;accessModes&quot;**: \[** &quot;ReadWriteOnce&quot; **\],**</span><br><span class="line"></span><br><span class="line">    &quot;nfs&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">        &quot;path&quot;**:** &quot;&#x2F;openshit-pv&quot;**,**</span><br><span class="line"></span><br><span class="line">        &quot;server&quot;**:** &quot;192.168.6.7&quot;</span><br><span class="line"></span><br><span class="line">    **&#125;,**</span><br><span class="line"></span><br><span class="line">    &quot;persistentVolumeReclaimPolicy&quot;**:** &quot;Recycle&quot;</span><br><span class="line"></span><br><span class="line">  **&#125;**</span><br><span class="line"></span><br><span class="line">**&#125;**</span><br></pre></td></tr></table></figure>
<p>举例：jenkins使用创建的PV</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">**&#123;**</span><br><span class="line"></span><br><span class="line">  &quot;kind&quot;**:** &quot;Template&quot;**,**</span><br><span class="line"></span><br><span class="line">  &quot;apiVersion&quot;**:** &quot;v1&quot;**,**</span><br><span class="line"></span><br><span class="line">  &quot;metadata&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">    &quot;name&quot;**:** &quot;jenkins-persistent&quot;**,**</span><br><span class="line"></span><br><span class="line">    &quot;creationTimestamp&quot;**:** null**,**</span><br><span class="line"></span><br><span class="line">    &quot;annotations&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">      &quot;description&quot;**:** &quot;Jenkins service, with persistent storage.&quot;**,**</span><br><span class="line"></span><br><span class="line">      &quot;iconClass&quot;**:** &quot;icon-jenkins&quot;**,**</span><br><span class="line"></span><br><span class="line">      &quot;tags&quot;**:** &quot;instant-app,jenkins&quot;</span><br><span class="line"></span><br><span class="line">    **&#125;**</span><br><span class="line"></span><br><span class="line">  **&#125;,**</span><br><span class="line"></span><br><span class="line">  &quot;objects&quot;**: \[**</span><br><span class="line"></span><br><span class="line">    **&#123;**</span><br><span class="line"></span><br><span class="line">      &quot;kind&quot;**:** &quot;Service&quot;**,**</span><br><span class="line"></span><br><span class="line">      &quot;apiVersion&quot;**:** &quot;v1&quot;**,**</span><br><span class="line"></span><br><span class="line">      &quot;metadata&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">        &quot;name&quot;**:** &quot;$&#123;JENKINS\_SERVICE\_NAME&#125;&quot;**,**</span><br><span class="line"></span><br><span class="line">        &quot;creationTimestamp&quot;**:** null</span><br><span class="line"></span><br><span class="line">      **&#125;,**</span><br><span class="line"></span><br><span class="line">      &quot;spec&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">        &quot;ports&quot;**: \[**</span><br><span class="line"></span><br><span class="line">          **&#123;**</span><br><span class="line"></span><br><span class="line">            &quot;name&quot;**:** &quot;web&quot;**,**</span><br><span class="line"></span><br><span class="line">            &quot;protocol&quot;**:** &quot;TCP&quot;**,**</span><br><span class="line"></span><br><span class="line">            &quot;port&quot;**:** **8080,**</span><br><span class="line"></span><br><span class="line">            &quot;targetPort&quot;**:** **8080,**</span><br><span class="line"></span><br><span class="line">            &quot;nodePort&quot;**:** **0**</span><br><span class="line"></span><br><span class="line">          **&#125;**</span><br><span class="line"></span><br><span class="line">        **\],**</span><br><span class="line"></span><br><span class="line">        &quot;selector&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">          &quot;name&quot;**:** &quot;$&#123;JENKINS\_SERVICE\_NAME&#125;&quot;</span><br><span class="line"></span><br><span class="line">        **&#125;,**</span><br><span class="line"></span><br><span class="line">        &quot;portalIP&quot;**:** &quot;&quot;**,**</span><br><span class="line"></span><br><span class="line">        &quot;type&quot;**:** &quot;ClusterIP&quot;**,**</span><br><span class="line"></span><br><span class="line">        &quot;sessionAffinity&quot;**:** &quot;None&quot;</span><br><span class="line"></span><br><span class="line">      **&#125;**</span><br><span class="line"></span><br><span class="line">    **&#125;,**</span><br><span class="line"></span><br><span class="line">    **&#123;**</span><br><span class="line"></span><br><span class="line">      &quot;kind&quot;**:** &quot;Route&quot;**,**</span><br><span class="line"></span><br><span class="line">      &quot;apiVersion&quot;**:** &quot;v1&quot;**,**</span><br><span class="line"></span><br><span class="line">      &quot;metadata&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">        &quot;name&quot;**:** &quot;jenkins&quot;**,**</span><br><span class="line"></span><br><span class="line">        &quot;creationTimestamp&quot;**:** null</span><br><span class="line"></span><br><span class="line">      **&#125;,**</span><br><span class="line"></span><br><span class="line">      &quot;spec&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">        &quot;to&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">          &quot;kind&quot;**:** &quot;Service&quot;**,**</span><br><span class="line"></span><br><span class="line">          &quot;name&quot;**:** &quot;$&#123;JENKINS\_SERVICE\_NAME&#125;&quot;</span><br><span class="line"></span><br><span class="line">        **&#125;,**</span><br><span class="line"></span><br><span class="line">        &quot;tls&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">          &quot;termination&quot;**:** &quot;edge&quot;**,**</span><br><span class="line"></span><br><span class="line">          &quot;certificate&quot;**:** &quot;-----BEGIN CERTIFICATE-----**\\n**MIIDIjCCAgqgAwIBAgIBATANBgkqhkiG9w0BAQUFADCBoTELMAkGA1UEBhMCVVMx**\\n**CzAJBgNVBAgMAlNDMRUwEwYDVQQHDAxEZWZhdWx0IENpdHkxHDAaBgNVBAoME0Rl**\\n**ZmF1bHQgQ29tcGFueSBMdGQxEDAOBgNVBAsMB1Rlc3QgQ0ExGjAYBgNVBAMMEXd3**\\n**dy5leGFtcGxlY2EuY29tMSIwIAYJKoZIhvcNAQkBFhNleGFtcGxlQGV4YW1wbGUu**\\n**Y29tMB4XDTE1MDExMjE0MTk0MVoXDTE2MDExMjE0MTk0MVowfDEYMBYGA1UEAwwP**\\n**d3d3LmV4YW1wbGUuY29tMQswCQYDVQQIDAJTQzELMAkGA1UEBhMCVVMxIjAgBgkq**\\n**hkiG9w0BCQEWE2V4YW1wbGVAZXhhbXBsZS5jb20xEDAOBgNVBAoMB0V4YW1wbGUx**\\n**EDAOBgNVBAsMB0V4YW1wbGUwgZ8wDQYJKoZIhvcNAQEBBQADgY0AMIGJAoGBAMrv**\\n**gu6ZTTefNN7jjiZbS&#x2F;xvQjyXjYMN7oVXv76jbX8gjMOmg9m0xoVZZFAE4XyQDuCm**\\n**47VRx5Qrf&#x2F;YLXmB2VtCFvB0AhXr5zSeWzPwaAPrjA4ebG+LUo24ziS8KqNxrFs1M**\\n**mNrQUgZyQC6XIe1JHXc9t+JlL5UZyZQC1IfaJulDAgMBAAGjDTALMAkGA1UdEwQC**\\n**MAAwDQYJKoZIhvcNAQEFBQADggEBAFCi7ZlkMnESvzlZCvv82Pq6S46AAOTPXdFd**\\n**TMvrh12E1sdVALF1P1oYFJzG1EiZ5ezOx88fEDTW+Lxb9anw5&#x2F;KJzwtWcfsupf1m**\\n**V7J0D3qKzw5C1wjzYHh9&#x2F;Pz7B1D0KthQRATQCfNf8s6bbFLaw&#x2F;dmiIUhHLtIH5Qc**\\n**yfrejTZbOSP77z8NOWir+BWWgIDDB2&#x2F;&#x2F;3AkDIQvT20vmkZRhkqSdT7et4NmXOX&#x2F;j**\\n**jhPti4b2Fie0LeuvgaOdKjCpQQNrYthZHXeVlOLRhMTSk3qUczenkKTOhvP7IS9q**\\n**+Dzv5hqgSfvMG392KWh5f8xXfJNs4W5KLbZyl901MeReiLrPH3w&#x3D;**\\n**\-----END CERTIFICATE-----&quot;**,**</span><br><span class="line"></span><br><span class="line">          &quot;key&quot;**:** &quot;-----BEGIN PRIVATE KEY-----**\\n**MIICeAIBADANBgkqhkiG9w0BAQEFAASCAmIwggJeAgEAAoGBAMrvgu6ZTTefNN7j**\\n**jiZbS&#x2F;xvQjyXjYMN7oVXv76jbX8gjMOmg9m0xoVZZFAE4XyQDuCm47VRx5Qrf&#x2F;YL**\\n**XmB2VtCFvB0AhXr5zSeWzPwaAPrjA4ebG+LUo24ziS8KqNxrFs1MmNrQUgZyQC6X**\\n**Ie1JHXc9t+JlL5UZyZQC1IfaJulDAgMBAAECgYEAnxOjEj&#x2F;vrLNLMZE1Q9H7PZVF**\\n**WdP&#x2F;JQVNvQ7tCpZ3ZdjxHwkvf&#x2F;&#x2F;aQnuxS5yX2Rnf37BS&#x2F;TZu+TIkK4373CfHomSx**\\n**UTAn2FsLmOJljupgGcoeLx5K5nu7B7rY5L1NHvdpxZ4YjeISrRtEPvRakllENU5y**\\n**gJE8c2eQOx08ZSRE4TkCQQD7dws2&#x2F;FldqwdjJucYijsJVuUdoTqxP8gWL6bB251q**\\n**elP2&#x2F;a6W2elqOcWId28560jG9ZS3cuKvnmu&#x2F;4LG88vZFAkEAzphrH3673oTsHN+d**\\n**uBd5uyrlnGjWjuiMKv2TPITZcWBjB8nJDSvLneHF59MYwejNNEof2tRjgFSdImFH**\\n**mi995wJBAMtPjW6wiqRz0i41VuT9ZgwACJBzOdvzQJfHgSD9qgFb1CU&#x2F;J&#x2F;hpSRIM**\\n**kYvrXK9MbvQFvG6x4VuyT1W8mpe1LK0CQAo8VPpffhFdRpF7psXLK&#x2F;XQ&#x2F;0VLkG3O**\\n**KburipLyBg&#x2F;u9ZkaL0Ley5zL5dFBjTV2Qkx367Ic2b0u9AYTCcgi2DsCQQD3zZ7B**\\n**v7BOm7MkylKokY2MduFFXU0Bxg6pfZ7q3rvg8gqhUFbaMStPRYg6myiDiW&#x2F;JfLhF**\\n**TcFT4touIo7oriFJ**\\n**\-----END PRIVATE KEY-----&quot;**,**</span><br><span class="line"></span><br><span class="line">          &quot;caCertificate&quot;**:** &quot;-----BEGIN CERTIFICATE-----**\\n**MIIEFzCCAv+gAwIBAgIJALK1iUpF2VQLMA0GCSqGSIb3DQEBBQUAMIGhMQswCQYD**\\n**VQQGEwJVUzELMAkGA1UECAwCU0MxFTATBgNVBAcMDERlZmF1bHQgQ2l0eTEcMBoG**\\n**A1UECgwTRGVmYXVsdCBDb21wYW55IEx0ZDEQMA4GA1UECwwHVGVzdCBDQTEaMBgG**\\n**A1UEAwwRd3d3LmV4YW1wbGVjYS5jb20xIjAgBgkqhkiG9w0BCQEWE2V4YW1wbGVA**\\n**ZXhhbXBsZS5jb20wHhcNMTUwMTEyMTQxNTAxWhcNMjUwMTA5MTQxNTAxWjCBoTEL**\\n**MAkGA1UEBhMCVVMxCzAJBgNVBAgMAlNDMRUwEwYDVQQHDAxEZWZhdWx0IENpdHkx**\\n**HDAaBgNVBAoME0RlZmF1bHQgQ29tcGFueSBMdGQxEDAOBgNVBAsMB1Rlc3QgQ0Ex**\\n**GjAYBgNVBAMMEXd3dy5leGFtcGxlY2EuY29tMSIwIAYJKoZIhvcNAQkBFhNleGFt**\\n**cGxlQGV4YW1wbGUuY29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA**\\n**w2rK1J2NMtQj0KDug7g7HRKl5jbf0QMkMKyTU1fBtZ0cCzvsF4CqV11LK4BSVWaK**\\n**rzkaXe99IVJnH8KdOlDl5Dh&#x2F;+cJ3xdkClSyeUT4zgb6CCBqg78ePp+nN11JKuJlV**\\n**IG1qdJpB1J5O&#x2F;kCLsGcTf7RS74MtqMFo96446Zvt7YaBhWPz6gDaO&#x2F;TUzfrNcGLA**\\n**EfHVXkvVWqb3gqXUztZyVex&#x2F;gtP9FXQ7gxTvJml7UkmT0VAFjtZnCqmFxpLZFZ15**\\n**+qP9O7Q2MpsGUO&#x2F;4vDAuYrKBeg1ZdPSi8gwqUP2qWsGd9MIWRv3thI2903BczDc7**\\n**r8WaIbm37vYZAS9G56E4+wIDAQABo1AwTjAdBgNVHQ4EFgQUugLrSJshOBk5TSsU**\\n**ANs4+SmJUGwwHwYDVR0jBBgwFoAUugLrSJshOBk5TSsUANs4+SmJUGwwDAYDVR0T**\\n**BAUwAwEB&#x2F;zANBgkqhkiG9w0BAQUFAAOCAQEAaMJ33zAMV4korHo5aPfayV3uHoYZ**\\n**1ChzP3eSsF+FjoscpoNSKs91ZXZF6LquzoNezbfiihK4PYqgwVD2+O0&#x2F;Ty7UjN4S**\\n**qzFKVR4OS&#x2F;6lCJ8YncxoFpTntbvjgojf1DEataKFUN196PAANc3yz8cWHF4uvjPv**\\n**WkgFqbIjb+7D1YgglNyovXkRDlRZl0LD1OQ0ZWhd4Ge1qx8mmmanoBeYZ9+DgpFC**\\n**j9tQAbS867yeOryNe7sEOIpXAAqK&#x2F;DTu0hB6+ySsDfMo4piXCc2aA&#x2F;eI2DCuw08e**\\n**w17Dz9WnupZjVdwTKzDhFgJZMLDqn37HQnT6EemLFqbcR0VPEnfyhDtZIQ&#x3D;&#x3D;**\\n**\-----END CERTIFICATE-----&quot;</span><br><span class="line"></span><br><span class="line">        **&#125;**</span><br><span class="line"></span><br><span class="line">      **&#125;**</span><br><span class="line"></span><br><span class="line">    **&#125;,**</span><br><span class="line"></span><br><span class="line">    **&#123;**</span><br><span class="line"></span><br><span class="line">      &quot;kind&quot;**:** &quot;PersistentVolumeClaim&quot;**,**</span><br><span class="line"></span><br><span class="line">      &quot;apiVersion&quot;**:** &quot;v1&quot;**,**</span><br><span class="line"></span><br><span class="line">      &quot;metadata&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">        &quot;name&quot;**:** &quot;$&#123;JENKINS\_SERVICE\_NAME&#125;&quot;</span><br><span class="line"></span><br><span class="line">      **&#125;,**</span><br><span class="line"></span><br><span class="line">      &quot;spec&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">        &quot;accessModes&quot;**: \[**</span><br><span class="line"></span><br><span class="line">          &quot;ReadWriteOnce&quot;</span><br><span class="line"></span><br><span class="line">        **\],**</span><br><span class="line"></span><br><span class="line">        &quot;resources&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">          &quot;requests&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">            &quot;storage&quot;**:** &quot;$&#123;VOLUME\_CAPACITY&#125;&quot;</span><br><span class="line"></span><br><span class="line">          **&#125;**</span><br><span class="line"></span><br><span class="line">        **&#125;**</span><br><span class="line"></span><br><span class="line">      **&#125;**</span><br><span class="line"></span><br><span class="line">    **&#125;,**   </span><br><span class="line"></span><br><span class="line">    **&#123;**</span><br><span class="line"></span><br><span class="line">      &quot;kind&quot;**:** &quot;DeploymentConfig&quot;**,**</span><br><span class="line"></span><br><span class="line">      &quot;apiVersion&quot;**:** &quot;v1&quot;**,**</span><br><span class="line"></span><br><span class="line">      &quot;metadata&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">        &quot;name&quot;**:** &quot;$&#123;JENKINS\_SERVICE\_NAME&#125;&quot;**,**</span><br><span class="line"></span><br><span class="line">        &quot;creationTimestamp&quot;**:** null</span><br><span class="line"></span><br><span class="line">      **&#125;,**</span><br><span class="line"></span><br><span class="line">      &quot;spec&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">        &quot;strategy&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">          &quot;type&quot;**:** &quot;Recreate&quot;**,**</span><br><span class="line"></span><br><span class="line">          &quot;resources&quot;**: &#123;&#125;**</span><br><span class="line"></span><br><span class="line">        **&#125;,**</span><br><span class="line"></span><br><span class="line">        &quot;triggers&quot;**: \[**</span><br><span class="line"></span><br><span class="line">          **&#123;**</span><br><span class="line"></span><br><span class="line">            &quot;type&quot;**:** &quot;ImageChange&quot;**,**</span><br><span class="line"></span><br><span class="line">            &quot;imageChangeParams&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">              &quot;automatic&quot;**:** **true,**</span><br><span class="line"></span><br><span class="line">              &quot;containerNames&quot;**: \[**</span><br><span class="line"></span><br><span class="line">                &quot;jenkins&quot;</span><br><span class="line"></span><br><span class="line">              **\],**</span><br><span class="line"></span><br><span class="line">              &quot;from&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">                &quot;kind&quot;**:** &quot;ImageStreamTag&quot;**,**</span><br><span class="line"></span><br><span class="line">                &quot;name&quot;**:** &quot;jenkins-1-centos7:latest&quot;**,**</span><br><span class="line"></span><br><span class="line">                &quot;namespace&quot;**:** &quot;openshift&quot;</span><br><span class="line"></span><br><span class="line">              **&#125;,**</span><br><span class="line"></span><br><span class="line">              &quot;lastTriggeredImage&quot;**:** &quot;&quot;</span><br><span class="line"></span><br><span class="line">            **&#125;**</span><br><span class="line"></span><br><span class="line">          **&#125;,**</span><br><span class="line"></span><br><span class="line">          **&#123;**</span><br><span class="line"></span><br><span class="line">            &quot;type&quot;**:** &quot;ConfigChange&quot;</span><br><span class="line"></span><br><span class="line">          **&#125;**</span><br><span class="line"></span><br><span class="line">        **\],**</span><br><span class="line"></span><br><span class="line">        &quot;replicas&quot;**:** **1,**</span><br><span class="line"></span><br><span class="line">        &quot;selector&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">          &quot;name&quot;**:** &quot;$&#123;JENKINS\_SERVICE\_NAME&#125;&quot;</span><br><span class="line"></span><br><span class="line">        **&#125;,**</span><br><span class="line"></span><br><span class="line">        &quot;template&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">          &quot;metadata&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">            &quot;creationTimestamp&quot;**:** null**,**</span><br><span class="line"></span><br><span class="line">            &quot;labels&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">              &quot;name&quot;**:** &quot;$&#123;JENKINS\_SERVICE\_NAME&#125;&quot;</span><br><span class="line"></span><br><span class="line">            **&#125;**</span><br><span class="line"></span><br><span class="line">          **&#125;,**</span><br><span class="line"></span><br><span class="line">          &quot;spec&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">            &quot;containers&quot;**: \[**</span><br><span class="line"></span><br><span class="line">              **&#123;**</span><br><span class="line"></span><br><span class="line">                &quot;name&quot;**:** &quot;jenkins&quot;**,**</span><br><span class="line"></span><br><span class="line">                &quot;image&quot;**:** &quot;$&#123;JENKINS\_IMAGE&#125;&quot;**,**</span><br><span class="line"></span><br><span class="line">                &quot;env&quot;**: \[**</span><br><span class="line"></span><br><span class="line">                  **&#123;**</span><br><span class="line"></span><br><span class="line">                    &quot;name&quot;**:** &quot;JENKINS\_PASSWORD&quot;**,**</span><br><span class="line"></span><br><span class="line">                    &quot;value&quot;**:** &quot;$&#123;JENKINS\_PASSWORD&#125;&quot;</span><br><span class="line"></span><br><span class="line">                  **&#125;**</span><br><span class="line"></span><br><span class="line">                **\],**</span><br><span class="line"></span><br><span class="line">                &quot;resources&quot;**: &#123;&#125;,**</span><br><span class="line"></span><br><span class="line">                &quot;volumeMounts&quot;**: \[**</span><br><span class="line"></span><br><span class="line">                  **&#123;**</span><br><span class="line"></span><br><span class="line">                    &quot;name&quot;**:** &quot;$&#123;JENKINS\_SERVICE\_NAME&#125;-data&quot;**,**</span><br><span class="line"></span><br><span class="line">                    &quot;mountPath&quot;**:** &quot;&#x2F;var&#x2F;lib&#x2F;jenkins&quot;</span><br><span class="line"></span><br><span class="line">                  **&#125;**</span><br><span class="line"></span><br><span class="line">                **\],**</span><br><span class="line"></span><br><span class="line">                &quot;terminationMessagePath&quot;**:** &quot;&#x2F;dev&#x2F;termination-log&quot;**,**</span><br><span class="line"></span><br><span class="line">                &quot;imagePullPolicy&quot;**:** &quot;IfNotPresent&quot;**,**</span><br><span class="line"></span><br><span class="line">                &quot;capabilities&quot;**: &#123;&#125;,**</span><br><span class="line"></span><br><span class="line">                &quot;securityContext&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">                  &quot;capabilities&quot;**: &#123;&#125;,**</span><br><span class="line"></span><br><span class="line">                  &quot;privileged&quot;**:** **false**</span><br><span class="line"></span><br><span class="line">                **&#125;**</span><br><span class="line"></span><br><span class="line">              **&#125;**</span><br><span class="line"></span><br><span class="line">            **\],**</span><br><span class="line"></span><br><span class="line">            &quot;volumes&quot;**: \[**</span><br><span class="line"></span><br><span class="line">              **&#123;**</span><br><span class="line"></span><br><span class="line">                &quot;name&quot;**:** &quot;$&#123;JENKINS\_SERVICE\_NAME&#125;-data&quot;**,**</span><br><span class="line"></span><br><span class="line">                &quot;persistentVolumeClaim&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">                  &quot;claimName&quot;**:** &quot;$&#123;JENKINS\_SERVICE\_NAME&#125;&quot;</span><br><span class="line"></span><br><span class="line">                **&#125;**</span><br><span class="line"></span><br><span class="line">              **&#125;**</span><br><span class="line"></span><br><span class="line">            **\],**</span><br><span class="line"></span><br><span class="line">            &quot;restartPolicy&quot;**:** &quot;Always&quot;**,**</span><br><span class="line"></span><br><span class="line">            &quot;dnsPolicy&quot;**:** &quot;ClusterFirst&quot;</span><br><span class="line"></span><br><span class="line">          **&#125;**</span><br><span class="line"></span><br><span class="line">        **&#125;**</span><br><span class="line"></span><br><span class="line">      **&#125;**</span><br><span class="line"></span><br><span class="line">    **&#125;**</span><br><span class="line"></span><br><span class="line">  **\],**</span><br><span class="line"></span><br><span class="line">  &quot;parameters&quot;**: \[**</span><br><span class="line"></span><br><span class="line">    **&#123;**</span><br><span class="line"></span><br><span class="line">      &quot;name&quot;**:** &quot;JENKINS\_SERVICE\_NAME&quot;**,**</span><br><span class="line"></span><br><span class="line">      &quot;description&quot;**:** &quot;Jenkins service name&quot;**,**</span><br><span class="line"></span><br><span class="line">      &quot;value&quot;**:** &quot;jenkins&quot;</span><br><span class="line"></span><br><span class="line">    **&#125;,**</span><br><span class="line"></span><br><span class="line">    **&#123;**</span><br><span class="line"></span><br><span class="line">      &quot;name&quot;**:** &quot;JENKINS\_PASSWORD&quot;**,**</span><br><span class="line"></span><br><span class="line">      &quot;description&quot;**:** &quot;Password for the Jenkins user&quot;**,**</span><br><span class="line"></span><br><span class="line">      &quot;generate&quot;**:** &quot;expression&quot;**,**</span><br><span class="line"></span><br><span class="line">      &quot;value&quot;**:** &quot;password&quot;</span><br><span class="line"></span><br><span class="line">    **&#125;,**</span><br><span class="line"></span><br><span class="line">    **&#123;**</span><br><span class="line"></span><br><span class="line">      &quot;name&quot;**:** &quot;VOLUME\_CAPACITY&quot;**,**</span><br><span class="line"></span><br><span class="line">      &quot;description&quot;**:** &quot;Volume space available for data, e.g. 512Mi, 2Gi&quot;**,**</span><br><span class="line"></span><br><span class="line">      &quot;value&quot;**:** &quot;512Mi&quot;**,**</span><br><span class="line"></span><br><span class="line">      &quot;required&quot;**:** **true**</span><br><span class="line"></span><br><span class="line">    **&#125;**</span><br><span class="line"></span><br><span class="line">  **\],**</span><br><span class="line"></span><br><span class="line">  &quot;labels&quot;**: &#123;**</span><br><span class="line"></span><br><span class="line">    &quot;template&quot;**:** &quot;jenkins-persistent-template&quot;</span><br><span class="line"></span><br><span class="line">  **&#125;**</span><br><span class="line"></span><br><span class="line">**&#125;**</span><br></pre></td></tr></table></figure>
<h3 id="Route使用"><a href="#Route使用" class="headerlink" title="Route使用"></a>Route使用</h3><p>Route提供了外部访问服务的能力，此时需要外部dns的支持，dns的进行地址解析需要配置到haproxy-rouer所在的node节点IP</p>
<p>登录到haproxy-route所在的容器查看配置信息，确认是将每个应用的pod的IP地址配置到了haproxy的配置文件，完成负载均衡</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">backend be\_http\_demo\_django-psql-example</span><br><span class="line"></span><br><span class="line">  mode http</span><br><span class="line"></span><br><span class="line">  option redispatch</span><br><span class="line"></span><br><span class="line">  option forwardfor</span><br><span class="line"></span><br><span class="line">  balance leastconn</span><br><span class="line"></span><br><span class="line">  timeout check **5000**ms</span><br><span class="line"></span><br><span class="line">  http-request set-header X-Forwarded-Host **%\[**req**.**hdr**(**host**)\]**</span><br><span class="line"></span><br><span class="line">  http-request set-header X-Forwarded-Port **%\[**dst\_port**\]**</span><br><span class="line"></span><br><span class="line">  http-request set-header X-Forwarded-Proto https if **&#123;** ssl\_fc **&#125;**</span><br><span class="line"></span><br><span class="line">    cookie OPENSHIFT\_demo\_django-psql-example\_SERVERID insert indirect nocache httponly</span><br><span class="line"></span><br><span class="line">    http-request set-header X-Forwarded-Proto http</span><br><span class="line"></span><br><span class="line">  http-request set-header Forwarded for**\&#x3D;%\[**src**\],**host**\&#x3D;%\[**req**.**hdr**(**host**)\],**proto**\&#x3D;%\[**req**.**hdr**(**X-Forwarded-Proto**)\]**</span><br><span class="line"></span><br><span class="line">  server **10.1.0.3:8080 10.1.0.3:8080** check inter **5000**ms cookie **10.1.0.3:8080**</span><br><span class="line"></span><br><span class="line">backend be\_http\_demo\_jenkins</span><br><span class="line"></span><br><span class="line">  mode http</span><br><span class="line"></span><br><span class="line">  option redispatch</span><br><span class="line"></span><br><span class="line">  option forwardfor</span><br><span class="line"></span><br><span class="line">  balance leastconn</span><br><span class="line"></span><br><span class="line">  timeout check **5000**ms</span><br><span class="line"></span><br><span class="line">  http-request set-header X-Forwarded-Host **%\[**req**.**hdr**(**host**)\]**</span><br><span class="line"></span><br><span class="line">  http-request set-header X-Forwarded-Port **%\[**dst\_port**\]**</span><br><span class="line"></span><br><span class="line">  http-request set-header X-Forwarded-Proto https if **&#123;** ssl\_fc **&#125;**</span><br><span class="line"></span><br><span class="line">    cookie OPENSHIFT\_demo\_jenkins\_SERVERID insert indirect nocache httponly</span><br><span class="line"></span><br><span class="line">    http-request set-header X-Forwarded-Proto http</span><br><span class="line"></span><br><span class="line">  http-request set-header Forwarded for**\&#x3D;%\[**src**\],**host**\&#x3D;%\[**req**.**hdr**(**host**)\],**proto**\&#x3D;%\[**req**.**hdr**(**X-Forwarded-Proto**)\]**</span><br><span class="line"></span><br><span class="line">  server **10.1.1.20:8080 10.1.1.20:8080** check inter **5000**ms cookie **10.1.1.20:8080**</span><br></pre></td></tr></table></figure>
<h4 id="DNS-配置"><a href="#DNS-配置" class="headerlink" title="DNS 配置"></a>DNS 配置</h4><p>DNS是基于ubuntu14.04 部署了bind9，参考配置：192.168.10.149为haproxy-router所在的节点IP（运行haproxy-router的容器所在的节点IP）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@origin**\-**dns**:&#x2F;**etc**&#x2F;**bind# cat **&#x2F;**etc**&#x2F;**bind**&#x2F;**named**.**conf**.**local</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Do any local configuration here</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Consider adding the 1918 zones here, if they are not used in your</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; organization</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;include &quot;&#x2F;etc&#x2F;bind&#x2F;zones.rfc1918&quot;;</span><br><span class="line"></span><br><span class="line">zone &quot;novalocal&quot; **&#123;**</span><br><span class="line"></span><br><span class="line">        **type** master**;**</span><br><span class="line"></span><br><span class="line">        file &quot;&#x2F;etc&#x2F;bind&#x2F;db.novalocal&quot;**;**</span><br><span class="line"></span><br><span class="line">**&#125;;**</span><br><span class="line"></span><br><span class="line">zone  &quot;devops.inspur&quot; **&#123;** </span><br><span class="line"></span><br><span class="line">     **type** master**;** </span><br><span class="line"></span><br><span class="line">     file &quot;&#x2F;etc&#x2F;bind&#x2F;db.devops.inspur&quot;**;** </span><br><span class="line"></span><br><span class="line">**&#125;;** </span><br><span class="line"></span><br><span class="line">zone  &quot;10.168.192.in-addr.arpa&quot; **&#123;** </span><br><span class="line"></span><br><span class="line">     **type** master**;** </span><br><span class="line"></span><br><span class="line">     file &quot;&#x2F;etc&#x2F;bind&#x2F;db.17.110.10&quot;**;** </span><br><span class="line"></span><br><span class="line">**&#125;;**</span><br><span class="line"></span><br><span class="line">cat db**.**devops**.**inspur</span><br><span class="line"></span><br><span class="line">**;** </span><br><span class="line"></span><br><span class="line">**;** BIND data file for dev sites </span><br><span class="line"></span><br><span class="line">**;** </span><br><span class="line"></span><br><span class="line">$TTL    **604800** </span><br><span class="line"></span><br><span class="line">@       IN      SOA     devops**.**inspur**.** root**.**devops**.**inspur**. (** </span><br><span class="line"></span><br><span class="line">                              **3**         **;** Serial </span><br><span class="line"></span><br><span class="line">                         **604800**         **;** Refresh </span><br><span class="line"></span><br><span class="line">                          **86400**         **;** Retry  </span><br><span class="line"></span><br><span class="line">                        **2419200**         **;** Expire </span><br><span class="line"></span><br><span class="line">                         **604800** **)       ;** Negative Cache TTL </span><br><span class="line"></span><br><span class="line">**;** </span><br><span class="line"></span><br><span class="line">@       IN      NS      devops**.**inspur**.** </span><br><span class="line"></span><br><span class="line">@       IN      A       **10.110.17.131**</span><br><span class="line"></span><br><span class="line">**\*.**devops**.**inspur**.**  **14400**   IN      A       **10.110.17.131**</span><br><span class="line"></span><br><span class="line">root@origin**\-**dns**:&#x2F;**etc**&#x2F;**bind# cat db.17.110.10</span><br><span class="line"></span><br><span class="line">**;** </span><br><span class="line"></span><br><span class="line">**;** BIND reverse data file for dev domains </span><br><span class="line"></span><br><span class="line">**;** </span><br><span class="line"></span><br><span class="line">$TTL    **604800** </span><br><span class="line"></span><br><span class="line">@       IN      SOA     dev**.** root**.**dev**. (** </span><br><span class="line"></span><br><span class="line">                              **3**         **;** Serial </span><br><span class="line"></span><br><span class="line">                         **604800**         **;** Refresh </span><br><span class="line"></span><br><span class="line">                          **86400**         **;** Retry </span><br><span class="line"></span><br><span class="line">                        **2419200**         **;** Expire </span><br><span class="line"></span><br><span class="line">                         **604800** **)       ;** Negative Cache TTL </span><br><span class="line"></span><br><span class="line">**;** </span><br><span class="line"></span><br><span class="line">@        IN      NS      devops**.**inspur**.** </span><br><span class="line"></span><br><span class="line">**149**      IN      PTR     devops**.**inspur**.**</span><br></pre></td></tr></table></figure>

<p>获取部署的应用对应的Router</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">**\[**root@origin**\-**master image-streams**\]**\# oc get route **\-**n demo</span><br><span class="line"></span><br><span class="line">NAME               HOST**&#x2F;**PORT                            PATH      SERVICE            LABELS                      INSECURE POLICY   TLS TERMINATION</span><br><span class="line"></span><br><span class="line">django-psql-test   www**.**django-psql-test**.**devops**.**inspur             django-psql-test   template**\&#x3D;**django-psql-test</span><br></pre></td></tr></table></figure>
<p>windows或者linux配置dns地址就可以访问该应用</p>
<h2 id="S2I"><a href="#S2I" class="headerlink" title="S2I"></a>S2I</h2><p>参考（<a href="https://github.com/openshift/source-to-image%EF%BC%89" target="_blank" rel="noopener">https://github.com/openshift/source-to-image）</a></p>
<p>简单了解了S2I的思路，类似CloudFoundry的BuildPack，S2I基于build image+source code，使用脚本将源码打入build image，作为应用的docker image。这里的build image 类似CloudFoundry的buildpack，build image里面内置了应用的运行环境例如tomcat、jre、nginx</p>
<p>例如运行python程序的buil image</p>
<p><a href="https://github.com/openshift/sti-python/tree/master/2.7" target="_blank" rel="noopener">https://github.com/openshift/sti-python/tree/master/2.7</a></p>
<p><img src="file://C:/Users/wangd/AppData/Local/Temp/msohtmlclip1/01/clip_image005.jpg"></p>
<p>制作Build Image的dockerFile：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM openshift**&#x2F;**base-centos7</span><br><span class="line"></span><br><span class="line">\# This image provides a Python **2.7** environment you can use to run your Python</span><br><span class="line"></span><br><span class="line">\# applications**.**</span><br><span class="line"></span><br><span class="line">MAINTAINER SoftwareCollections**.**org **&lt;**sclorg@redhat**.**com**\&gt;**</span><br><span class="line"></span><br><span class="line">EXPOSE **8080**</span><br><span class="line"></span><br><span class="line">ENV PYTHON\_VERSION**\&#x3D;****2.7** \\</span><br><span class="line"></span><br><span class="line">    PATH**\&#x3D;**$HOME**&#x2F;.**local**&#x2F;**bin**&#x2F;:**$PATH</span><br><span class="line"></span><br><span class="line">LABEL io**.**k8s**.****description****\&#x3D;**&quot;Platform for building and running Python 2.7 applications&quot; \\</span><br><span class="line"></span><br><span class="line">      io**.**k8s**.**display-name**\&#x3D;**&quot;Python 2.7&quot; \\</span><br><span class="line"></span><br><span class="line">      io**.**openshift**.**expose-services**\&#x3D;**&quot;8080:http&quot; \\</span><br><span class="line"></span><br><span class="line">      io**.**openshift**.**tags**\&#x3D;**&quot;builder,python,python27,rh-python27&quot;</span><br><span class="line"></span><br><span class="line">RUN yum install **\-**y centos-release-scl **&amp;&amp;** \\</span><br><span class="line"></span><br><span class="line">    yum install **\-**y **\--**setopt**\&#x3D;**tsflags**\&#x3D;**nodocs **\--**enablerepo**\&#x3D;**centosplus python27 python27-python-devel python27-python-setuptools python27-python-pip epel-release **&amp;&amp;** \\</span><br><span class="line"></span><br><span class="line">    yum install **\-**y **\--**setopt**\&#x3D;**tsflags**\&#x3D;**nodocs install nss\_wrapper **&amp;&amp;** \\</span><br><span class="line"></span><br><span class="line">    yum clean all **\-**y</span><br><span class="line"></span><br><span class="line">\# Copy the S2I scripts from the specific language image to $STI\_SCRIPTS\_PATH</span><br><span class="line"></span><br><span class="line">COPY **.&#x2F;**s2i**&#x2F;**bin**&#x2F;** $STI\_SCRIPTS\_PATH</span><br><span class="line"></span><br><span class="line">\# Each language image can have &#39;contrib&#39; a directory with extra files needed to</span><br><span class="line"></span><br><span class="line">\# run and build the applications**.**</span><br><span class="line"></span><br><span class="line">COPY **.&#x2F;**contrib**&#x2F; &#x2F;**opt**&#x2F;**app-root</span><br><span class="line"></span><br><span class="line">RUN chown **\-**R **1001:0** **&#x2F;**opt**&#x2F;**app-root **&amp;&amp;** chmod **\-**R og**+**rwx **&#x2F;**opt**&#x2F;**app-root</span><br><span class="line"></span><br><span class="line">USER **1001**</span><br><span class="line"></span><br><span class="line">\# Set the **default** CMD to print the usage of the language image</span><br><span class="line"></span><br><span class="line">CMD $STI\_SCRIPTS\_PATH**&#x2F;**usage</span><br></pre></td></tr></table></figure>
<p>不同开发环境需要提供不同的build image，如果同一开发环境下，应用对运行环境需求不同，也需要开发不同的build image。</p>
<p>S2I 虽然简化了应用部署的流程，但是增加了更多的定制化过程。</p>
<p>建议使用场景：平台提供固定的几种build image。</p>
]]></content>
  </entry>
  <entry>
    <title>Kubernetes 弃用docker</title>
    <url>/2021/01/04/Kubernetes-%E5%BC%83%E7%94%A8Docker/</url>
    <content><![CDATA[<p>Kubernetes 在其最新的 Changelog 中宣布，自 Kubernetes 1.20 之后将弃用 docker 作为容器运行时。那么这到底是怎么回事？开发者和企业会受到什么样到影响？</p>
<p>近几年，Kubernetes 已经成为自有机房、云上广泛使用的容器编排方案，最广泛的使用方式是 Kubernetes+docker。从 DevOps 人员的角度，一面用 kubctl 命令、k8s API 来操作集群，一面在单机用 docker 命令来管理镜像、运行镜像。</p>
<p>单独用 docker 的情况，在一些公司的场景里面也是有的。一种场景是“只分不合”，把一台机器用 docker 做资源隔离，但是不需要将多容器“编排”。单独用 Kubernetes，下层不是 docker 的情况，并不算很多。</p>
<p>Kubernetes 和 docker 的关系，简单来说，有互补，也有竞争。在一般的认知中，Kubernetes 和 docker 是互补关系：</p>
<pre><code>        dockers 属于下层——容器引擎
        Kubernetes 属于上层——编排调度层。</code></pre>
<p>​</p>
<p>docker 源于 Linux Container，可以将一台机器的资源分成 N 份容器，做到资源的隔离，并将可运行的程序定义为标准的 docker image；Kubernetes 则可以把不同机器的每份容器进行编排、调度，组成分布式系统。<br>Kubernetes 和 docker 并不完全是“泾渭分明”的互补关系，它之间有重叠部分，也可以说成是竞争，主要在于几个点：</p>
<ul>
<li><p>系统三大移植资源是计算、存储、网络，从 Kubernetes 角度 docker 属于“Runtime（运行时）”，也就是计算资源；但是 docker 技术体系里面，本身也包括存储层、网络层。上下层职责的重叠，也可以看作竞争。</p>
</li>
<li><p>docker 原本有个原生的调度引擎——Swarm，几年前在调度编排领域，还是 Kubernetes、Mesos、Swarm 三者并存，Kubernetes 最终胜出，但 docker 仍有“继续向上做一层的意愿”。</p>
</li>
</ul>
<p><img src="/2021/01/04/Kubernetes-%E5%BC%83%E7%94%A8Docker/1.png" alt="avatar"></p>
<p>Kubernetes 在如何使用 docker 方面，存在争议和变数。kubernetes 1.20 ChangeLog 中所谓要废弃 docker 的传言，也是无风不起浪。换句话说，即便 Kubernetes 一直用 docker，也不是用 docker 的全部，多少是不一样的。</p>
<p><img src="/2021/01/04/Kubernetes-%E5%BC%83%E7%94%A8Docker/2.png" alt="avatar"></p>
<p>而且，“弃用 docker”这个词本身有多重的含义，docker 并非一个单层软件，Kubernetes 1.20 弃用 dockershim 并不代表弃用了 docker 的全部，仍有 containerd 可以对接 docker。</p>
<h2 id="Kubernetes-有-CRI、OCI-两个容器标准"><a href="#Kubernetes-有-CRI、OCI-两个容器标准" class="headerlink" title="Kubernetes 有 CRI、OCI 两个容器标准"></a>Kubernetes 有 CRI、OCI 两个容器标准</h2><p>在目前广泛使用 kubernetes 与 Runtime 的桥接方案，CRI（Container Runtime Interface）与 OCI（Open Container Initiative）是“套娃“关系。Kubernetes 的 kubelet 调用 CRI，OCI 的实现者然后再调用 OCI。</p>
<p>下图也说明了 CRI 与 OCI 的关系：</p>
<p><img src="/2021/01/04/Kubernetes-%E5%BC%83%E7%94%A8Docker/3.jpg" alt="avatar"></p>
<p>从 Kubernetes 的角度，CRI 是与 CNI（网络）、CSI（存储）相同层级的接口。</p>
<ul>
<li>OCI 是个自下而上的标准，也就是从实现抽象出接口，它是 Linux Foundation 主导的。docker 实现的核心 RunC，也就是 OCI 的典型实现、标准实现。</li>
<li>CRI 是个自上而下的标准，源于 Kubernetes 对移植层（运行时）的要求。</li>
</ul>
<p>容器引擎层自下而上定义 OCI，容器编排层自上而下定义 CRI，这也让它们出现了“套娃“运行情况。</p>
<p>在 Kubernetes 的 dockershim、cri-containerd、cri-o 三种实现中，RedHat 推崇的 cri-o 已经比较主流，它虽然仍是“套娃“，但已经比较精简。</p>
<p><img src="/2021/01/04/Kubernetes-%E5%BC%83%E7%94%A8Docker/4.jpg" alt="avatar"></p>
<p>下面是从 kubernetes 集群运行的全景图看 cri-o 的位置：</p>
<p><img src="/2021/01/04/Kubernetes-%E5%BC%83%E7%94%A8Docker/5.jpg" alt="avatar"></p>
<h2 id="docker-本源于-Linux-Container"><a href="#docker-本源于-Linux-Container" class="headerlink" title="docker 本源于 Linux Container"></a>docker 本源于 Linux Container</h2><p>docker 作为容器引擎，其实现的基础是 Linux Container——从内核到用户空间的机制。Linux Container 可以分成两个部分，内核里面的 cgroup，用户空间的 lxc。docker 最初实现的时候，也是完全基于 Linux Container 的，基于 lxc 做更上层的东西。这张很多人认为“与事实不符“的图，其实代表了过去：</p>
<p><img src="/2021/01/04/Kubernetes-%E5%BC%83%E7%94%A8Docker/6.jpg" alt="avatar"></p>
<p>在 docker 的发展过程中，最终弃用了 C 语言写成 lxc，换成了 go 语言写成的 libcontainer。下面的图也不是很新，但它更能表示 docker 后续典型的架构，这里面已经没有了 lxc。</p>
<p><img src="/2021/01/04/Kubernetes-%E5%BC%83%E7%94%A8Docker/7.jpg" alt="avatar"></p>
<p>然而，万变不离其宗，docker 实现的本源，还是 Linux Container。即便不用 lxc，当仍要用内核的 cgroup，并且模式也是类似的。</p>
<h2 id="Kubernetes-最终如何桥接容器"><a href="#Kubernetes-最终如何桥接容器" class="headerlink" title="Kubernetes 最终如何桥接容器"></a>Kubernetes 最终如何桥接容器</h2><p>从纯技术的角度，与其讨 Kubernetes 与 docker 关系，不如讨论 Kubernetes 与最终容器实现层的关系。因为 docker 这个名词，在不同的时候，有着不同的内涵、外延。</p>
<p>下面是 docker 的简图：</p>
<p><img src="/2021/01/04/Kubernetes-%E5%BC%83%E7%94%A8Docker/8.jpg" alt="avatar"></p>
<p>从软件模块的角度，图中的 docker Engine、cri-containd、containd-shim、runC 都属于 docker 体系的软件。</p>
<p>下图中的紫、橙、红三种颜色，代表了 dockershim、cri-containerd、cri-o 三种 CRI 的典型方式——流程在逐渐缩短，这也是 CRI 实现的一个演进过程。</p>
<p><img src="/2021/01/04/Kubernetes-%E5%BC%83%E7%94%A8Docker/9.jpg" alt="avatar"></p>
<p>1、 如果是 kubelet 的 dockershim 模式（紫色），流程是这样的：</p>
<ul>
<li>1.kubelet 从 CRI 的 gRPC 调用 dockershim，二者在同一个进程</li>
<li>2.dockershim 调用 docker 守护进程</li>
<li>3.docker 守护进程调用 containerd；containerd 调用 containerd-shim（有时名为 docker-containerd-shim 守护进程）完成创建容器等操作</li>
<li>4.containerd-shim 访问 OCI 的实现 runC（命令行可执行程序）<br>​</li>
</ul>
<p>2、 如果是 kubelet 的 cri-containerd 模式（橙色），流程是这样的：</p>
<ul>
<li>1.kubelet 从 CRI 的 gRPC 调用 cri-containerd；</li>
<li>2.cri-containerd 调用 containerd；containerd 调用 containerd-shim（同上）</li>
<li>3.containerd-shim 调用 RucnC （同上）<br>​</li>
</ul>
<p>在很多人的印象中，如果不用 docker 守护进程，就相当于“弃用 docker“，这其实也就是从 dockershim 到 containerd 的变化。从另一个角度来说，containerd 这个守护进程，也是 docker 组织做的。</p>
<p>3、 如果是 kubelet 的 cri-o 模式（红色），则更加简练：</p>
<ul>
<li>1.kubelet 从 CRI 的 gRPC 调用 cri-o；</li>
<li>2.cri-o 调用 OCI 的实现 runC<br>​</li>
</ul>
<p>如果以 kubelet 调用 CRI 为起点，OCI 的 runC 调用为终点，三种模式经历的可执行程序分别是：</p>
<ul>
<li>dockershim 模式：dockershim(*)-&gt;dockd-&gt;containerd-&gt;containerd-shim</li>
<li>cri-containerd 模式：cri-containerd(*)-&gt; containerd-&gt;containerd-shim</li>
<li>cri-o 模式：cri-o<br>​<br>dockershim 模式有 3 个可执行程序，dockershim 一般与 kubelet 同进程；cri-containerd 模式有 2-3 个可执行程序，cri-containerd 可与 containerd 同进程；cri-o 模式只有 1 个可执行程序。</li>
</ul>
<p>显然在这种 Red Hat 推崇的 cri-o 模式下，docker 体系的 containerd 也用不着了，只剩 runC 这个命令行的程序。runC 也是用 go 写成的，里面有调用 libcontainer。</p>
<p>当 docker 萎缩到这个地步，其实也只剩 Linux 内核里面 cgroup、namespace 功能的封装了。</p>
<p>总结来说，由于老技术实现的惯性，在生产环境大量使用的经典 Kubernetes+ docker 方案依然运行，且运维已经成熟，不会很快升级。对于开发人员、企业，对于 K8S API 的使用频率、变数，远远大于 docker API，至于 Kubernetes 和 docker 的桥接，更不用关心。因此，即便“彻底弃用 docker”，对开发者与企业的影响也非常有限。</p>
]]></content>
  </entry>
  <entry>
    <title>团队管理</title>
    <url>/2021/01/15/%E5%9B%A2%E9%98%9F%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<h2 id="痛点分析"><a href="#痛点分析" class="headerlink" title="痛点分析"></a>痛点分析</h2><h3 id="自我认知"><a href="#自我认知" class="headerlink" title="自我认知"></a>自我认知</h3><p> 从个人角度，对于新成为团队管理者，或者已经成为团队管理者一段时间，可能都存在这样的问题</p>
<ol>
<li>作为组长，依然沉迷于代码，不能自拔</li>
<li>甩手掌柜，给组员完全放权，最后检查工作结果</li>
<li>没有理论支撑，团队管理没有章法，想到哪就做到那，常常会出现丢三落四的现象，一直忙，但是产出不高</li>
<li>不重视团队成员交流</li>
</ol>
<h3 id="业务管理方面"><a href="#业务管理方面" class="headerlink" title="业务管理方面"></a>业务管理方面</h3><ol>
<li>业务目标拆分的很细，或者业务目标拆分的很粗</li>
<li>不能定义明确的验收标准</li>
<li>合理的工作绩效评估</li>
</ol>
<h3 id="团队管理"><a href="#团队管理" class="headerlink" title="团队管理"></a>团队管理</h3><ol>
<li>团队成员主动性不足，自我驱动能力差</li>
<li>绩效差的员工工作更加懈怠</li>
<li>没有技术分享的氛围</li>
</ol>
<h2 id="实践目标"><a href="#实践目标" class="headerlink" title="实践目标"></a>实践目标</h2><h3 id="自我认知-1"><a href="#自我认知-1" class="headerlink" title="自我认知"></a>自我认知</h3><p>通过培训以及阅读相关的管理书籍，对以上的管理问题有了比较深的理解，对理论的理解可以作为实践目标。兼顾管理与业务，管理不能脱离业务，找到管理与业务的平衡点，因人而异，定期Check，掌握系统的项目管理理论、团队管理理论，并能付诸实践，将与组内成员的交流作为组长必备工作。</p>
<h3 id="业务管理"><a href="#业务管理" class="headerlink" title="业务管理"></a>业务管理</h3><p>使用OKR和SMART原则制定目标，使用业务需求跟踪矩阵跟踪工作结果，采用360度绩效考核方法</p>
<h3 id="团队管理-1"><a href="#团队管理-1" class="headerlink" title="团队管理"></a>团队管理</h3><p>把羊群变成有战斗力的狼群，表现好的由于受到重视会加倍努力，表现的越来越好；原本不被看重的员工则越来越差，最后悄然离职，鼓励团队成员积极探索，乐于分享与承担的工作氛围，不断学习，追求进步</p>
<h2 id="领导力风格建设"><a href="#领导力风格建设" class="headerlink" title="领导力风格建设"></a>领导力风格建设</h2><p>团队肯定是需要一个组长或者说领导，那领导需要具有一定的能力能够影响或者驱动团队成员高质量的完成工作，肯定是具有强大的业务能力这个硬技能，作为一线的班组长，只有具备扎实的业务技能，才能首先在团队中建立一定的影响力。但是每个团队的可能存在不同方向的事情，组长需要掌握一定的软技能才能驱动团队高质量完成目标，例如沟通能力、项目管理能力、压力管理。这方面的提高目前需要通过参加多种相关培训，阅读项目管理与团队管理的书籍。这里面会有很多案例来指导项目管理中遇到的问题。俗话说，书读历史才能掌握未来，这个用到项目管理里面应该是类似的道理<br><img src="/2021/01/15/%E5%9B%A2%E9%98%9F%E7%AE%A1%E7%90%86/%E9%A2%86%E5%AF%BC%E5%8A%9B.png" alt="avatar"></p>
<h2 id="业务目标分解与跟踪"><a href="#业务目标分解与跟踪" class="headerlink" title="业务目标分解与跟踪"></a>业务目标分解与跟踪</h2><p>团队肯定是要承担业务相关的工作，这里就需要进行业务目标的拆解，根据团队成员的差异化能力，制定差异化的细化目标，目标管理是整个团队中最重要的事情之一。作为管理者应该愿意花时间和组内成员一起讨论、制定目标。在目标分解过程中，给与帮助和知道，及时对焦纠偏，确保目标达成。这样既是对自己负责，也是对团队成员负责。常用的方式包括OKR原则和SMART原则。所谓SMART原则，即：目标必须是具体的（Specific）,目标必须是可以衡量的（Measurable）,目标必须是可以达到的（Attainable）,目标必须和其他目标具有相关性（Relevant）,目标必须具有明确的截止期限（Time-based）,在团队里推行日总结、站立会，定时同步进度，遇到风险的能够及时反馈，作为团队组长也需要主动识别到风险，并对目标做响应的调整<br><img src="/2021/01/15/%E5%9B%A2%E9%98%9F%E7%AE%A1%E7%90%86/smart.png" alt="avatar"></p>
<h2 id="360度绩效评价"><a href="#360度绩效评价" class="headerlink" title="360度绩效评价"></a>360度绩效评价</h2><p>业绩评价是运用数理统计和运筹学的方法，通过建立综合评价指标体系，对照相应的评价标准，定量分析与定性分析相结合。360度绩效评估，又称“360度绩效反馈”或“全方位评估”，最早由被誉为“美国力量象征”的典范企业英特尔首先提出并加以实施的。从多个方面对员工绩效进行评价，以理论为指导，结合团队实际情况进行评价，公平/公正/责任/尊重。</p>
<p><img src="/2021/01/15/%E5%9B%A2%E9%98%9F%E7%AE%A1%E7%90%86/360.png" alt="avatar"></p>
<h2 id="有效沟通"><a href="#有效沟通" class="headerlink" title="有效沟通"></a>有效沟通</h2><p>因人而异进行沟通</p>
<p><img src="/2021/01/15/%E5%9B%A2%E9%98%9F%E7%AE%A1%E7%90%86/goutong.png" alt="avatar"></p>
]]></content>
  </entry>
  <entry>
    <title>基于操作系统制作一个docker镜像</title>
    <url>/2021/01/14/%E5%9F%BA%E4%BA%8E%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%88%B6%E4%BD%9C%E4%B8%80%E4%B8%AADocker%E9%95%9C%E5%83%8F/</url>
    <content><![CDATA[<p>整理了一下如何将Linux 操作系统 转换为docker镜像，这里可以适用于x86\arm\mpis等架构下，命令行操作如下所示</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar --numeric-owner --exclude&#x3D;&#x2F;proc --exclude&#x3D;&#x2F;sys  -cvf &#x2F;home&#x2F;linux-base.tar &#x2F;</span><br></pre></td></tr></table></figure>
<p>其中</p>
<ol>
<li>–numeric-owner 以UID和GID代替用户名和组名</li>
<li>–exclude=/proc –exclude=/sys  在新的docker镜像不包括上述目录</li>
<li>-cvf 压缩命令</li>
<li>/home/linux-base.tar 目标文件</li>
<li>/ 代表根下开始</li>
</ol>
<p>将生成的压缩文件导入到docker，执行以下命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$cat .&#x2F;linux-base.tar |docker import - linux-base</span><br><span class="line"></span><br><span class="line">$docker images</span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">linux-base        latest              d3455babc696e        1 minutes ago      1.67GB</span><br></pre></td></tr></table></figure>
<p>测试</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ docker run linux-base:latest echo cat &#x2F;etc&#x2F;redhat-release</span><br><span class="line">cat &#x2F;etc&#x2F;redhat-release</span><br></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title>多种硬盘接口详解</title>
    <url>/2021/01/12/%E5%A4%9A%E7%A7%8D%E7%A1%AC%E7%9B%98%E6%8E%A5%E5%8F%A3%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<p><a href="https://blog.csdn.net/shuai0845/article/details/98330290" target="_blank" rel="noopener">https://blog.csdn.net/shuai0845/article/details/98330290</a></p>
<h1 id="固态硬盘"><a href="#固态硬盘" class="headerlink" title="固态硬盘"></a>固态硬盘</h1><p>固态驱动器（Solid State Drive），俗称固态硬盘，固态硬盘是用固态电子存储芯片阵列而制成的硬盘，因为台湾英语里把固体电容称之为Solid而得名。SSD由控制单元和存储单元（FLASH芯片、DRAM芯片）组成。固态硬盘在接口的规范和定义、功能及使用方法上与普通硬盘的完全相同，在产品外形和尺寸上也完全与普通硬盘一致。被广泛应用于军事、车载、工控、视频监控、网络监控、网络终端、电力、医疗、航空、导航设备等诸多领域。</p>
<h2 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h2>]]></content>
  </entry>
  <entry>
    <title>epoll的基本概念和C10K问题</title>
    <url>/2021/01/07/epoll%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8CC10K%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h2 id="问题由来"><a href="#问题由来" class="headerlink" title="问题由来"></a>问题由来</h2><p>网络服务在处理数以万计的客户端连接时，往往出现效率低下甚至完全瘫痪，这被称为C10K问题。随着互联网的迅速发展，越来越多的网络服务开始面临C10K问题，作为大型网站的开发人员有必要对C10K问题有一定的了解。(本文的主要参考文献是 <a href="http://www.kegel.com/c10k.htmls%E3%80%82" target="_blank" rel="noopener">http://www.kegel.com/c10k.htmls。</a>) C10K问题的最大特点是：设计不够良好的程序，其性能和连接数与机器性能的关系往往是非线性的。举个例子：如果没有考虑过C10K问题，一个经典的基于select的程序能在旧服务器上很好处理1000并发的吞吐量，它在2倍性能新服务器上往往处理不了并发2000的吞吐量。这是因为在策略不当时，大量操作的消耗和当前连接数n成线性相关。会导致单个任务的资源消耗和当前连接数的关系会是O(n)。而服务程序需要同时对数以万计的socket进行I/O处理，积累下来的资源消耗会相当可观，这显然会导致系统吞吐量不能和机器性能匹配。为解决这个问题，必须改变对连接提供服务的策略。</p>
<h2 id="基本策略："><a href="#基本策略：" class="headerlink" title="基本策略："></a>基本策略：</h2><p>主要有两方面的策略：</p>
<p>1.应用软件以何种方式和操作系统合作，获取I/O事件并调度多个socket上的I/O操作；</p>
<p>2.应用软件以何种方式处理任务和线程/进程的关系。前者主要有阻塞I/O、非阻塞I/O、异步I/O这3种方案，后者主要有每任务1进程、每任务1线程、单线程、多任务共享线程池以及一些更复杂的变种方案。常用的经典策略如下：</p>
<ol>
<li><p>Serve one client with each thread/process, and use blocking I/O这是小程序和java常用的策略，对于交互式的长连接应用也是常见的选择(比如BBS)。这种策略很能难足高性能程序的需求，好处是实现极其简单， 容易嵌入复杂的交互逻辑。Apache、ftpd等都是这种工作模式。</p>
</li>
<li><p>Serve many clients with single thread, and use nonblocking I/O and readiness notification 这是经典模型，datapipe等程序都是如此实现的。优点在于实现较简单，方便移植，也能提供足够的性能；缺点在于无法充分利用多CPU的机器。尤其是程序本身没有复杂的业务逻辑时。</p>
</li>
<li><p>Serve many clients with each thread, and use nonblocking I/O and readiness notification 对经典模型2的简单改进，缺点是容易在多线程并发上出bug，甚至某些OS不支持多线程操作readiness notification。</p>
</li>
<li><p>Serve many clients with each thread, and use asynchronous I/O 在有AI/O支持的OS上，能提供相当高的性能。不过AI/O编程模型和经典模型差别相当大，基本上很难写出一个框架同时支持AI/O和经典模型，降低了程序的可移植性。在Windows上，这基本上是唯一的可选方案。<br>本文主要讨论模型2的细节，也就是在模型2下应用软件如何处理Socket I/O。</p>
<p><a href="https://blog.csdn.net/shenya1314/article/details/73691088" target="_blank" rel="noopener">https://blog.csdn.net/shenya1314/article/details/73691088</a></p>
</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>云原生主要技术</title>
    <url>/2020/12/07/%E4%BA%91%E5%8E%9F%E7%94%9F%E4%B8%BB%E8%A6%81%E6%8A%80%E6%9C%AF/</url>
    <content><![CDATA[<p>上一篇文章介绍了云计算和云原生，这里讲一下云原生的主要技术，主要包括容器、微服务、DevOps、ServiceMesh、ServerLess、声明式API，当然我这里并不会将具体的技术，主要还是概念相关的东西了。先上一个CNCF 生态的技术栈，前几年看的时候，没有几个，今天一看，真多啊</p>
<p><img src="/2020/12/07/%E4%BA%91%E5%8E%9F%E7%94%9F%E4%B8%BB%E8%A6%81%E6%8A%80%E6%9C%AF/cncf.png" alt="avatar"></p>
<h2 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h2><p>还是先上一张PPT的截图吧，简单明了。</p>
<p><img src="/2020/12/07/%E4%BA%91%E5%8E%9F%E7%94%9F%E4%B8%BB%E8%A6%81%E6%8A%80%E6%9C%AF/docker1.png" alt="avatar"></p>
<p>1、容器作为应用的集装箱，封装应用的依赖，简化应用的部署，集装箱的这个类比，戳中了众多应用开发者的痛点，在没有使用容器之前，部署一个应用+升级一个应用是非常复杂，而且也是非常容易出现问题的地方。</p>
<p>2、容器的隔离特性，将虚拟化的隔离特性带给应用开发者，当然这里并没有多少新的技术，还是靠Linux底层的Cgroup、Namespace、Quota等等，对这些做了封装。刚看到这个类比：我们无论什么样的开发，其实都是对接口的封装，例如我们做IAAS、PAAS平台是对vmware、Kubernetes的接口的二次开发，我们比较陌生的docker，其实是对linux接口的开发，Linux其实是对底层软硬件驱动的接口开发。。。</p>
<p>3、轻量级虚拟化，如果现在最火的docker 不是轻量级，估计也会沦为CloudFoundry 中DEA+warden的下场</p>
<p>基于比较易用的镜像能力，docker以“Build Once,Run Anywhere” 的宣传口语，一统容器江湖.<br><img src="/2020/12/07/%E4%BA%91%E5%8E%9F%E7%94%9F%E4%B8%BB%E8%A6%81%E6%8A%80%E6%9C%AF/docker.png" alt="avatar"></p>
<p>这里想说点别的,我们一直在用比喻去讲解docker 和容器,但是，大家应该比较清楚，比喻在让你利杰这个事务的时候，也让你停止了思考，其实比喻更适合对门外汉讲，我们技术人员看到的应该是这样的docker或者更详细点。</p>
<p><img src="/2020/12/07/%E4%BA%91%E5%8E%9F%E7%94%9F%E4%B8%BB%E8%A6%81%E6%8A%80%E6%9C%AF/docker2.png" alt="avatar"></p>
<h2 id="容器编排"><a href="#容器编排" class="headerlink" title="容器编排"></a>容器编排</h2><p>按照云原生应用的十二要素原则，其实一个容器只能用于运行一个进程，那么对于分布式应用来说，必然需要一套编排管理工具，也就是用于容器的编排管理和运维，例如Kubernetes、Swarm、Mesos等，大部分还都是使用Kubernetes，由Google背书，并且具有丰富的网络、存储、计算扩展机制（好像容易扩展的开源项目才能活，例如IAAS领域的OpenStack），就下下图描述的宠物与家畜，电话接线员一样，Kubernetes 解决了容器管理/应用管理的问题，开发者把应用丢到K8s集群，然后访问应用即可。</p>
<p><img src="/2020/12/07/%E4%BA%91%E5%8E%9F%E7%94%9F%E4%B8%BB%E8%A6%81%E6%8A%80%E6%9C%AF/k8s1.png" alt="avatar"></p>
<p>管理：Kubernetes的目标是让你可以像管理牲畜一样管理你的服务，而不是像宠物一样</p>
<p>编排：丰富的编排策略，用户只需要创建应用与访问应用，对于应用相关的网络、存储、数据等都不需要用户管理</p>
<h2 id="微服务"><a href="#微服务" class="headerlink" title="微服务"></a>微服务</h2><p>微服务改造意味着先选择一套大型的应用程序，然后识别出限界上下文（bounded contexts）及其内部的业务功能，并对它们进行分割，重要的是要将数据一起进行分割，也就<br>是说要采用应用数据库而非集成数据库。为了理解业务领域的内容，关键的一点就是要在一开始就采用上下文图（context map ）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">微服务 (Microservices) 是一种软件架构风格，它是以专注于单一责任与功能的小型功能区块 (Small Building Blocks) 为基础，利用模块化的方式组合出复杂的大型应用程序，各功能区块使用与语言无关 (Language-Independent&#x2F;Language agnostic) 的 API 集相互通信---维基百科</span><br></pre></td></tr></table></figure>
<p><big>微服务架构带来的优势</big>：<br>1、各服务开发语言无关性<br>2、各服务编译构建部署无关性<br>3、服务复用（在传统厂商，这个很难，大部分的微服务还都是定制开发的）</p>
<p>微服务架构的两个问题:</p>
<ul>
<li>服务发现：在众多的微服务组件中，服务使用者如何找到准确的微服务组件  </li>
<li>负载均衡：多实例微服务，如果实现负载均衡</li>
</ul>
<p>微服务带来的比较头大的问题，如下图，这也是云原生的下一个技术 ServiceMesh逐渐普及的原因,总结来说就是，微服务是以提高运维复杂度的代价，来提高敏捷性。是好是坏还真不好说，对于开发人员来说 有好处有坏处，好处就是开发方便，选择自己喜欢的框架和开发语言，坏处就是各个微服务交互的时候就有些问题，需要考虑的点比较多。对于运维人员来说，感觉全是坏处，原来只需要运维一个tomcat，现在需要运维N个tomcat。。。</p>
<p><img src="/2020/12/07/%E4%BA%91%E5%8E%9F%E7%94%9F%E4%B8%BB%E8%A6%81%E6%8A%80%E6%9C%AF/weifuwu.png" alt="avatar"></p>
<h2 id="Service-Mesh"><a href="#Service-Mesh" class="headerlink" title="Service Mesh"></a>Service Mesh</h2><p>Service Mesh 服务网格是一个基础设施层，用于处理服务间通信。云原生应用有着复杂的服务拓扑，服务网格保证请求在这些拓扑中可靠地穿梭。在实际应用当中，服务网格通常是由一系列轻量级的网络代理组成的，它们与应用程序部署在一起，但对应用程序透明。</p>
<p>对ServiceMesh描述最好的，应该是面向容器的SideCar设计模式，这个SideCar的设计模式在ServiceMesh 还没有普及起来的时候就有人提出来了，可以看下图，通常我们第一印象就是感觉多了这个sidecar 是不是运维复杂，浪费资源等等，不过细考虑容器化的思想，其实多出来的这个sidecar只是一个进程而已。</p>
<p><img src="/2020/12/07/%E4%BA%91%E5%8E%9F%E7%94%9F%E4%B8%BB%E8%A6%81%E6%8A%80%E6%9C%AF/sidecar.png" alt="avatar"></p>
<p>这里安利一下<a href="https://istio.io/" target="_blank" rel="noopener">istio</a>，Istio是语言无关的服务治理框架，对ServiceMesh的架构、功能和API进行了标准化，与Kubernetes紧密结合</p>
<ol>
<li>数据平面，主要是智能代理（Enovy），即sidecar ，用于管理微服务之间的网络流入和流出，在创建微服务时，由istio自动注入该sidecar</li>
<li>控制平面：将用户配置的路由规则，推送到sidecar，安全相关控制<ul>
<li>主要功能 </li>
<li>动态服务发现</li>
<li>负载均衡</li>
<li>熔断</li>
<li>健康检查</li>
<li>容错、监控指标</li>
<li>灰度发布/流量控制</li>
</ul>
</li>
<li>流程：<ul>
<li>创建应用时自动注入sidecar</li>
<li>流量拦截，pod初始化时，将业务容器的流量拦截到sidecar，sidecar将流量转到业务容器</li>
<li>服务发现，sidecar查询istiod服务，获取服务实例列表</li>
<li>负责均衡：sidecar根据负载均衡策略，选择服务实例</li>
<li>流量治理：sidecar查询istiod服务，获取流量控制规则，在拦截的流量中执行流量控制</li>
<li>访问安全：sidecar进行双向认证和通道加密</li>
<li>服务监控：sidecar连接管理平面，将监控指标、日志、调用链发送istiod</li>
</ul>
</li>
</ol>
<h2 id="DevOps"><a href="#DevOps" class="headerlink" title="DevOps"></a>DevOps</h2>]]></content>
      <tags>
        <tag>云计算</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统安装流程</title>
    <url>/2021/01/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E6%B5%81%E7%A8%8B/</url>
    <content><![CDATA[<p>几个主要的流程</p>
<ol>
<li>通用流程：首先，bios启动，选择操作系统的启动（安装）模式（此时，内存是空白的），然后根据相关的安装模式，寻找操作系统的引导程序（不同的模式，对应不同的引导程序当然也对应着不同的引导程序存在的位置），引导程序加载文件系统初始化（initrd）程序和内核初始镜像（vmlinuz），完成操作系统安装前的初始化；接着，操作系统开始安装相关的系统和应用程序。</li>
<li>硬盘安装的流程：bios启动——MBR寻找grub——grub程序读取menu.list等配置文件，找到内核启动镜像和相关初始化程序，安装（或者启动）。</li>
<li>PXE(Pre-boot Execution Environment)是由Intel设计，可以使计算机通过网络启动的协议。协议分为client和server两端，PXE client在网卡的ROM中，当计算机启动时，BIOS把PXE client调入内存执行，并显示出命令菜单，经用户选择后，PXE<br>client将放置在远端的操作系统通过网络下载到本地运行。</li>
<li>pxe网络安装的流程：bios启动——pxe client中的程序进入内存，显示命令菜单——此程序开始寻找网络引导程序（bootstrap文件，这个文件的名字随着发行版的不同而不同，在centos中，它是pxelinux.0）——引导程序读取配置文件pxelinux.cfg，<br>获得系统初始化的相关文件信息——系统启动，开始进行安装。</li>
</ol>
<p><a href="https://www.cnblogs.com/struggle-1216/p/11764647.html" target="_blank" rel="noopener">https://www.cnblogs.com/struggle-1216/p/11764647.html</a></p>
]]></content>
  </entry>
  <entry>
    <title>kubernetes 新版调度器框架</title>
    <url>/2021/01/19/kubernetes-%E6%96%B0%E7%89%88%E8%B0%83%E5%BA%A6%E5%99%A8%E6%A1%86%E6%9E%B6/</url>
    <content><![CDATA[<h2 id="新版本调度器框架用来解决的问题"><a href="#新版本调度器框架用来解决的问题" class="headerlink" title="新版本调度器框架用来解决的问题"></a>新版本调度器框架用来解决的问题</h2><ol>
<li>当前版本的调度器，越来越多的特性被加入到调度器，让调度器的代码越来越多，逻辑越来越复杂，不容易维护，不容易发现问题</li>
<li>当前版本的调度器extender机制扩展点有限，对于”Filter”类型的扩展，只能在默认的预选函数之后执行，”Preempt”类型的扩展只能在默认的抢占函数之后调用，只能有一个Binding 的扩展，而且这个Bind 扩展会代替默认的扩展功能，extender扩展机制不能在任意点调用，例如无法在默认的 预选函数之前进行调用</li>
<li>每次调用Extender时，都需要对json数据进行解析，调用http 服务的速度慢与直接本地的api调用</li>
<li>没有默认调度器与extender的交互机制，例如当extender 扩展出现异常时，无法通知默认的调度器</li>
<li>extender的调度器是以一个单独的进程运行，不能共享默认调度器的cache，需要extender 构建自己的cache<h2 id="新版本调度器框架机制"><a href="#新版本调度器框架机制" class="headerlink" title="新版本调度器框架机制"></a>新版本调度器框架机制</h2>在调度一个Pod时，分为调度部分和绑定部分，其中调度部分用于为Pod选择一个节点，绑定部分将调度部分的决策作用于集群，一个调度Cycle和一个绑定Cycle 被称为一个调度上下文，其中多个调度Cycle是串行运行，绑定Cycle 是并行运行，对于一个Pod，当出现内部错误时或者该Pod无法被调度时，调度Cycle 和绑定Cycle就会终止，这个Pod 被重新放到调度队列</li>
</ol>
<p>插件扩展点：</p>
<p><img src="/2021/01/19/kubernetes-%E6%96%B0%E7%89%88%E8%B0%83%E5%BA%A6%E5%99%A8%E6%A1%86%E6%9E%B6/1.png" alt="avatar"></p>
<ol>
<li><p>Queue Sort</p>
<p>在这个插件点的插件 用于对调度队列中的Pod进行排序</p>
</li>
<li><p>PreFilter</p>
<p>在这个插件点的插件，用于对Pod进行预处理、检查集群、Pod，当该插件出现错误是，该调度会结束，PreFilter在调度周期内只会调用一次</p>
</li>
<li><p>Filter</p>
<p> 过滤出不能运行Pod的节点，对于每一个Node，调度器都会按照顺序调用filter插件，都某个一个Filter插件判断Node不符合要求时，不会再对该节点调用其他插件。多个Node会并行进行评估，在一个调度周期内，Filter可能会被调用多次</p>
</li>
<li><p>PostFilter</p>
<p> 在Filter插件点后进行调用，只有当没有为Pod找到Node时，才会调用该PostFilter节点的插件，当其中一个PostFilter节点为Pod找到了一个节点，其他的PostFilter插件不会再调用</p>
</li>
<li><p>PreScore</p>
<p>用于更新内部状态、产生日志、监控信息等</p>
</li>
<li><p>Scoring</p>
<p>和原调度器的打分机制相同，包含打分和归一化两部分</p>
</li>
<li><p>Reserve</p>
<p>包含Reserve和Unreserve两部分，用于通知为Pod在Node上预留节点或者不为Pod预留资源，该阶段会在Bind之前进行调用，这个地方在做gang scheduling 的时候比较有用</p>
</li>
<li><p>Permit</p>
<p> 用于限制或者推迟Pod的绑定，有三种结果，Approve：当所有的Permit 插件都是Approve时，这个Pod将会被Bind。 Deny：如果任意一个Permit插件Deny，则这个Pod就会重新被放入到调度队列。Wait：如果一个Permit插件提示Wait，则需要在timeout时间内等待其他的Permit插件提示Approve，如果timeout时间内没有等到Approve，则该Pod会被重新放入到调度队列</p>
</li>
<li><p>PreBind</p>
<p>做一些Pod bind之前的准备工作，例如创建网络存储的卷，将卷挂载到主机，如果任意一个PreBind 插件报错，该Pod就会重新被放到调度队列中，重新进行调度</p>
</li>
<li><p>Bind</p>
<p>将Pod 绑定到Node，可能会存在多个Bind plugin，不同的Bind Plugin 可能会选择不同的Pod进行Bind</p>
</li>
<li><p>PostBind</p>
<p>这里主要用于信息扩展，当一个Pod被成功Bind到一个节点时，意味着一个调度周期结束，可以用于清理一些相关的资源</p>
</li>
</ol>
<h2 id="插件生命周期"><a href="#插件生命周期" class="headerlink" title="插件生命周期"></a>插件生命周期</h2><ol>
<li>初始化<br>需要两步完成插件的初始化，首先，插件需要被注册，其次调度器会根据配置选择初始化的插件，如果一个插件在多个扩展点注册，该插件只会被初始化一次</li>
</ol>
<ol start="2">
<li><p>并发</p>
<p>在编写插件时，需要考虑两种类型的插件并发，当在并发评估每个节点时，一个插件可能会被调用多次，在多个调度的上下文，一个插件也可能能被并发调用，但是在一个调度的上下文内，插件是被顺序调用。</p>
<p>如下图所示，调度器的Main thread。一次只处理一个调度周期，任意的在Permit扩展点之上的扩展点，包括Permit扩展点，会在下一个调度周期开始之前全部结束，Permit 之后，Bind Thread会并发执行，并发执行，就是扩展插件可能会被两个不同的上下文执行，其中Reserver插件的Unreserve函数可能会在main thread或者 bind thread中被调用</p>
</li>
</ol>
<p><img src="/2021/01/19/kubernetes-%E6%96%B0%E7%89%88%E8%B0%83%E5%BA%A6%E5%99%A8%E6%A1%86%E6%9E%B6/2.png" alt="avatar"></p>
<h2 id="使用方式"><a href="#使用方式" class="headerlink" title="使用方式"></a>使用方式</h2><ol>
<li>定义插件的对象和构造函数</li>
</ol>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// QoSSort is a plugin that implements QoS class based sorting.</span></span><br><span class="line"><span class="keyword">type</span> Sort <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line"><span class="comment">// New initializes a new plugin and returns it.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">(_ *runtime.Unknown, _ framework.FrameworkHandle)</span> <span class="params">(framework.Plugin, error)</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> &amp;Sort&#123;&#125;, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>根据插件对应的插件点，实现对应的接口函数</li>
</ol>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// QueueSortPlugin is an interface that must be implemented by "QueueSort" plugins.</span></span><br><span class="line"><span class="comment">// These plugins are used to sort pods in the scheduling queue. Only one queue sort</span></span><br><span class="line"><span class="comment">// plugin may be enabled at a time.</span></span><br><span class="line"><span class="keyword">type</span> QueueSortPlugin <span class="keyword">interface</span> &#123;</span><br><span class="line">    Plugin</span><br><span class="line">    <span class="comment">// Less are used to sort pods in the scheduling queue.</span></span><br><span class="line">    Less(*PodInfo, *PodInfo) <span class="keyword">bool</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>插件注册</li>
</ol>
<p>在调度器的启动的main 函数添加自定义的调度插件</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// cmd/main.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    rand.Seed(time.Now().UnixNano())</span><br><span class="line">    command := app.NewSchedulerCommand(</span><br><span class="line">        app.WithPlugin(qos.Name, qos.New),</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">if</span> err := command.Execute(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">        os.Exit(<span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>编译启动</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ bin&#x2F;kube-scheduler --kubeconfig&#x3D;scheduler.conf --config&#x3D;.&#x2F;manifests&#x2F;qos&#x2F;scheduler-config.yaml</span><br></pre></td></tr></table></figure>

<h2 id="Use-Case"><a href="#Use-Case" class="headerlink" title="Use Case"></a>Use Case</h2><h3 id="Coscheduling-批调度"><a href="#Coscheduling-批调度" class="headerlink" title="Coscheduling 批调度"></a>Coscheduling 批调度</h3><p>Coscheduling 和之前理解的gang scheduling 有些区别，引用<a href="https://blog.csdn.net/yunqiinsight/article/details/107350005" target="_blank" rel="noopener">这里</a>的一些描述</p>
<blockquote>
<p>Wikipedia对 Coscheduling的定义是“在并发系统中将多个相关联的进程调度到不同处理器上同时运行的策略”。在Coscheduling的场景中，最主要的原则是保证所有相关联的进程能够同时启动。防止部分进程的异常，导致整个关联进程组的阻塞。这种导致阻塞的部分异常进程，称之为“碎片（fragement）”。<br>在Coscheduling的具体实现过程中，根据是否允许“碎片”存在，可以细分为Explicit Coscheduling，Local Coscheduling和Implicit Coscheduling。 其中Explicit Coscheduling就是大家常听到的Gang Scheduling。Gang Scheduling要求完全不允许有“碎片”存在， 也就是“All or Nothing”。维基百科的具体解释</p>
</blockquote>
<blockquote>
<p>Explicit coscheduling requires all processing to actually take place at the same time, and is typically implemented by global scheduling across all processors. A specific algorithm is known as gang scheduling.<br>Local coscheduling allows individual processors to schedule the processing independently.<br>Dynamic (or implicit) coscheduling is a form of coscheduling where individual processors can still schedule processing independently, but they make scheduling decisions in cooperation with other processors.</p>
</blockquote>
<blockquote>
<p>我们将上述定义的概念对应到Kubernetes中，就可以理解Kubernetes调度系统支持批任务Coscheduling的含义了。 一个批任务（关联进程组）包括了N个Pod（进程），Kubernetes调度器负责将这N个Pod调度到M个节点（处理器）上同时运行。如果这个批任务需要部分Pod同时启动即可运行，我们称需启动Pod的最小数量为min-available。特别地，当min-available=N时，批任务要求满足Gang Scheduling。</p>
</blockquote>
<p>这里基于Kubernetes新版本的调度框架开发的Coscheduling 借鉴了kube-batch调度器的思想，也有PodGroup的概念，只是把kube-batch的一些功能拆为了多个调度器插件<br><a href="https://github.com/kubernetes-sigs/scheduler-plugins/tree/master/pkg/coscheduling" target="_blank" rel="noopener">项目地址</a></p>
<p><img src="/2021/01/19/kubernetes-%E6%96%B0%E7%89%88%E8%B0%83%E5%BA%A6%E5%99%A8%E6%A1%86%E6%9E%B6/3.png" alt="avatar"></p>
<p>用到的几个插件扩展点</p>
<p>QueueSort插件：这里主要是将调度队列中 属于同一Podgroup到的Pod 放在一起，并安装PodGroup的创建时间/优先级，对Pod进行排序，来决定Pod进入调度队列的先后顺序。</p>
<p>Prefilter插件：判断该PodGroup中的已经运行的Pod是否已经满足最小的Pod 运行数量，如果已经满足，则不再对该PodGroup中Pennding的Pod进行调度</p>
<p>Permit插件：该插件主要是延迟绑定，即Pod进入到Permit阶段时，用户可以自定义条件来允许Pod通过、拒绝Pod通过以及让Pod等待状态(可设置超时时间)。Permit的延迟绑定的功能，刚好可以让属于同一个PodGruop的Pod调度到这个节点时，进行等待，等待积累的Pod数目满足足够的数目时，再统一运行同一个PodGruop的所有Pod进行绑定并创建。</p>
<p>UnReserve插件：当某个Pod Permit 的时间超时，则会进入UnReserve阶段，则会将该Pod所在的PodGroup中所有的Pod都UnReserve，重新进入Pennding队列</p>
<h3 id="Dynamic-Resource-Binding"><a href="#Dynamic-Resource-Binding" class="headerlink" title="Dynamic Resource Binding"></a>Dynamic Resource Binding</h3><p>NA</p>
<h3 id="Custom-Scheduler-Plugins"><a href="#Custom-Scheduler-Plugins" class="headerlink" title="Custom Scheduler Plugins"></a>Custom Scheduler Plugins</h3><p>编写自定义调度插件时，不需要fork k8s 原生的调度代码，只需要要引入这些代码就可以，如下所示</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    scheduler <span class="string">"k8s.io/kubernetes/cmd/kube-scheduler/app"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    command := scheduler.NewSchedulerCommand(</span><br><span class="line">            scheduler.WithPlugin(<span class="string">"example-plugin1"</span>, ExamplePlugin1),</span><br><span class="line">            scheduler.WithPlugin(<span class="string">"example-plugin2"</span>, ExamplePlugin2))</span><br><span class="line">    <span class="keyword">if</span> err := command.Execute(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">        fmt.Fprintf(os.Stderr, <span class="string">"%v\n"</span>, err)</span><br><span class="line">        os.Exit(<span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title>gpu 热挂载项目分析</title>
    <url>/2021/01/18/gpu-%E7%83%AD%E6%8C%82%E8%BD%BD%E9%A1%B9%E7%9B%AE%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<p>测试场景 NVIDIA-Driver 418.67<br>nvidia-docker 版本</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root~]# rpm -qa|grep nvidia</span><br><span class="line">nvidia_peer_memory-1.0-8.x86_64</span><br><span class="line">libnvidia-container1-1.3.1-1.x86_64</span><br><span class="line">nvidia-docker2-2.5.0-1.noarch</span><br><span class="line">libnvidia-container-tools-1.3.1-1.x86_64</span><br><span class="line">nvidia-container-runtime-3.4.0-1.x86_64</span><br><span class="line">nvidia-container-toolkit-1.4.0-2.x86_64</span><br></pre></td></tr></table></figure>
<h2 id="Linux-设备的major-和minor-number"><a href="#Linux-设备的major-和minor-number" class="headerlink" title="Linux 设备的major 和minor number"></a>Linux 设备的major 和minor number</h2><p>Linux 系统的/dev 目录下面的设备文件是用来描述外设的，如/dev/sda1表示第一块硬盘的第一个分区，但是这个/dev/sda1紧紧是方便用户观察，Linux内核中表示不同的设备是通过major和minor number 实现，对多major和minor number 来加载相应的驱动程序。其中<br>major number：表示不同的设备类型</p>
<p>minor number ：表示同一个设备的不同分区</p>
<p>主设备号标识设备对应的驱动程序（或者多个相关的驱动程序共用相同的一个主设备号），次设备号表示驱动程序驱动的一个设备。</p>
<p>例如Linux系统中的sda磁盘和sdb 磁盘major number 都是8，但是sda的minor number 是从0 开始，sdb的minor number 是16开始<br>使用以下命令查看major number 和minor number</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@node devices]# ls -l /dev/sda1</span><br><span class="line">brw-rw---- 1 root disk 8, 1 1月  29 16:55 /dev/sda1</span><br></pre></td></tr></table></figure>
<p>上述命令中，brw的b表示块设备(block),主设备号是8,次设备号是1。也就是8,1表示major,minor。也可以stat –format=%t:%T显示</p>
<p>查看GPU的信息major和minor 信息</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@node ~]# ls -l /dev/nvidia0 </span><br><span class="line">crw-rw-rw- 1 root root 195, 0 Jan 18 16:48 /dev/nvidia0</span><br><span class="line">[root@node ~]# ls -l /dev/nvidia1</span><br><span class="line">crw-rw-rw- 1 root root 195, 1 Jan 18 16:48 /dev/nvidia1</span><br></pre></td></tr></table></figure>
<p>也可以通过代码获取major number 和minor numer ，这里找到一段代码用于获取</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getDiskMajorMinor</span><span class="params">(path <span class="keyword">string</span>)</span> <span class="params">(major, minor <span class="keyword">int</span>, err error)</span></span> &#123;</span><br><span class="line">	stat := syscall.Stat_t&#123;&#125;</span><br><span class="line">	err = syscall.Stat(path, &amp;stat)</span><br><span class="line">	<span class="keyword">if</span> <span class="literal">nil</span> != err &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="number">0</span>, <span class="number">0</span>, err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">//refer to "dev_t new_decode_dev(u32 dev)" defined in the kernel header file linux/kdev.h</span></span><br><span class="line">	major = <span class="keyword">int</span>(((<span class="keyword">uint32</span>(stat.Dev)) &gt;&gt; <span class="number">8</span>) &amp; <span class="number">0xfff</span>)</span><br><span class="line">	minor = <span class="keyword">int</span>((stat.Dev &amp; <span class="number">0xff</span>) | ((stat.Dev &gt;&gt; <span class="number">12</span>) &amp; <span class="number">0xfff00</span>))</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> major, minor, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Linux-mknod-命令"><a href="#Linux-mknod-命令" class="headerlink" title="Linux mknod 命令"></a>Linux mknod 命令</h2><p>linux操作系统跟外部设备（如磁盘、光盘等）的通信都是通过设备文件进行的，应用程序可以打开、关闭、读写这些设备文件，从而对设备进行读写，这种操作就像读写普通的文件一样easy。linux为不同种类的设备文件提供了相同的接口，比如read(),write(),open(),close()。</p>
<p>在系统与设备通信之前，系统首先要建立一个设备文件，这个设备文件存放在/dev目录下。其实系统默认情况下就已经生成了很多设备文件，有时候需要自己手动新建一些设备文件，这个时候就会用到像mkdir, mknod这样的命令。</p>
<p>我们也可以自己mknod /dev/sda1_myref b 8 1来创建设备文件。设备文件可以看成是对linux内核设备对象的一个索引。所以主设备号和次设备号均相同的两个设备文件，对其中一个设备的修改，在另一个设备文件访问时也会看到修改的结果。</p>
<p> mknod 的标准形式为:       mknod DEVNAME {b | c}  MAJOR  MINOR</p>
<p>1，DEVNAME是要创建的设备文件名，如果想将设备文件放在一个特定的文件夹下，就需要先用mkdir在dev目录下新建一个目录；</p>
<p>2， b和c 分别表示块设备和字符设备：</p>
<pre><code>b表示系统从块设备中读取数据的时候，直接从内存的buffer中读取数据，而不经过磁盘；

c表示字符设备文件与设备传送数据的时候是以字符的形式传送，一次传送一个字符，比如打印机、终端都是以字符的形式传送数据；</code></pre>
<p>3，MAJOR和MINOR分别表示主设备号和次设备号：为了管理设备，系统为每个设备分配一个编号，一个设备号由主设备号和次设备号组成。主设备号标示某一种类的设备，次设备号用来区分同一类型的设备。linux操作系统中为设备文件编号分配了32位无符号整数，其中前12位是主设备号，后20位为次设备号，所以在向系统申请设备文件时主设备号不好超过4095，次设备号不好超过2^20 -1。</p>
<h2 id="cgroup-device子系统"><a href="#cgroup-device子系统" class="headerlink" title="cgroup device子系统"></a>cgroup device子系统</h2><p>使用devices 子系统可以允许或者拒绝cgroup中的进程访问设备。devices子系统有三个控制文件：devices.allow,devices.deny,devices.list。devices.allow用于指定cgroup中的进程可以访问的设备,devices.deny用于指定cgroup中的进程不能访问的设备，devices.list用于报告cgroup中的进程访问的设备。devices.allow文件中包含若干条目，每个条目有四个字段：type、major、minor 和 access。type、major 和 minor 字段中使用的值对应 Linux 分配的设备。</p>
<p>type指定设备类型：</p>
<pre><code>a - 应用所有设备，可以是字符设备，也可以是块设备

b- 指定块设备

c - 指定字符设备</code></pre>
<p>major和minor指定设备的主次设备号。</p>
<p>access 则指定相应的权限：</p>
<pre><code>r - 允许任务从指定设备中读取

w - 允许任务写入指定设备

m - 允许任务生成还不存在的设备文件</code></pre>
<p>具体可以参考<a href="https://www.cnblogs.com/lisperl/archive/2012/04/24/2468170.html" target="_blank" rel="noopener">这里</a></p>
<h2 id="pokerfaceSad-CVE-2021-1056-项目"><a href="#pokerfaceSad-CVE-2021-1056-项目" class="headerlink" title="pokerfaceSad/CVE-2021-1056 项目"></a>pokerfaceSad/CVE-2021-1056 项目</h2><p>这个项目主要是一个main.sh, 脚本里主要是查询GPU的major number，然后使用mknod 命令新增容器，如下所示</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@container1:&#x2F;ttt# nvidia-smi </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 450.80.02    Driver Version: 418.80.02    CUDA Version: 11.0     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage&#x2F;Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                               |                      |               MIG M. |</span><br><span class="line">|&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;|</span><br><span class="line">|   0  Tesla P100-PCIE...  Off  | 00000000:86:00.0 Off |                    0 |</span><br><span class="line">| N&#x2F;A   33C    P0    25W &#x2F; 250W |      0MiB &#x2F; 16280MiB |      0%      Default |</span><br><span class="line">|                               |                      |                  N&#x2F;A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">                                                                               </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                                  |</span><br><span class="line">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span><br><span class="line">|        ID   ID                                                   Usage      |</span><br><span class="line">|&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;|</span><br><span class="line">|  No running processes found                                                 |</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@container1:&#x2F;ttt# ll -l &#x2F;dev&#x2F;nvidia0</span><br><span class="line">crw-rw-rw- 1 root root 195, 0 Jan 18 08:48 &#x2F;dev&#x2F;nvidia0</span><br><span class="line"></span><br><span class="line">root@container1:&#x2F;ttt# mknod -m 666 &#x2F;dev&#x2F;nvidia1 c 195 0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@container1:&#x2F;ttt# nvidia-smi       </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage&#x2F;Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                               |                      |               MIG M. |</span><br><span class="line">|&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;|</span><br><span class="line">|   0  Tesla P100-PCIE...  Off  | 00000000:86:00.0 Off |                    0 |</span><br><span class="line">| N&#x2F;A   32C    P0    25W &#x2F; 250W |      0MiB &#x2F; 16280MiB |      0%      Default |</span><br><span class="line">|                               |                      |                  N&#x2F;A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">|   1  Tesla P100-PCIE...  Off  | 00000000:AF:00.0 Off |                    0 |</span><br><span class="line">| N&#x2F;A   28C    P0    25W &#x2F; 250W |      0MiB &#x2F; 16280MiB |      0%      Default |</span><br><span class="line">|                               |                      |                  N&#x2F;A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">                                                                               </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                                  |</span><br><span class="line">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span><br><span class="line">|        ID   ID                                                   Usage      |</span><br><span class="line">|&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;|</span><br><span class="line">|  No running processes found                                                 |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>


<h2 id="GPUmounter-项目"><a href="#GPUmounter-项目" class="headerlink" title="GPUmounter 项目"></a>GPUmounter 项目</h2><p>该项目主要设计了一个项目，用于Kubernetes 内的集群，用于增加删除容器内的GPU卡数，主要功能是在容器外部进行操作，将容器内的GPU卡数增加或者减少</p>
<p>容器外部控制容器内GPU卡 数量的方法如下所示：</p>
<p>获取Pod对应的容器的cgroup文件信息，例如容器ID为d80172f6ba5f9d4e82ce6f95c592f89dfa5f3ad637c9c38f7739c04b1f9c5d62<br>则该容器对应的cgroup 的device 目录如下所示：<br>执行命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd  &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;devices&#x2F;system.slice&#x2F;docker-d80172f6ba5f9d4e82ce6f95c592f89dfa5f3ad637c9c38f7739c04b1f9c5d62.scope</span><br><span class="line"></span><br><span class="line">echo c &quot;195:0 rw&quot; &gt;devices.allow</span><br></pre></td></tr></table></figure>
<p>从该目录的cgroup.procs 文件中获取容器对应的PID，该文件可能存在多个PId，获取该文件中第一个PID，如下所示为157136</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node1 docker-d80172f6ba5f9d4e82ce6f95c592f89dfa5f3ad637c9c38f7739c04b1f9c5d62.scope]# cat cgroup.procs </span><br><span class="line">157136</span><br><span class="line">157158</span><br><span class="line">157166</span><br><span class="line">157174</span><br></pre></td></tr></table></figure>

<p>进入容器命名空间执行命令</p>
<p> nsenter –target 157136 –mount<br> /bin/mknod -m  666   /dev/nvidia1  c 195 0</p>
<p>再次登录容器查看GPU信息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@28cam0e1oddj1-0:&#x2F;ttt# nvidia-smi   </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage&#x2F;Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                               |                      |               MIG M. |</span><br><span class="line">|&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;|</span><br><span class="line">|   0  Tesla P100-PCIE...  Off  | 00000000:86:00.0 Off |                    0 |</span><br><span class="line">| N&#x2F;A   33C    P0    26W &#x2F; 250W |      0MiB &#x2F; 16280MiB |      0%      Default |</span><br><span class="line">|                               |                      |                  N&#x2F;A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">|   1  Tesla P100-PCIE...  Off  | 00000000:AF:00.0 Off |                    0 |</span><br><span class="line">| N&#x2F;A   29C    P0    25W &#x2F; 250W |      0MiB &#x2F; 16280MiB |      0%      Default |</span><br><span class="line">|                               |                      |                  N&#x2F;A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">                                                                               </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                                  |</span><br><span class="line">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span><br><span class="line">|        ID   ID                                                   Usage      |</span><br><span class="line">|&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;|</span><br><span class="line">|  No running processes found                                                 |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>


<p>核心代码如下所示</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">MountGPU</span><span class="params">(pod *corev1.Pod, gpu *device.NvidiaGPU)</span> <span class="title">error</span></span> &#123;</span><br><span class="line"></span><br><span class="line">	Logger.Info(<span class="string">"Start mount GPU: "</span> + gpu.String() + <span class="string">" to Pod: "</span> + pod.Name)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// change devices control group</span></span><br><span class="line">	containerID := pod.Status.ContainerStatuses[<span class="number">0</span>].ContainerID</span><br><span class="line">	containerID = strings.Replace(containerID, <span class="string">"docker://"</span>, <span class="string">""</span>, <span class="number">1</span>)</span><br><span class="line">    Logger.Info(<span class="string">"Pod :"</span> + pod.Name + <span class="string">" container ID: "</span> + containerID)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//拼接 该容器对应的cgroup 文件 例如：/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-pod1234_abcd_5678_efgh.slice</span></span><br><span class="line">	cgroupPath, err := cgroup.GetCgroupName(<span class="string">"cgroupfs"</span>, pod, containerID)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		Logger.Error(<span class="string">"Get cgroup path for Pod: "</span> + pod.Name + <span class="string">" failed"</span>)</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	Logger.Info(<span class="string">"Successfully get cgroup path: "</span> + cgroupPath + <span class="string">" for Pod: "</span> + pod.Name)</span><br><span class="line"></span><br><span class="line">  <span class="comment">//获得容器对应的真实的cgroup目录，如/sys/fs/cgroup/devices+cgroupPath，即/sys/fs/cgroup/devices/kubepods.slice/kubepods-besteffort.slice/kubepods-besteffort-pod17edd3dd_e2ec_43c6_8c7d_83d4322f1b2c.slice</span></span><br><span class="line">   <span class="comment">//将GPU 的版本信息读写权限配置到device.allow</span></span><br><span class="line">  <span class="comment">// echo c  "&#123;device.DEFAULT_NVIDA_MAJOR_NUMBER&#125;:&#123;gpu.MinorNumber&#125;  rw" &gt;  /sys/fs/cgroup/devices/kubepods.slice/kubepods-besteffort.slice/kubepods-besteffort-pod17edd3dd_e2ec_43c6_8c7d_83d4322f1b2c.slice/devices.allow"</span></span><br><span class="line">	<span class="keyword">if</span> err := cgroup.AddGPUDevicePermission(cgroupPath, gpu); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		Logger.Error(<span class="string">"Add GPU "</span> + gpu.String() + <span class="string">"failed"</span>)</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	Logger.Info(<span class="string">"Successfully add GPU: "</span> + gpu.String() + <span class="string">" permisssion for Pod: "</span> + pod.Name)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// get target PID of this group</span></span><br><span class="line">    <span class="comment">//从文件 /sys/fs/cgroup/devices/kubepods.slice/kubepods-besteffort.slice/kubepods-besteffort-pod17edd3dd_e2ec_43c6_8c7d_83d4322f1b2c.slice/cgroup.procs中获取PID</span></span><br><span class="line">	pids, err := cgroup.GetCgroupPIDs(cgroupPath)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		Logger.Error(<span class="string">"Get PID of Pod: "</span> + pod.Name + <span class="string">" Container: "</span> + containerID + <span class="string">" failed"</span>)</span><br><span class="line">		Logger.Error(err)</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	PID, err := strconv.Atoi(pids[<span class="number">0</span>])</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		Logger.Error(<span class="string">"Invalid PID: "</span>, pids[<span class="number">0</span>])</span><br><span class="line">		Logger.Error(err)</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	Logger.Info(<span class="string">"Successfully get PID: "</span> + strconv.Itoa(PID) + <span class="string">" of Pod: "</span> + pod.Name + <span class="string">" Container: "</span> + containerID)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// enter container namespace to mknod</span></span><br><span class="line">    <span class="comment">//进入容器命名mount 命名空间，执行mknod</span></span><br><span class="line">    <span class="comment">// nsenter --target containerPid --cgroup --ipc --mount --net --pid --user --uts  </span></span><br><span class="line">    <span class="comment">// "mknod -m " + device.DEFAULT_DEVICE_FILE_PERMISSION + " " + gpu.DeviceFilePath + " c " + strconv.Itoa(device.DEFAULT_NVIDA_MAJOR_NUMBER) + " " + strconv.Itoa(gpu.MinorNumber)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	cfg := &amp;namespace.Config&#123;</span><br><span class="line">		Mount:  <span class="literal">true</span>, <span class="comment">// Execute into mount namespace</span></span><br><span class="line">		Target: PID,  <span class="comment">// Enter into Target namespace</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> err := namespace.AddGPUDeviceFile(cfg, gpu); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		Logger.Error(<span class="string">"Failed to create device file in Target PID Namespace: "</span>, PID, <span class="string">" Pod: "</span>, pod.Name, <span class="string">" Namespace: "</span>, pod.Namespace)</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	Logger.Info(<span class="string">"Successfully create device file in Target PID Namespace: "</span>, PID, <span class="string">" Pod: "</span>, pod.Name, <span class="string">" Namespace: "</span>, pod.Namespace)</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title>什么是LLVM</title>
    <url>/2021/01/26/%E4%BB%80%E4%B9%88%E6%98%AFLLVM/</url>
    <content><![CDATA[<h2 id="LLVM-介绍"><a href="#LLVM-介绍" class="headerlink" title="LLVM 介绍"></a>LLVM 介绍</h2><p>LLVM项目是模块化、可重用的编译器以及工具链技术的集合。LLVM是构架编译器(compiler)的框架系统，以C++编写而成，用于优化以任意程序语言编写的程序的编译时间(compile-time)、链接时间(link-time)、运行时间(run-time)以及空闲时间(idle-time)，对开发者保持开放，并兼容已有脚本。</p>
<blockquote>
<p>趣闻：Chris Latter本来只是想写一个底层的虚拟机，这也是LLVM名字的由来，low level virtual machine，跟Java的JVM虚拟机一样，可是后来，llvm从来没有被用作过虚拟机，哪怕LLVM的名气已经传开了。所以人们决定仍然叫他LLVM，更多的时候只是当作“商标”一样的感觉在使用，其实它跟虚拟机没有半毛钱关系。官方描述如下:The name “LLVM” itself is not an acronym; it is the full name of the project. “LLVM”这个名称本身不是首字母缩略词; 它是项目的全名。</p>
</blockquote>
<h2 id="传统的编译器架构"><a href="#传统的编译器架构" class="headerlink" title="传统的编译器架构"></a>传统的编译器架构</h2><p> <img src="/2021/01/26/%E4%BB%80%E4%B9%88%E6%98%AFLLVM/1.png" alt="avatar"></p>
<ul>
<li>Frontend:前端，词法分析、语法分析、语义分析、生成中间代码</li>
<li>Optimizer:优化器，中间代码优化</li>
<li>Backend:后端生成机器码</li>
</ul>
<h2 id="LLVM-编译器架构"><a href="#LLVM-编译器架构" class="headerlink" title="LLVM 编译器架构"></a>LLVM 编译器架构</h2><p> <img src="/2021/01/26/%E4%BB%80%E4%B9%88%E6%98%AFLLVM/2.png" alt="avatar"></p>
<ul>
<li>不同的前端后端使用统一的中间代码LLVM Intermediate Representation (LLVM IR)</li>
<li>如果需要支持一种新的编程语言，那么只需要实现一个新的前端</li>
<li>如果需要支持一种新的硬件设备，那么只需要实现一个新的后端</li>
<li>优化阶段是一个通用的阶段，它针对的是统一的LLVM IR，不论是支持新的编程语言，还是支持新的硬件设备，都不需要对优化阶段做修改</li>
<li>相比之下，GCC的前端和后端没分得太开，前端后端耦合在了一起。所以GCC为了支持一门新的语言，或者为了支持一个新的目标平台，就 变得特别困难</li>
<li>LLVM现在被作为实现各种静态和运行时编译语言的通用基础结构(GCC家族、Java、.NET、Python、Ruby、Scheme、Haskell、D等)</li>
</ul>
<p>为什么使用三段式设计？优势在哪里？首先解决一个很大的问题：假如有N种语言（C、OC、C++、Swift…）的前端，同时也有M个架构（模拟器、arm64、x86…）的target，是否就需要N*M个编译器？三段式架构的价值就提现出来了，通过共享优化器的中转，很好的解决了这个问题。</p>
]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux eBPF介绍</title>
    <url>/2021/01/26/Linux-eBPF%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<h2 id="eBPF的介绍"><a href="#eBPF的介绍" class="headerlink" title="eBPF的介绍"></a>eBPF的介绍</h2><p>eBPF源于早年间的成型于 BSD 之上的传统技术 BPF(Berkeley Packet Filter)。BPF 的全称是 Berkeley Packet Filter，顾名思义，这是一个用于过滤(filter)网络报文(packet)的架构。BPF 是在 1997 年首次被引入 Linux 的，Linux 内核中的报文过滤机制其实是有自己的名字的：Linux Socket Filter，简称 LSF。从 3.15 开始，一个套源于 BPF 的全新设计开始，在3.17被添置到了 kernel/bpf 下。全新设计最终被命名为了 extended BPF(eBPF)；为了后向兼容，传统的 BPF 仍被保留了下来，并被重命名为 classical BPF(cBPF)。相对于 cBPF，eBPF 带来的改变可谓是革命性的：一方面，它已经为内核追踪(Kernel Tracing)、应用性能调优/监控、流控(Traffic Control)等领域带来了激动人心的变革；另一方面，在接口的设计以及易用性上，eBPF 也有了较大的改进。</p>
<p>cBPF 所覆盖的功能范围很简单，就是网络监控和 seccomp 两块，数据接口设计的粗放；而 eBPF 的利用范围要广的多，性能调优、内核监控、流量控制什么的，数据接口的多样性设计。</p>
<h2 id="使用eBPF可以做什么？"><a href="#使用eBPF可以做什么？" class="headerlink" title="使用eBPF可以做什么？"></a>使用eBPF可以做什么？</h2><p>一个eBPF程序会附加到指定的内核代码路径中，当执行该代码路径时，会执行对应的eBPF程序。鉴于它的起源，eBPF特别适合编写网络程序，将该网络程序附加到网络socket，进行流量过滤，流量分类以及执行网络分类器的动作。eBPF程序甚至可以修改一个已建链的网络socket的配置。XDP工程会在网络栈的底层运行eBPF程序，高性能地进行处理接收到的报文。从下图可以看到eBPF支持的功能，eBPF是一项革命性的技术，可以在Linux内核中运行沙盒程序，而无需更改内核源代码或加载内核模块。通过使Linux内核可编程，基础架构软件可以利用现有的层，从而使它们更加智能和功能丰富，而无需继续为系统增加额外的复杂性层。·</p>
<p>上个图，目前没有看明白</p>
<p> <img src="/2021/01/26/Linux-eBPF%E4%BB%8B%E7%BB%8D/2.jpg" alt="avatar"></p>
<h2 id="eBFP程序"><a href="#eBFP程序" class="headerlink" title="eBFP程序"></a>eBFP程序</h2><p>在很多情况下，不是直接使用eBPF，而是通过Cilium，bcc或bpftrace等项目间接使用eBPF，这些项目在eBPF之上提供了抽象，并且不需要直接编写程序，而是提供了指定基于意图的定义的功能，然后使用eBPF实施。如果不存在更高级别的抽象，则需要直接编写程序。 Linux内核希望eBPF程序以字节码的形式加载。虽然当然可以直接编写字节码，但更常见的开发实践是利用LLVM之类的编译器套件将伪C代码编译为eBPF字节码。</p>
<p>eBPF调用关系(运行架构)</p>
<p><img src="/2021/01/26/Linux-eBPF%E4%BB%8B%E7%BB%8D/3.jpg" alt="avatar"></p>
<h2 id="eBPF-项目"><a href="#eBPF-项目" class="headerlink" title="eBPF 项目"></a>eBPF 项目</h2><p>bpftrace项目，<a href="https://github.com/iovisor/bpftrace" target="_blank" rel="noopener">项目地址</a></p>
<p>bpftrace是Linux eBPF的高级跟踪语言。它的语言受awk和C以及DTrace和SystemTap等以前的跟踪程序的启发。 bpftrace使用LLVM作为后端将脚本编译为eBPF字节码，并利用BCC作为与Linux eBPF子系统以及现有Linux跟踪功能和连接点进行交互的库。</p>
<p>bcc项目，<a href="https://github.com/iovisor/bcc" target="_blank" rel="noopener">项目地址</a></p>
<p>现在可以用 C 来实现 BPF，但编译出来的却仍然是 ELF 文件，开发者需要手动析出真正可以注入内核的代码。这工作有些麻烦，于是就有人设计了 BPF Compiler Collection(BCC)，BCC 是一个 python 库，但是其中有很大一部分的实现是基于 C 和 C++的，python实现了对 BCC 应用层接口的封装。使用 BCC 进行 BPF 的开发仍然需要开发者自行利用 C 来设计 BPF 程序——但也仅此而已，余下的工作，包括编译、解析 ELF、加载 BPF 代码块以及创建 map 等等基本可以由 BCC 一力承担，无需多劳开发者费心</p>
<p>Cilium项目，<a href="https://github.com/cilium/cilium" target="_blank" rel="noopener">项目地址</a></p>
<p>Cilium是一个开源项目，提供基于eBPF的联网，安全性和可观察性。它是从头开始专门设计的，旨在将eBPF的优势带入Kubernetes的世界，并满足容器工作负载的新可伸缩性，安全性和可见性要求。</p>
]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>介绍WASM</title>
    <url>/2021/01/26/%E4%BB%8B%E7%BB%8DWASM/</url>
    <content><![CDATA[<p>在JavaScript和机器代码之间搭建桥梁，将后端的算法编译为.wasm文件导入到前端，供js调用。从理论上讲，这项新技术最终实现了让我们可以编写机器代码以在浏览器的虚拟安全沙箱中运行，甚至升级后的WASM被设计为其它语言的编译目标，允许将服务器端代码（例如C或C ++代码）编译到其中，同时在浏览器中执行。要强调的是，WASM并非由开发人员去编写，而是允许开发人员借助C、Go或其它语言编写，并使该逻辑在浏览器上工作</p>
<h2 id="WASM的设计初衷是什么？"><a href="#WASM的设计初衷是什么？" class="headerlink" title="WASM的设计初衷是什么？"></a>WASM的设计初衷是什么？</h2><ol>
<li><p>WASM的出现绝不是要让它成为一门新的编程语言，正相反，它被规划并设计为一个编译目标，允许C的开发者编译其代码，并在浏览器上运行。</p>
</li>
<li><p>WASM旨在提供高度优化的网络计算能力，并被期待去打破JavaScript在既有环境中的垄断（尽管JavaScript是一种很不错的语言，但其在设计之初就没有考虑到性能上的问题）。</p>
</li>
<li><p>WASM并不是被拿来实现网站优化的，而是尝试在运行以下这些繁重任务时，将浏览器（以及服务端运行时，例如Node.js）的运行推升到一个水准：视频编辑游戏开发AR / VR实时应用音乐编辑和流媒体加密VPN影像辨识以及，其它的一些繁重的任务可以这样说，那些你可以想到的、原本工作量巨大的web代码编译以及性能调试，回到设计初衷上，都可以被用来反向证明WASM的价值。</p>
</li>
</ol>
<h2 id="使用WASM的场景"><a href="#使用WASM的场景" class="headerlink" title="使用WASM的场景"></a>使用WASM的场景</h2><p>Tensorflow.js： 把AI和ML带给JS开发人员的库，在添加了WASM后端支持后，Tensorflow一直致力于实现更多的模型，效果如何？与纯JS版本相比，这些模型性能平均提高了10倍。，对这块没有深入研究，只是了解个概念，具体可以参考<a href="https://blog.tensorflow.org/2020/03/introducing-webassembly-backend-for-tensorflow-js.html" target="_blank" rel="noopener">这里</a></p>
]]></content>
      <tags>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title>Sysdig-项目</title>
    <url>/2021/01/26/Sysdig-%E9%A1%B9%E7%9B%AE/</url>
    <content><![CDATA[<hr>
<p>title: Sysdig 项目<br>date: 2021-01-26 19:17:46<br>tags: Linux</p>
<hr>
<p>sysdig相当于strace + tcpdump + lsof + htop + iftop 以及其他工具的合集 ，除此之外其还能对容器如docker、coreOS、LXC进行监控，收集了一些用法，具体可以参考<a href="https://blog.csdn.net/vic_qxz/article/details/107761255?utm_medium=distribute.pc_relevant.none-task-blog-searchFromBaidu-3.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-searchFromBaidu-3.control" target="_blank" rel="noopener">这里</a></p>
<h2 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h2><p>sysdig 通过在内核的 driver 模块注册系统调用的 hook，这样当有系统调用发生和完成的时候，它会把系统调用信息拷贝到特定的 buffer，然后用户模块的组件对数据信息处理（解压、解析、过滤等），并最终通过 sysdig 命令行和用户进行交互。如下图所示：<br> <img src="/2021/01/26/Sysdig-%E9%A1%B9%E7%9B%AE/1.png" alt="avatar"></p>
<h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><ol>
<li><p>网络<br> 查看占用网络带宽最多的进程：</p>
<p> sysdig -c topprocs_net</p>
<p> 显示主机192.168.0.1的网络传输数据：</p>
<p> sysdig -s2000 -X -c echo_fds fd.cip=192.168.0.1</p>
<p> 这里显示网络传输功能，实际效果和tcpdump抓包是一样的。而且其本身也支持sysdig -w dump.scap抓包保存（可以配置-X或-A使用），抓好包也支持sysdir -r dump.scap读取。</p>
<p> 查看连接最多的服务器端口：</p>
<p> in terms of established connections:</p>
<p> sysdig -c fdcount_by fd.sport “evt.type=accept”</p>
<p> in terms of total bytes:</p>
<p> sysdig -c fdbytes_by fd.sport</p>
<p> 查看客户端连接最多的ip：</p>
<p> in terms of established connections</p>
<p> sysdig -c fdcount_by fd.cip “evt.type=accept”</p>
<p> in terms of total bytes</p>
<p> sysdig -c fdbytes_by fd.cip</p>
<p> 列出所有不是访问apache服务的访问连接：</p>
<p> sysdig -p”%proc.name %fd.name” “evt.type=accept and proc.name!=httpd”</p>
</li>
<li><p>硬盘 I/O</p>
<p> 查看使用硬盘带宽最多的进程：</p>
<p> sysdig -c topprocs_file</p>
<p> 列出使用大量文件描述符的进程</p>
<p> sysdig -c fdcount_by proc.name “fd.type=file”</p>
<p> See the top files in terms of read+write bytes</p>
<p> sysdig -c topfiles_bytes</p>
<p> Print the top files that apache has been reading from or writing to</p>
<p> sysdig -c topfiles_bytes proc.name=httpd</p>
<p> Basic opensnoop: snoop file opens as they occur</p>
<p> sysdig -p “%12user.name %6proc.pid %12proc.name %3fd.num %fd.typechar %fd.name” evt.type=open</p>
<p> See the top directories in terms of R+W disk activity</p>
<p> sysdig -c fdbytes_by fd.directory “fd.type=file”</p>
<p> See the top files in terms of R+W disk activity in the /tmp directory</p>
<p> sysdig -c fdbytes_by fd.filename “fd.directory=/tmp/“</p>
<p> Observe the I/O activity on all the files named ‘passwd’</p>
<p> sysdig -A -c echo_fds “fd.filename=passwd”</p>
<p> Display I/O activity by FD type</p>
<p> sysdig -c fdbytes_by fd.type</p>
</li>
<li><p>进程和CPU使用率</p>
<p> See the top processes in terms of CPU usage</p>
<p> sysdig -c topprocs_cpu</p>
<p> See the top processes for CPU 0</p>
<p> sysdig -c topprocs_cpu evt.cpu=0</p>
<p> Observe the standard output of a process</p>
<p> sysdig -s4096 -A -c stdout proc.name=cat</p>
</li>
</ol>
<p>4、应用</p>
<pre><code>查看机器所有的HTTP请求

sudo sysdig -s 2000 -A -c echo_fds fd.port=80 and evt.buffer contains GET

查看机器所有的SQL select查询

sudo sysdig -s 2000 -A -c echo_fds evt.buffer contains SELECT

See queries made via apache to an external MySQL server happening in real time

sysdig -s 2000 -A -c echo_fds fd.sip=192.168.30.5 and proc.name=apache2 and evt.buffer contains SELECT</code></pre>
<ol start="5">
<li><p>性能和错误</p>
<p> See the files where most time has been spent</p>
<p> sysdig -c topfiles_time</p>
<p> See the files where apache spent most time</p>
<p> sysdig -c topfiles_time proc.name=httpd</p>
<p> See the top processes in terms of I/O errors</p>
<p> sysdig -c topprocs_errors</p>
<p> See the top files in terms of I/O errors</p>
<p> sysdig -c topfiles_errors</p>
<p> See all the failed disk I/O calls</p>
<p> sysdig fd.type=file and evt.failed=true</p>
<p> See all the failed file opens by httpd</p>
<p> sysdig “proc.name=httpd and evt.type=open and evt.failed=true”</p>
<p> See the system calls where most time has been spent</p>
<p> sysdig -c topscalls_time</p>
<p> See the top system calls returning errors</p>
<p> sysdig -c topscalls “evt.failed=true”</p>
<p> snoop failed file opens as they occur</p>
<p> sysdig -p “%12user.name %6proc.pid %12proc.name %3fd.num %fd.typechar %fd.name” evt.type=open and evt.failed=true</p>
<p> Print the file I/O calls that have a latency greater than 1ms:</p>
<p> sysdig -c fileslower 1</p>
</li>
<li><p>安全</p>
<p> Show the directories that the user “root” visits</p>
<p> sysdig -p”%evt.arg.path” “evt.type=chdir and user.name=root”</p>
<p> Observe ssh activity</p>
<p> sysdig -A -c echo_fds fd.name=/dev/pretmx and proc.name=sshd</p>
<p> Show every file open that happens in /etc</p>
<p> sysdig evt.type=open and fd.name contains /etc</p>
<p> Show the ID of all the login shells that have launched the “tar” command</p>
<p> sysdig -r file.scap -c list_login_shells tar</p>
<p> Show all the commands executed by the login shell with the given ID</p>
<p> sysdig -r trace.scap.gz -c spy_users proc.loginshellid=5459</p>
</li>
<li><p>容器</p>
<p> 查看机器上运行的容器列表及其资源使用情况</p>
<p> sudo csysdig -vcontainers</p>
<p> 查看容器上下文的进程列表</p>
<p> sudo csysdig -pc</p>
<p> 查看运行在wordpress1容器里CPU的使用率</p>
<p> sudo sysdig -pc -c topprocs_cpu container.name=wordpress1</p>
<p> 查看运行在wordpress1容器里网络带宽的使用率</p>
<p> sudo sysdig -pc -c topprocs_net container.name=wordpress1</p>
<p> 查看在wordpress1容器里使用网络带宽最多的进程</p>
<p> sudo sysdig -pc -c topprocs_net container.name=wordpress1</p>
<p> 查看在wordpress1 容器里占用 I/O 字节最多的文件</p>
<p> sudo sysdig -pc -c topfiles_bytes container.name=wordpress1</p>
<p> 查看在wordpress1 容器里网络连接的排名情况</p>
<p> sudo sysdig -pc -c topconns container.name=wordpress1</p>
<p> 显示wordpress1容器里所有命令执行的情况</p>
<p> sudo sysdig -pc -c spy_users container.name=wordpress1</p>
</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>kubernetes nfs pvc</title>
    <url>/2021/01/27/kubernetes-nfs-pvc/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>NFS 硬挂载和软挂载</title>
    <url>/2021/02/07/NFS-%E7%A1%AC%E6%8C%82%E8%BD%BD%E5%92%8C%E8%BD%AF%E6%8C%82%E8%BD%BD/</url>
    <content><![CDATA[<h2 id="硬挂载"><a href="#硬挂载" class="headerlink" title="硬挂载"></a>硬挂载</h2><p>硬挂载通常用于块资源，例如本地磁盘或 SAN 。当 NFS 文件系统挂载是硬挂载时、会反复发出影响挂载资源任何部分的 NFS 请求、直到满足请求（例如，服务器崩溃并在以后重新启动）。服务器恢复联机后、程序将继续执行服务器崩溃期间不受干扰的状态。我们可以使用挂载选项 “INTR” 、该选项允许在服务器停机或无法访问时中断 NFS 请求。因此，建议的设置是硬设置和 INTR 选项。</p>
<p>优势： 如果连接丢失、则所有 NFS 客户端都将冻结、直到 NFS 服务器重新联机。因此不会丢失数据。确保数据完整性和消息传送。</p>
<p>缺点： 持续连接可能会对性能产生影响。</p>
<p>命令从远程计算机 host.server.com 在 mount -point/mymountpoint 上硬挂载目录 /home 。rw —表示已安装要进行读写的资源、以及为键盘中断启用 Intr 。 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mount -o rw,hard,intr host.server.com&#x2F;home &#x2F;mymountpoint</span><br></pre></td></tr></table></figure>

<h1 id="软挂载"><a href="#软挂载" class="headerlink" title="软挂载"></a>软挂载</h1><p>软挂载通常用于 NFS 或 CIFS 等网络文件协议。当 NFS 文件系统挂载是软挂载时、程序或应用程序从 NFS 文件系统请求文件时、 NFS 客户端守护进程将尝试从 NFS 服务器检索数据。NFS 会反复尝试与服务器联系，直至已建立连接,满足 NFS 重试阈值,已达到nfstimeOut 值.如果发生其中一个事件， Control 将返回调用程序。但是，如果 NFS 服务器没有响应（由于 NFS 服务器的任何崩溃、超时或故障）、 NFS 客户端将向请求文件访问的客户端计算机上的进程报告错误、然后退出。</p>
<p>优势:  此机制的优点是“快速响应”、因为它不会等待 NFS 服务器响应。如果 NFS 服务器不可用、内核将在预配置的时间段后超时 I/O 操作。</p>
<p>劣势: 缺点是，如果 NFS 驱动程序缓存数据并且软挂载超时、应用程序可能不知道哪些写入 NFS 卷实际上是提交到磁盘的。<br>数据损坏或数据丢失。</p>
<p>在 mount -point/mymountpoint 上从远程计算机 host.server.com 执行软挂载的命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mount -o rw,soft host.server.com&#x2F;home &#x2F;mymountpoint</span><br></pre></td></tr></table></figure>

<p>要检查当前系统上存在的挂载类型，请执行以下操作：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[usero1@Linux01 ~]$ nfsstat -m</span><br><span class="line"></span><br><span class="line">&#x2F;home from vrouter:&#x2F;home</span><br><span class="line">Flags: rw,relatime,vers&#x3D;4.1,rsize&#x3D;262144,wsize&#x3D;262144,namlen&#x3D;255,hard,proto&#x3D;tcp,port&#x3D;0,timeo&#x3D;600,retrans&#x3D;2,sec&#x3D;sys,clientaddr&#x3D; 10.0.0.1,local_lock&#x3D;none,addr&#x3D;10.0.0.2</span><br><span class="line">&#x2F;mnt&#x2F;test from svm-data-lif1:&#x2F;vol_unix</span><br><span class="line">Flags: rw,relatime,vers&#x3D;4.0,rsize&#x3D;65536,wsize&#x3D;65536,namlen&#x3D;255,hard,proto&#x3D;tcp,port&#x3D;0,timeo&#x3D;600,retrans&#x3D;2,sec&#x3D;sys,clientaddr&#x3D; 10.0.0.1,local_lock&#x3D;none,addr&#x3D;10.0.0.2</span><br></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title>cachefilesd缓存项目介绍</title>
    <url>/2021/02/19/cachefilesd%E7%BC%93%E5%AD%98%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<p>原文引自<a href="https://www.kernel.org/doc/html/latest/filesystems/caching/cachefiles.html" target="_blank" rel="noopener">这里</a></p>
<h2 id="FS-Cache"><a href="#FS-Cache" class="headerlink" title="FS Cache"></a>FS Cache</h2><p>FS-Cache是一种内核功能，网络文件系统或其他文件系统可以通过它来缓存数据到本地磁盘空间，减少网络传输的数据，从而提升性能。这在网络速度比较慢时会得到比较好的效果。</p>
<p>FS-Cache 可以被任何希望添加本地缓存的文件系统使用，例如：AFS、NFS、CIFS和Isofs。</p>
<p>FS-Cache 对于客户端文件系统是透明存在的，当这项功能开启的时候，透过缓存请求文件对于客户端是无感知的。可以参考下图，FS-Cache可以认为是网络文件系统和缓存后端的中间介质:<br><img src="/2021/02/19/cachefilesd%E7%BC%93%E5%AD%98%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D/1.png" alt="avatar"></p>
<p>看一个更详细的图，FS-Cache为网络文件系统提供了一个缓存工具，从而让缓存对用户无感知<br><img src="/2021/02/19/cachefilesd%E7%BC%93%E5%AD%98%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D/2.png" alt="avatar"></p>
<p>FS-Cache并不遵循在允许访问之前将所有完全打开的每个netfs文件完全加载到高速缓存中，主要有以下几个原因：</p>
<ol>
<li>没有Cache 也应该能够正常操作</li>
<li>被访问的文件的大小不应该受限于Cache的空间大小</li>
<li>所有已经打开的文件大小不应该受限于Cache的空间大小</li>
<li>不应该强制用户为了一个文件操作（访问文件的一小部分）将整个文件全部进行下载缓存</li>
</ol>
<p>FS-Cache提供的能力如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. More than one cache can be used at once. Caches can be selected explicitly by use of tags. 一次可以使用多个Cache，不同的Cache使用不同的tag区分</span><br><span class="line">2. Caches can be added &#x2F; removed at any time. Cache可以在任何时间被移除或者添加</span><br><span class="line">3. The netfs is provided with an interface that allows either party to withdraw caching facilities from a file (required for (2)). 网络文件系统提供接口，能够允许其他方删除文件cache相关的能力</span><br><span class="line">4. The interface to the netfs returns as few errors as possible, preferring rather to let the netfs remain oblivious. 网络文件系统尽量不要返回错误</span><br><span class="line">5. Cookies are used to represent indices, files and other objects to the netfs. The simplest cookie is just a NULL pointer - indicating nothing cached there. 使用cookie表示文件系统的目录、文件、其他对象</span><br><span class="line">6. The netfs is allowed to propose - dynamically - any index hierarchy it desires, though it must be aware that the index search function is recursive, stack space is limited, and indices can only be children of indices.</span><br><span class="line">7. Data I&#x2F;O is done direct to and from the netfs’s pages. The netfs indicates that page A is at index B of the data-file represented by cookie C, and that it should be read or written. The cache backend may or may not start I&#x2F;O on that page, but if it does, a netfs callback will be invoked to indicate completion. The I&#x2F;O may be either synchronous or asynchronous.</span><br><span class="line">8. Cookies can be “retired” upon release. At this point FS-Cache will mark them as obsolete and the index hierarchy rooted at that point will get recycled.</span><br><span class="line">9. The netfs provides a “match” function for index searches. In addition to saying whether a match was made or not, this can also specify that an entry should be updated or deleted.</span><br><span class="line">10. As much as possible is done asynchronously.</span><br></pre></td></tr></table></figure>

<p>FS-Cache维护了一个网络文件系统数据的全部索引，该信息可以位于一个或者多个cache中，如下图所示：</p>
<p><img src="/2021/02/19/cachefilesd%E7%BC%93%E5%AD%98%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D/3.png" alt="avatar"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">In the example above, you can see two netfs’s being backed: NFS and AFS. These have different index hierarchies:</span><br><span class="line"></span><br><span class="line">* The NFS primary index contains per-server indices. Each server index is indexed by NFS file handles to get data file objects. Each data file objects can have an array of pages, but may also have further child objects, such as extended attributes and directory entries. Extended attribute objects themselves have page-array contents.</span><br><span class="line">* The AFS primary index contains per-cell indices. Each cell index contains per-logical-volume indices. Each of volume index contains up to three indices for the read-write, read-only and backup mirrors of those volumes. Each of these contains vnode data file objects, each of which contains an array of pages.</span><br></pre></td></tr></table></figure>
<h2 id="Kernel-内部的Cache-管理"><a href="#Kernel-内部的Cache-管理" class="headerlink" title="Kernel 内部的Cache 管理"></a>Kernel 内部的Cache 管理</h2><p>FS-Cache维护类内核形态的网络文件感兴趣的对象，这些对象使用fscache_cookie 结构体来表示，以cookie的方式被引用。</p>
<p>FS-Cache 也单独维护了内核形态的 缓存后端正在使用的对象cache</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FS-Cache maintains an in-kernel representation of each object that a netfs is currently interested in. Such objects are represented by the fscache_cookie struct and are referred to as cookies.</span><br><span class="line"></span><br><span class="line">FS-Cache also maintains a separate in-kernel representation of the objects that a cache backend is currently actively caching. Such objects are represented by the fscache_object struct. The cache backends allocate these upon request, and are expected to embed them in their own representations. These are referred to as objects.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">There is a 1:N relationship between cookies and objects. A cookie may be represented by multiple objects - an index may exist in more than one cache - or even by no objects (it may not be cached).</span><br><span class="line"></span><br><span class="line">Furthermore, both cookies and objects are hierarchical. The two hierarchies correspond, but the cookies tree is a superset of the union of the object trees of multiple caches:</span><br><span class="line"></span><br><span class="line">    NETFS INDEX TREE               :      CACHE 1     :      CACHE 2</span><br><span class="line">                                   :                  :</span><br><span class="line">                                   :   +-----------+  :</span><br><span class="line">                          +-----------&gt;|  IObject  |  :</span><br><span class="line">      +-----------+       |        :   +-----------+  :</span><br><span class="line">      |  ICookie  |-------+        :         |        :</span><br><span class="line">      +-----------+       |        :         |        :   +-----------+</span><br><span class="line">            |             +------------------------------&gt;|  IObject  |</span><br><span class="line">            |                      :         |        :   +-----------+</span><br><span class="line">            |                      :         V        :         |</span><br><span class="line">            |                      :   +-----------+  :         |</span><br><span class="line">            V             +-----------&gt;|  IObject  |  :         |</span><br><span class="line">      +-----------+       |        :   +-----------+  :         |</span><br><span class="line">      |  ICookie  |-------+        :         |        :         V</span><br><span class="line">      +-----------+       |        :         |        :   +-----------+</span><br><span class="line">            |             +------------------------------&gt;|  IObject  |</span><br><span class="line">      +-----+-----+                :         |        :   +-----------+</span><br><span class="line">      |           |                :         |        :         |</span><br><span class="line">      V           |                :         V        :         |</span><br><span class="line">+-----------+     |                :   +-----------+  :         |</span><br><span class="line">|  ICookie  |-------------------------&gt;|  IObject  |  :         |</span><br><span class="line">+-----------+     |                :   +-----------+  :         |</span><br><span class="line">      |           V                :         |        :         V</span><br><span class="line">      |     +-----------+          :         |        :   +-----------+</span><br><span class="line">      |     |  ICookie  |--------------------------------&gt;|  IObject  |</span><br><span class="line">      |     +-----------+          :         |        :   +-----------+</span><br><span class="line">      V           |                :         V        :         |</span><br><span class="line">+-----------+     |                :   +-----------+  :         |</span><br><span class="line">|  DCookie  |-------------------------&gt;|  DObject  |  :         |</span><br><span class="line">+-----------+     |                :   +-----------+  :         |</span><br><span class="line">                  |                :                  :         |</span><br><span class="line">          +-------+-------+        :                  :         |</span><br><span class="line">          |               |        :                  :         |</span><br><span class="line">          V               V        :                  :         V</span><br><span class="line">    +-----------+   +-----------+  :                  :   +-----------+</span><br><span class="line">    |  DCookie  |   |  DCookie  |------------------------&gt;|  DObject  |</span><br><span class="line">    +-----------+   +-----------+  :                  :   +-----------+</span><br><span class="line">                                   :                  :</span><br><span class="line">In the above illustration, ICookie and IObject represent indices and DCookie and DObject represent data storage objects. Indices may have representation in multiple caches, but currently, non-index objects may not. Objects of any type may also be entirely unrepresented.</span><br><span class="line"></span><br><span class="line">As far as the netfs API goes, the netfs is only actually permitted to see pointers to the cookies. The cookies themselves and any objects attached to those cookies are hidden from it.</span><br></pre></td></tr></table></figure>

<h2 id="对象管理状态机"><a href="#对象管理状态机" class="headerlink" title="对象管理状态机"></a>对象管理状态机</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Within FS-Cache, each active object is managed by its own individual state machine. The state for an object is kept in the fscache_object struct, in object-&gt;state. A cookie may point to a set of objects that are in different states.</span><br><span class="line"></span><br><span class="line">Each state has an action associated with it that is invoked when the machine wakes up in that state. There are four logical sets of states:</span><br><span class="line"></span><br><span class="line">* Preparation: states that wait for the parent objects to become ready. The representations are hierarchical, and it is expected that an object must be created or accessed with respect to its parent object.</span><br><span class="line">* Initialisation: states that perform lookups in the cache and validate what’s found and that create on disk any missing metadata.</span><br><span class="line">* Normal running: states that allow netfs operations on objects to proceed and that update the state of objects.</span><br><span class="line">*  Termination: states that detach objects from their netfs cookies, that delete objects from disk, that handle disk and system errors and that free up in-memory resources.</span><br><span class="line">  </span><br><span class="line">In most cases, transitioning between states is in response to signalled events. When a state has finished processing, it will usually set the mask of events in which it is interested (object-&gt;event_mask) and relinquish the worker thread. Then when an event is raised (by calling fscache_raise_event()), if the event is not masked, the object will be queued for processing (by calling fscache_enqueue_object()).</span><br></pre></td></tr></table></figure>

<h2 id="Provision-of-CPU-Time"><a href="#Provision-of-CPU-Time" class="headerlink" title="Provision of CPU Time"></a>Provision of CPU Time</h2><p>The work to be done by the various states was given CPU time by the threads of the slow work facility. This was used in preference to the workqueue facility because:</p>
<p>Threads may be completely occupied for very long periods of time by a particular work item. These state actions may be doing sequences of synchronous, journalled disk accesses (lookup, mkdir, create, setxattr, getxattr, truncate, unlink, rmdir, rename).</p>
<p>Threads may do little actual work, but may rather spend a lot of time sleeping on I/O. This means that single-threaded and 1-per-CPU-threaded workqueues don’t necessarily have the right numbers of threads.</p>
<h2 id="Locking-Simplification"><a href="#Locking-Simplification" class="headerlink" title="Locking Simplification"></a>Locking Simplification</h2><p>Because only one worker thread may be operating on any particular object’s state machine at once, this simplifies the locking, particularly with respect to disconnecting the netfs’s representation of a cache object (fscache_cookie) from the cache backend’s representation (fscache_object) - which may be requested from either end.</p>
<h2 id="状态集合"><a href="#状态集合" class="headerlink" title="状态集合"></a>状态集合</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The Set of States</span><br><span class="line">The object state machine has a set of states that it can be in. There are preparation states in which the object sets itself up and waits for its parent object to transit to a state that allows access to its children:</span><br><span class="line"></span><br><span class="line">1. State FSCACHE_OBJECT_INIT.</span><br><span class="line"></span><br><span class="line">Initialise the object and wait for the parent object to become active. In the cache, it is expected that it will not be possible to look an object up from the parent object, until that parent object itself has been looked up.</span><br><span class="line"></span><br><span class="line">There are initialisation states in which the object sets itself up and accesses disk for the object metadata:</span><br><span class="line"></span><br><span class="line">2. State FSCACHE_OBJECT_LOOKING_UP.</span><br><span class="line"></span><br><span class="line">Look up the object on disk, using the parent as a starting point. FS-Cache expects the cache backend to probe the cache to see whether this object is represented there, and if it is, to see if it’s valid (coherency management).</span><br><span class="line"></span><br><span class="line">The cache should call fscache_object_lookup_negative() to indicate lookup failure for whatever reason, and should call fscache_obtained_object() to indicate success.</span><br><span class="line"></span><br><span class="line">At the completion of lookup, FS-Cache will let the netfs go ahead with read operations, no matter whether the file is yet cached. If not yet cached, read operations will be immediately rejected with ENODATA until the first known page is uncached - as to that point there can be no data to be read out of the cache for that file that isn’t currently also held in the pagecache.</span><br><span class="line"></span><br><span class="line">3. State FSCACHE_OBJECT_CREATING.</span><br><span class="line"></span><br><span class="line">Create an object on disk, using the parent as a starting point. This happens if the lookup failed to find the object, or if the object’s coherency data indicated what’s on disk is out of date. In this state, FS-Cache expects the cache to create</span><br><span class="line"></span><br><span class="line">The cache should call fscache_obtained_object() if creation completes successfully, fscache_object_lookup_negative() otherwise.</span><br><span class="line"></span><br><span class="line">At the completion of creation, FS-Cache will start processing write operations the netfs has queued for an object. If creation failed, the write ops will be transparently discarded, and nothing recorded in the cache.</span><br><span class="line"></span><br><span class="line">There are some normal running states in which the object spends its time servicing netfs requests:</span><br><span class="line"></span><br><span class="line">4. State FSCACHE_OBJECT_AVAILABLE.</span><br><span class="line"></span><br><span class="line">A transient state in which pending operations are started, child objects are permitted to advance from FSCACHE_OBJECT_INIT state, and temporary lookup data is freed.</span><br><span class="line"></span><br><span class="line">5. State FSCACHE_OBJECT_ACTIVE.</span><br><span class="line"></span><br><span class="line">The normal running state. In this state, requests the netfs makes will be passed on to the cache.</span><br><span class="line"></span><br><span class="line">6. State FSCACHE_OBJECT_INVALIDATING.</span><br><span class="line"></span><br><span class="line">The object is undergoing invalidation. When the state comes here, it discards all pending read, write and attribute change operations as it is going to clear out the cache entirely and reinitialise it. It will then continue to the FSCACHE_OBJECT_UPDATING state.</span><br><span class="line"></span><br><span class="line">7. State FSCACHE_OBJECT_UPDATING.</span><br><span class="line"></span><br><span class="line">The state machine comes here to update the object in the cache from the netfs’s records. This involves updating the auxiliary data that is used to maintain coherency.</span><br><span class="line"></span><br><span class="line">And there are terminal states in which an object cleans itself up, deallocates memory and potentially deletes stuff from disk:</span><br><span class="line"></span><br><span class="line">8. State FSCACHE_OBJECT_LC_DYING.</span><br><span class="line"></span><br><span class="line">The object comes here if it is dying because of a lookup or creation error. This would be due to a disk error or system error of some sort. Temporary data is cleaned up, and the parent is released.</span><br><span class="line"></span><br><span class="line">9. State FSCACHE_OBJECT_DYING.</span><br><span class="line"></span><br><span class="line">The object comes here if it is dying due to an error, because its parent cookie has been relinquished by the netfs or because the cache is being withdrawn.</span><br><span class="line"></span><br><span class="line">Any child objects waiting on this one are given CPU time so that they too can destroy themselves. This object waits for all its children to go away before advancing to the next state.</span><br><span class="line"></span><br><span class="line">10. State FSCACHE_OBJECT_ABORT_INIT.</span><br><span class="line"></span><br><span class="line">The object comes to this state if it was waiting on its parent in FSCACHE_OBJECT_INIT, but its parent died. The object will destroy itself so that the parent may proceed from the FSCACHE_OBJECT_DYING state.</span><br><span class="line"></span><br><span class="line">11. State FSCACHE_OBJECT_RELEASING.</span><br><span class="line"></span><br><span class="line">12. State FSCACHE_OBJECT_RECYCLING.</span><br><span class="line"></span><br><span class="line">The object comes to one of these two states when dying once it is rid of all its children, if it is dying because the netfs relinquished its cookie. In the first state, the cached data is expected to persist, and in the second it will be deleted.</span><br><span class="line"></span><br><span class="line">13. State FSCACHE_OBJECT_WITHDRAWING.</span><br><span class="line"></span><br><span class="line">The object transits to this state if the cache decides it wants to withdraw the object from service, perhaps to make space, but also due to error or just because the whole cache is being withdrawn.</span><br><span class="line"></span><br><span class="line">14. State FSCACHE_OBJECT_DEAD.</span><br><span class="line"></span><br><span class="line">The object transits to this state when the in-memory object record is ready to be deleted. The object processor shouldn’t ever see an object in this state.</span><br></pre></td></tr></table></figure>

<h2 id="CacheFiles介绍"><a href="#CacheFiles介绍" class="headerlink" title="CacheFiles介绍"></a>CacheFiles介绍</h2><p>CacheFiles,是属于Linux Kernel的一个模块，主要用于缓存已经挂载的文件系统，CacheFiles 是一个缓存后端，当一个文件系统挂载到本地时，可以基于CacheFiles做一个缓存目录，CacheFi 使用一个用户空间的守护进程进行cache管理，例如收割陈旧的节点和剔除，这个守护进程被称为cachefilesd</p>
<p>缓存的文件系统和数据完整性与后端服务的文件系统一样好，由于不同文件系统的日志记录接口都是特殊定义的，因此CacheFiles不会尝试记录任文件系统日志</p>
<p>CacheFiles 会创建一个混杂的字符设备”/dev/cachefiles”,用于与守护进程进行通信，这个设备一次打开只能做一次事情，当它打开时，至少存在部分缓存，守护进程打开 并发送指令用于控制缓存，CacheFiles目前只能用于一个单独的缓存</p>
<p>CacheFiles会尝试维护文件系统一定比例的空闲空间，可能会通过剔除部分cache用户缩小cache的大小，用于释放空间，这就意味着可以在同一介质上存放灵活的实时数据，可能会扩展来使用空闲的空间，也可能收缩</p>
<h2 id="Requiremenets"><a href="#Requiremenets" class="headerlink" title="Requiremenets"></a>Requiremenets</h2><p>使用CacheFiles 需要以下依赖</p>
<ul>
<li>dnotify: 对文件信号进行监听</li>
<li>extended attribute（xattrs）</li>
<li>openat() and friends</li>
<li>bmap() support on files in the filesystem (FIBMAP ioctl)</li>
<li>the use of bmap() to detect a partial page at the end of the file</li>
</ul>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>配置文件 /etc/cachefilesd.conf,配置文件的主要内容为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">brun &lt;N&gt;%, bcull &lt;N&gt;%, bstop &lt;N&gt;%, frun &lt;N&gt;%, fcull &lt;N&gt;%, fstop &lt;N&gt;%</span><br><span class="line">Configure the culling limits. Optional. See the section on culling The defaults are 7% (run), 5% (cull) and 1% (stop) respectively.</span><br><span class="line"></span><br><span class="line">The commands beginning with a ‘b’ are file space (block) limits, those beginning with an ‘f’ are file count limits(也可以限制文件数量).</span><br><span class="line"></span><br><span class="line">dir &lt;path&gt; 存放缓存的根目录</span><br><span class="line">Specify the directory containing the root of the cache. Mandatory.</span><br><span class="line">tag &lt;name&gt; </span><br><span class="line">Specify a tag to FS-Cache to use in distinguishing multiple caches. Optional. The default is “CacheFiles”.</span><br><span class="line">debug &lt;mask&gt;  用于开启日志</span><br><span class="line">Specify a numeric bitmask to control debugging in the kernel module. Optional. The default is zero (all off). The following values can be OR’d into the mask to collect various information:</span><br><span class="line"></span><br><span class="line">1	Turn on trace of function entry (_enter() macros)</span><br><span class="line">2	Turn on trace of function exit (_leave() macros)</span><br><span class="line">4	Turn on trace of internal debug points (_debug())</span><br><span class="line">This mask can also be set through sysfs, eg:</span><br><span class="line"></span><br><span class="line">echo 5 &gt;&#x2F;sys&#x2F;modules&#x2F;cachefiles&#x2F;parameters&#x2F;debug</span><br></pre></td></tr></table></figure>

<h2 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h2><p>启动守护进程，该守护进程打开 cache 设备（/dev/cachefiles）,配置cache，并开始进行cache，此时cache绑定fscache，cache开始运行。具体的启动命令和参数如下所示：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The daemon is run as follows:</span><br><span class="line"></span><br><span class="line">&#x2F;sbin&#x2F;cachefilesd [-d]* [-s] [-n] [-f &lt;configfile&gt;]</span><br><span class="line">The flags are:</span><br><span class="line"></span><br><span class="line">-d</span><br><span class="line">Increase the debugging level. This can be specified multiple times and is cumulative with itself.</span><br><span class="line">-s</span><br><span class="line">Send messages to stderr instead of syslog.</span><br><span class="line">-n</span><br><span class="line">Don’t daemonise and go into background.</span><br><span class="line">-f &lt;configfile&gt;</span><br><span class="line">Use an alternative configuration file rather than the default one.</span><br></pre></td></tr></table></figure>

<h2 id="缓存剔除"><a href="#缓存剔除" class="headerlink" title="缓存剔除"></a>缓存剔除</h2><p>缓存偶尔需要进行清理，用于释放空间，这里主要将近期未被使用的cache进行清理，基于文件的访问时间进行判断，如果空目录没有在使用也会被清理。Cache的清理是基于配置的当前文件系统的block比例和文件比例，主要有6个限制，如下所示</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">brun, frun</span><br><span class="line">If the amount of free space and the number of available files in the cache rises above both these limits, then culling is turned off.当缓存中空闲的block和file 都高于该值时，不进行缓存剔除</span><br><span class="line">bcull, fcull</span><br><span class="line">If the amount of available space or the number of available files in the cache falls below either of these limits, then culling is started.当缓存中可以使用的block或者files 有一个低于该值时，进行缓存剔除</span><br><span class="line">bstop, fstop</span><br><span class="line">If the amount of available space or the number of available files in the cache falls below either of these limits, then no further allocation of disk space or files is permitted until culling has raised things above these limits again.当缓存中可以使用的block或者files有一个低于该值时，除非缓存剔除机制进行了缓存剔除，否则不会再分配磁盘空间，</span><br></pre></td></tr></table></figure>
<p>通常配置是这样</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0 &lt;&#x3D; bstop &lt; bcull &lt; brun &lt; 100</span><br><span class="line">0 &lt;&#x3D; fstop &lt; fcull &lt; frun &lt; 100</span><br></pre></td></tr></table></figure>

<p>需要注意，这些值是表示的可以使用的空间和文件，并不是100 减去使用df 查看的信息，用户空间的守护进程扫描cache，来建立一个需要提出的对象表，基于最少使用原则进行剔除。“ A new scan of the cache is started as soon as space is made in the table”，如果对象的atimes(最后访问时间)发生了变化，不会进行剔除，或者内核模块通知说该文件仍然在使用，也不会删除该cache</p>
<h2 id="缓存结构"><a href="#缓存结构" class="headerlink" title="缓存结构"></a>缓存结构</h2><p>会存在两个目录 </p>
<ul>
<li>cache/</li>
<li>graveyard/</li>
</ul>
<p>活动的cache 对象会存放在 cache/ 目录。CacheFile的内核模块会将不再使用或者剔除的对象移动到graveyard 目录，守护进程会在graveyard进行删除，守护进程使用dnotify来监控graveyard目录，然后会将graveyard存在的对象删除。</p>
<ul>
<li><p>CacheFiles 模块将索引对象使用目录的方式进行表示，目录名称可能是”I….”或者”J….”</p>
</li>
<li><p>没有子对象的数据对象会以文件的方式进行表示，有子对象的数据对象会以目录的形式进行表示，文件名称可能是”D…”或者”E….”。如果表示目录，那么会有一个叫”data”的文件在该目录，用户真实的保存数据</p>
</li>
</ul>
<ul>
<li>特殊的对象，通数据对象类似，不过文件名是以”S….”或者”T…”的形式</li>
</ul>
<p>如果一个对象有子对象，那么他会以目录的形式表示，在该目录下会有一系列子目录，子目录的名称以@+子对象的哈希值命名，如下所示</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> &#x2F;INDEX    &#x2F;INDEX     &#x2F;INDEX                            &#x2F;DATA FILES</span><br><span class="line">&#x2F;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x2F;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x2F;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x2F;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">cache&#x2F;@4a&#x2F;I03nfs&#x2F;@30&#x2F;Ji000000000000000--fHg8hi8400</span><br><span class="line">cache&#x2F;@4a&#x2F;I03nfs&#x2F;@30&#x2F;Ji000000000000000--fHg8hi8400&#x2F;@75&#x2F;Es0g000w...DB1ry</span><br><span class="line">cache&#x2F;@4a&#x2F;I03nfs&#x2F;@30&#x2F;Ji000000000000000--fHg8hi8400&#x2F;@75&#x2F;Es0g000w...N22ry</span><br><span class="line">cache&#x2F;@4a&#x2F;I03nfs&#x2F;@30&#x2F;Ji000000000000000--fHg8hi8400&#x2F;@75&#x2F;Es0g000w...FP1ry</span><br></pre></td></tr></table></figure>

<p>如果文件名称太长，超过了NAME_MAX的大小，那么会被分成多分，第一份被用于创建嵌套目录，最后一份会位于最后一个目录，每个中间目录的名称会以”+”作为前缀，例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">J1223&#x2F;@23&#x2F;+xy...z&#x2F;+kl...m&#x2F;Epqr</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Note that keys are raw data, and not only may they exceed NAME_MAX in size, they may also contain things like ‘&#x2F;’ and NUL characters, and so they may not be suitable for turning directly into a filename.</span><br><span class="line"></span><br><span class="line">To handle this, CacheFiles will use a suitably printable filename directly and “base-64” encode ones that aren’t directly suitable. The two versions of object filenames indicate the encoding:</span><br><span class="line"></span><br><span class="line">OBJECT TYPE	PRINTABLE	ENCODED</span><br><span class="line">Index	“I…”	“J…”</span><br><span class="line">Data	“D…”	“E…”</span><br><span class="line">Special	“S…”	“T…”</span><br><span class="line">Intermediate directories are always “@” or “+” as appropriate.</span><br><span class="line"></span><br><span class="line">Each object in the cache has an extended attribute label that holds the object type ID (required to distinguish special objects) and the auxiliary data from the netfs. The latter is used to detect stale objects in the cache and update or retire them.</span><br><span class="line"></span><br><span class="line">Note that CacheFiles will erase from the cache any file it doesn’t recognise or any file of an incorrect type (such as a FIFO file or a device file).</span><br></pre></td></tr></table></figure>

<h2 id="转载的阅读摘要"><a href="#转载的阅读摘要" class="headerlink" title="转载的阅读摘要"></a>转载的阅读摘要</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install cachefilesd; </span><br><span class="line"></span><br><span class="line">挂载命令：直接mount服务端共享的目录到本地的&#x2F;mnt目录，必须使用-o fsc参数选项;</span><br><span class="line"></span><br><span class="line">All access to files under &#x2F;mount&#x2F;point will go through the cache, unless the file is opened for direct I&#x2F;O or writing; </span><br><span class="line"></span><br><span class="line">Opening a file from a shared file system for direct I&#x2F;O automatically bypasses the cache. This is because this type of access must be direct to the server.</span><br><span class="line"></span><br><span class="line">To avoid coherency management problems between superblocks, all NFS superblocks that wish to cache data have unique Level 2 keys. Normally, two NFS mounts with same source volume and options share a superblock, and thus share the caching, even if they mount different directories within that volume.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Opening a file from a shared file system for writing will not work on NFS version 2 and 3.  因为没有足够的维持并发写的一致性信息；</span><br><span class="line"></span><br><span class="line">Furthermore, this release of FS-Cache only caches regular NFS files. FS-Cache will not cache directories, symlinks, device files, FIFOs and sockets. 其只对文件数据进行cache的操作。</span><br></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title>GPUDirect Technologies</title>
    <url>/2021/03/01/GPUDirect-Technologies/</url>
    <content><![CDATA[<p>基于GPUDirect 技术，可以使网卡驱动，存储驱动直接从GPU 内存中读取和写入数据，不再需要经过主机CPU、主机内存，减少数据拷贝，GPUDirect技术包括</p>
<ul>
<li>GPUDirect Storage</li>
<li>GPUDirect Remote Direct Memory Access (RDMA)</li>
<li>GPUDirect Peer to Peer (P2P)</li>
<li>GPUDirect Video</li>
</ul>
<h2 id="GPUDirect-Storage"><a href="#GPUDirect-Storage" class="headerlink" title="GPUDirect Storage"></a>GPUDirect Storage</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NVIDIA® GPUDirect® Storage (GDS) is the newest addition to the GPUDirect family. GDS enables a direct data path for direct memory access (DMA) transfers between GPU memory and storage, which avoids a bounce buffer through the CPU. This direct path increases system bandwidth and decreases the latency and utilization load on the CPU.</span><br></pre></td></tr></table></figure>
<p>在本地存储和远端存储搭建一条直接的数据通道，(Nvme,NVME over Fabric, GPU memory),避免基于CPU 内存的拷贝，可以在网卡或者存储 开启 DMA(Direct Memory Access),如下图所示：</p>
<p><img src="/2021/03/01/GPUDirect-Technologies/1.png" alt="avatar"></p>
<p>使用GPUDirect Storage 需要安装单独的软件，查看Nvidia 官网，目前支持Ubuntu 操作系统，目前GPUDirect Storage 还是一个比较新的技术</p>
<p><img src="/2021/03/01/GPUDirect-Technologies/3.png" alt="avatar"></p>
<h2 id="GPUDirect-RDMA"><a href="#GPUDirect-RDMA" class="headerlink" title="GPUDirect RDMA"></a>GPUDirect RDMA</h2><p>更多详细的内容参考<a href="https://docs.nvidia.com/cuda/gpudirect-rdma/index.html" target="_blank" rel="noopener">这里</a></p>
<p>用于节点间的GPU 之间直接通信，避免了依赖CPU和主机内存的复制，可以提高10倍的性能，GPUDirect RDMA 属于CUDA的一部分，需要下载第三方的Network 驱动来支持 GPUDirect RDMA<br><img src="/2021/03/01/GPUDirect-Technologies/4.png" alt="avatar"></p>
<p>GPU Direct leverages PeerDirect RDMA and PeerDirect ASYNC™ capabilities of the Mellanox network adapters. 对于HCA卡，需要安装nvidia-peer-memory服务<br><img src="/2021/03/01/GPUDirect-Technologies/5.png" alt="avatar"></p>
<p>在单个节点上，如果需要启用GPUDirect RDMA功能，需要保证GPU与第三设备属于同一个PCI Express，我们在外部看来就是必须属于一个NUMA 组</p>
<p><img src="/2021/03/01/GPUDirect-Technologies/6.png" alt="avatar"></p>
<h3 id="GPUDirect-RDMA-如何工作？"><a href="#GPUDirect-RDMA-如何工作？" class="headerlink" title="GPUDirect RDMA 如何工作？"></a>GPUDirect RDMA 如何工作？</h3><p>当设置两个Peer（不通节点的两个GPU）间使用 GPU Direct时，在PCI Express设备的角度看，所有的物理地址相同。在此物理地址空间内是称为PCI BAR的线性窗口。 每个设备最多具有六个BAR寄存器，因此它最多可以具有六个活动的32位BAR区域。 64位BAR占用两个BAR寄存器。 PCI Express设备以对等设备的BAR地址发布到系统内存的相同方式来进行读写操作。传统上，使用CPU的MMU作为内存映射的I / O（MMIO）地址，将BAR窗口之类的资源映射到用户或内核地址空间。 但是，由于当前的操作系统没有足够的机制来在驱动程序之间交换MMIO区域，因此NVIDIA内核驱动程序会导出功能以执行必要的地址转换和映射。</p>
<p><font size="9">通常的 DMA 转换（Standard DMA Transfer)</font></p>
<p><img src="/2021/03/01/GPUDirect-Technologies/7.png" alt="avatar"></p>
<p><font size="9"> GPUDirect RDMA Transfers</font></p>
<p><img src="/2021/03/01/GPUDirect-Technologies/8.png" alt="avatar"></p>
<p><font size="9"> 支持的系统 </font><br><img src="/2021/03/01/GPUDirect-Technologies/10.png" alt="avatar"></p>
<p>对服务器配置有一定的要求才能达到最优性能，(终于明白为啥最新的A100服务器都需要有多个IB卡了，如果一台GPU服务器上有8张GPU卡，可能会存在8张Infiniband卡)</p>
<p><img src="/2021/03/01/GPUDirect-Technologies/9.png" alt="avatar"></p>
<p>什么是PCI BAR Size<br><img src="/2021/03/01/GPUDirect-Technologies/11.png" alt="avatar"></p>
]]></content>
  </entry>
  <entry>
    <title>cgroup blkio-controller</title>
    <url>/2021/03/22/cgroup-blkio-controller/</url>
    <content><![CDATA[<p><a href="https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v1/blkio-controller.html" target="_blank" rel="noopener">https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v1/blkio-controller.html</a></p>
]]></content>
  </entry>
  <entry>
    <title>k8s证书管理</title>
    <url>/2021/03/23/k8s%E8%AF%81%E4%B9%A6%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<h2 id="1-K8s集群内置的证书在一年后会到期，导致集群不能正常使用"><a href="#1-K8s集群内置的证书在一年后会到期，导致集群不能正常使用" class="headerlink" title="1.K8s集群内置的证书在一年后会到期，导致集群不能正常使用"></a>1.K8s集群内置的证书在一年后会到期，导致集群不能正常使用</h2><p>证书到期后会提示:Unable to connect to the server: x509: certificate has expired or is not yet valid</p>
<h2 id="2-master-节点"><a href="#2-master-节点" class="headerlink" title="2. master 节点"></a>2. master 节点</h2><p>在默认情况下，可以使用如下命令查看证书过期时间：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">openssl x509 -noout -dates -in &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;apiserver.crt</span><br></pre></td></tr></table></figure>

<p>证书主要存放在/etc/kubernetes/pki 目录</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node1 ssl]# ll</span><br><span class="line">total 52</span><br><span class="line">-rw-r--r-- 1 root root 1407 Mar 24 10:07 apiserver.crt</span><br><span class="line">-rw------- 1 root root 1675 Mar 24 10:07 apiserver.key</span><br><span class="line">-rw-r--r-- 1 root root 1099 Mar 24 10:07 apiserver-kubelet-client.crt</span><br><span class="line">-rw------- 1 root root 1679 Mar 24 10:07 apiserver-kubelet-client.key</span><br><span class="line">-rw-r--r-- 1 root root 1025 Jan 18 21:00 ca.crt</span><br><span class="line">-rw------- 1 root root 1679 Jan 18 21:00 ca.key</span><br><span class="line">-rw-r--r-- 1 root root 2401 Mar 24 09:53 cluster.yaml</span><br><span class="line">-rw-r--r-- 1 root root 1038 Jan 18 21:00 front-proxy-ca.crt</span><br><span class="line">-rw------- 1 root root 1679 Jan 18 21:00 front-proxy-ca.key</span><br><span class="line">-rw-r--r-- 1 root root 1058 Mar 24 10:07 front-proxy-client.crt</span><br><span class="line">-rw------- 1 root root 1675 Mar 24 10:07 front-proxy-client.key</span><br><span class="line">-rw------- 1 root root 1679 Jan 18 21:00 sa.key</span><br><span class="line">-rw------- 1 root root  451 Jan 18 21:00 sa.pub</span><br></pre></td></tr></table></figure>

<h2 id="3-集群在有效期内是进行证书续期"><a href="#3-集群在有效期内是进行证书续期" class="headerlink" title="3. 集群在有效期内是进行证书续期"></a>3. 集群在有效期内是进行证书续期</h2><h3 id="3-1-在某个master节点证书续期"><a href="#3-1-在某个master节点证书续期" class="headerlink" title="3.1 在某个master节点证书续期"></a>3.1 在某个master节点证书续期</h3><ol start="0">
<li><p>如果使用已经修改后的kubeadm，可以先将/usr/local/bin 目录下的kubeadm进行备份和替换</p>
</li>
<li><p>备份配置文件和etcd</p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp -rp &#x2F;etc&#x2F;kubernetes &#x2F;etc&#x2F;kubernetes.bak</span><br><span class="line">cp -r &#x2F;var&#x2F;lib&#x2F;etcd &#x2F;var&#x2F;lib&#x2F;etcd.bak</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>生成集群配置文件,如果证书已经超期了，执行此命令会失败，可以尝试修改节点时间或者使用8080 端口连接api-server获取这些信息</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;etc&#x2F;kubernetes</span><br><span class="line">kubeadm config view &gt; .&#x2F;cluster.yaml</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>使用kubeadm命令进行 证书续期</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubeadm alpha certs renew  apiserver --config&#x3D;.&#x2F;cluster.yaml</span><br><span class="line">kubeadm alpha certs renew  apiserver-kubelet-client --config&#x3D;.&#x2F;cluster.yaml</span><br><span class="line">kubeadm alpha certs renew  front-proxy-client --config&#x3D;.&#x2F;cluster.yaml</span><br></pre></td></tr></table></figure>
<p>执行完毕后，会在目录/etc/kubernetes/pki 生成新的证书，此时再查看证书有效期，会发现证书的有效期已经延长</p>
<ol start="4">
<li>重新生成配置文件</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm -f &#x2F;etc&#x2F;kubernetes&#x2F;*.conf</span><br><span class="line">kubeadm init phase kubeconfig all --config&#x3D;.&#x2F;cluster.yaml</span><br></pre></td></tr></table></figure>

<p>5.重启kubelet、apiserver、controller-manager、scheduler、etcd</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker ps |grep -E &#39;k8s_kube-apiserver|k8s_kube-controller-manager|k8s_kube-scheduler|k8s_etcd_etcd&#39; | awk -F &#39; &#39; &#39;&#123;print $1&#125;&#39; |xargs docker restart</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>复制新的认证文件 用于命令行使用kubectl</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm -fr ~&#x2F;.kube&#x2F;</span><br><span class="line">mkdir -p &#x2F;root&#x2F;.kube</span><br><span class="line">cp &#x2F;etc&#x2F;kubernetes&#x2F;admin.conf ~&#x2F;.kube&#x2F;config</span><br></pre></td></tr></table></figure>
<h3 id="3-3-高可用环境其他master节点证书续期"><a href="#3-3-高可用环境其他master节点证书续期" class="headerlink" title="3.3 高可用环境其他master节点证书续期"></a>3.3 高可用环境其他master节点证书续期</h3><ol>
<li>备份配置文件和etcd</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp -rp &#x2F;etc&#x2F;kubernetes &#x2F;etc&#x2F;kubernetes.bak</span><br><span class="line">cp -r &#x2F;var&#x2F;lib&#x2F;etcd &#x2F;var&#x2F;lib&#x2F;etcd.bak</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>删除无用的文件<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm &#x2F;etc&#x2F;kubernetes&#x2F;*.conf -rf</span><br><span class="line">rm &#x2F;etc&#x2F;kubernetes&#x2F;ssl -rf</span><br></pre></td></tr></table></figure></li>
<li>将master节点的以下信息复制到到计算节点 node53<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp -r &#x2F;etc&#x2F;kubernetes&#x2F;ssl&#x2F; node53:&#x2F;etc&#x2F;kubernetes</span><br><span class="line">scp  &#x2F;etc&#x2F;kubernetes&#x2F;cluster.yaml node53:&#x2F;etc&#x2F;kubernetes</span><br><span class="line">&#96;&#96;&#96;&#96; </span><br><span class="line">4. 执行命令生成各组件启动需要的配置文件</span><br><span class="line">&#96;&#96;&#96;&#96; </span><br><span class="line"> kubeadm init phase kubeconfig all --config&#x3D;.&#x2F;cluster.yaml</span><br><span class="line">&#96;&#96;&#96;&#96; </span><br><span class="line">5.重启kubelet、apiserver、controller-manager、scheduler、etcd</span><br></pre></td></tr></table></figure>
docker ps |grep -E ‘k8s_kube-apiserver|k8s_kube-controller-manager|k8s_kube-scheduler|k8s_etcd_etcd’ | awk -F ‘ ‘ ‘{print $1}’ |xargs docker restart<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">6. 复制新的认证文件 用于命令行使用kubectl</span><br></pre></td></tr></table></figure>
rm -fr ~/.kube/<br>mkdir -p /root/.kube<br>cp /etc/kubernetes/admin.conf ~/.kube/config<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 3.2 计算节点证书续期</span><br><span class="line">1. 备份配置文件</span><br></pre></td></tr></table></figure>
 cp -rp /etc/kubernetes /etc/kubernetes.bak<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2. 删除无用的文件</span><br><span class="line">&#96;&#96;&#96;&#96;   </span><br><span class="line">  rm &#x2F;etc&#x2F;kubernetes&#x2F;*.conf -rf</span><br><span class="line">  rm &#x2F;etc&#x2F;kubernetes&#x2F;ssl -rf</span><br></pre></td></tr></table></figure></li>
<li>将master节点的以下信息复制到到计算节点 node53<pre><code>scp -r /etc/kubernetes/ssl/ node53:/etc/kubernetes
scp  /etc/kubernetes/cluster.yaml node53:/etc/kubernetes
</code></pre>
</li>
</ol>
<pre><code>4. 执行命令生成kubelet启动需要的配置文件</code></pre>
<p> kubeadm init phase kubeconfig all –config=./cluster.yaml</p>
<p>````<br> 可以在/etc/kubernetes 目录看到新的配置文件<br>5. 删除 /var/lib/kubelet/pki/kubelet-client-current.pem 文件或者自定义的kubelet存放目录</p>
<ol start="6">
<li>此时执行命令systemctl restart kubelet 重启kubelet就可以</li>
</ol>
<h2 id="4-修改kubeadm源码支持更长的证书有效期"><a href="#4-修改kubeadm源码支持更长的证书有效期" class="headerlink" title="4. 修改kubeadm源码支持更长的证书有效期"></a>4. 修改kubeadm源码支持更长的证书有效期</h2><p>主要修改两块代码，如下所示</p>
<ol>
<li><p>修改一<br>vi staging/src/k8s.io/client-go/util/cert/cert.go,将时间修改为20年，具体的修改位置如下所示：</p>
<p><img src="/2021/03/23/k8s%E8%AF%81%E4%B9%A6%E7%AE%A1%E7%90%86/1.png" alt="avatar"></p>
</li>
</ol>
<ol start="2">
<li><p>修改二<br>vim ./cmd/kubeadm/app/util/pkiutil/pki_helpers.go，将时间修改为20年，具体的修改位置如下所示：</p>
<p><img src="/2021/03/23/k8s%E8%AF%81%E4%B9%A6%E7%AE%A1%E7%90%86/2.png" alt="avatar"></p>
</li>
</ol>
<p>执行命令make WHAT=cmd/kubeadm 重新编译生成kubeadm 可执行文件</p>
<h2 id="5-kubelet-自动续期与controller-manager的证书签发时间"><a href="#5-kubelet-自动续期与controller-manager的证书签发时间" class="headerlink" title="5. kubelet 自动续期与controller-manager的证书签发时间"></a>5. kubelet 自动续期与controller-manager的证书签发时间</h2><p>这里主要有两个参数<br>kubelet 进程接收 –rotate-certificates 参数，该参数决定 kubelet 在当前使用的 证书即将到期时，是否会自动申请新的证书。</p>
<p>kube-controller-manager 进程接收 –cluster-signing-duration 参数 （在 1.19 版本之前为 –experimental-cluster-signing-duration），用来 控制签发证书的有效期限。</p>
]]></content>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>物理机中的多种内存</title>
    <url>/2021/03/22/%E7%89%A9%E7%90%86%E6%9C%BA%E4%B8%AD%E7%9A%84%E5%A4%9A%E7%A7%8D%E5%86%85%E5%AD%98/</url>
    <content><![CDATA[<ol>
<li><p>ROM和RAM指的都是半导体存储器，ROM是Read Only Memory的缩写，RAM是Random Access Memory的缩写。ROM在系统停止供电的时候仍然可以保持数据，而RAM通常都是在掉电之后就丢失数据，典型的RAM就是计算机的内存。</p>
</li>
<li><p>RAM 有两大类，一种称为静态RAM（Static RAM/SRAM），SRAM速度非常快，是目前读写最快的存储设备了，但是它也非常昂贵，所以只在要求很苛刻的地方使用，譬如CPU的一级缓冲，二级缓冲。另一种称为动态RAM（Dynamic RAM/DRAM），DRAM保留数据的时间很短，速度也比SRAM慢，不过它还是比任何的ROM都要快，但从价格上来说DRAM相比SRAM要便宜很多，计算机内存就是DRAM的。</p>
</li>
</ol>
<ul>
<li><p>2.1 DRAM，动态随机存取存储器，需要不断的刷新，才能保存数据.而且是行列地址复用的，许多都有页模式。DRAM分为很多种，常见的主要有FPRAM/FastPage、EDORAM、SDRAM、DDR RAM、RDRAM、SGRAM以及WRAM等，这里介绍其中的一种DDR RAM。DDR RAM（Date-Rate RAM）也称作DDR SDRAM，这种改进型的RAM和SDRAM是基本一样的，不同之处在于它可以在一个时钟读写两次数据，这样就使得数据传输速度加倍了。这是目前电脑中用得最多的内存，而且它有着成本优势，事实上击败了Intel的另外一种内存标准－Rambus DRAM。在很多高端的显卡上，也配备了高速DDR RAM来提高带宽，这可以大幅度提高3D加速卡的像素渲染能力。</p>
</li>
<li><p>2.2  SRAM，静态的随机存取存储器，加电情况下，不需要刷新，数据不会丢失，而且，一般不是行列地址复用的。</p>
</li>
<li><p>2.3 SDRAM，同步的DRAM，即数据的读写需要时钟来同步。 DRAM和SDRAM由于实现工艺问题，容量较SRAM大。但是读写速度不如SRAM，但是现在，SDRAM的速度也已经很快了，时钟好像已经有 150兆的了。那么就是读写周期小于10ns了。</p>
<ul>
<li><p>2.4 每单位容量的DRAM使用较少的晶体管而且占用面积小，而SRAM则是用较多晶体管占用的面也要相对大不少；DRAM需要不断刷新来维持所存储的数据，SRAM则不需要；DRAM的存取时钟间隔长，而SRAM的速度快，时间短；DRAM的耗电低，SRAM耗电大。</p>
</li>
<li><p>2.5 目前，相同容量的SRAM价格是SDRAM的8倍左右，面积则将近大4倍，所以SRAM常用于快速存储的较低容量的RAM需求，比如Cache(缓存），比如CPU内部的L1 Cache和主板上的L2 Cache，一般只有几百K。</p>
</li>
</ul>
</li>
</ul>
<ol start="3">
<li><p>ROM也有很多种，PROM是可编程的ROM，PROM和 EPROM（可擦除可编程ROM）两者区别是，PROM是一次性的，也就是软件灌入后，就无法修改了，这种是早期的产品，现在已经不可能使用了，而 EPROM是通过紫外光的照射擦出原先的程序，是一种通用的存储器。另外一种EEPROM是通过电子擦出，价格很高，写入时间很长，写入很慢。举个例子，手机软件一般放在EEPROM中，我们打电话，有些最后拨打的号码，暂时是存在SRAM中的，不是马上写入通过记录（通话记录保存在EEPROM中），因为当时有很重要工作（通话）要做，如果写入，漫长的等待是让用户忍无可忍的。</p>
</li>
<li><p>FLASH存储器又称闪存，它结合了ROM和RAM的长处，不仅具备电子可擦出可编程（EEPROM）的性能，还不会断电丢失数据同时可以快速读取数据（NVRAM的优势），U盘和MP3里用的就是这种存储器。在过去的20年里，嵌入式系统一直使用ROM（EPROM）作为它们的存储设备，然而近年来 Flash全面代替了ROM（EPROM）在嵌入式系统中的地位，用作存储 Bootloader以及操作系统或者程序代码或者直接当硬盘使用（U盘）。目前Flash主要有两种NOR Flash和NADN Flash。NOR Flash的读取和我们常见的SDRAM的读取是一样，用户可以直接运行装载在NOR FLASH里面的代码，这样可以减少SRAM的容量从而节约了成本。NAND Flash没有采取内存的随机读取技术，它的读取是以一次读取一快的形式来进行的，通常是一次读取512个字节，采用这种技术的Flash比较廉价。用户不能直接运行NAND Flash上的代码，因此好多使用NAND Flash的开发板除了使用NAND Flah以外，还作上了一块小的NOR Flash来运行启动代码。一般小容量的用NOR Flash，因为其读取速度快，多用来存储操作系统等重要信息，而大容量的用NAND FLASH，最常见的NAND FLASH应用是嵌入式系统采用的DOC（Disk On Chip）和我们通常用的“闪盘”，可以在线擦除。目前市面上的FLASH 主要来自Intel，AMD，Fujitsu和Toshiba，而生产NAND Flash的主要厂家有Samsung和Toshiba。</p>
</li>
</ol>
<h2 id="PMEM"><a href="#PMEM" class="headerlink" title="PMEM"></a>PMEM</h2><p>AEP是Intel推出的一种新型的非易失Optane Memory设备，又被称作Apache Pass，所以一般习惯称作AEP。在这之前也有类似的设备称作NVDIMM或PMEM，目前Linux创建的AEP设备节点也是叫做pmem（如/dev/pmem0），所以本文中NVDIMM或PMEM都指AEP。</p>
]]></content>
  </entry>
  <entry>
    <title>物理服务器中的CPU die</title>
    <url>/2021/03/19/%E7%89%A9%E7%90%86%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%AD%E7%9A%84CPU-die/</url>
    <content><![CDATA[<p>最近在看一个开源项目，里面提到建立单服务器的资源拓扑，包括NUMA node、Dies、Socket这三个概念，这个Dies是第一次听说，搜集整理了一些关于 Dies的资料。</p>
<p>Dies是处理器在生产过程中引入的概念，总的来说，Die或者CPU Die指的是处理器在生产过程中，从晶圆（Silicon Wafer）上切割下来的一个个小方块（这也是为啥消费者看到的CPU芯片为什么都是方的的原因），在切割下来之前，每个小方块（Die）都需要经过各种加工，将电路逻辑刻到该Die上面。对于主流的CPU厂商Intel和AMD而言，他们会将1个或者N个CPU Die封装起来形成一个CPU Package，有时候也叫作CPU Socket，如下图所示：</p>
<p>   <img src="/2021/03/19/%E7%89%A9%E7%90%86%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%AD%E7%9A%84CPU-die/1.jpg" alt="avatar"></p>
<p>由于CPU Die的制作工艺及其复杂，导致CPU Die的大小会很大地影响到CPU Die的良品率，即CPU Die的大小越大，则CPU Die出错的概率越高，良品率也越低，相应的成本也越高。</p>
<p>在服务器领域，Intel Xeon系列的高端处理器会尽量地将整个CPU Socket做到一个CPU Die上，导致其相应的CPU Die的大小都比较大，这也是其价格昂贵的一个原因。将整个CPU Socket上的东西都做到一个CPU Die上的好处是CPU内部之间各个组件的连接是通过片内总线互联，有更多的资源可以相互共享，这样整体的性能能够更高。</p>
<p>而对于AMD的EYPC CPU而言，它的每个CPU Socket由4个CPU Die组成，每个CPU Die中包含有4个CPU内核，如下图所示：</p>
<p>   <img src="/2021/03/19/%E7%89%A9%E7%90%86%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%AD%E7%9A%84CPU-die/2.jpg" alt="avatar"></p>
<p>CPU Die之间通过片外总线（Infinity Fabric）互联，并且不同CPU Die上的CPU内核不能共享CPU缓存，而单个Die的Xeon处理器内和所有CPU内核其实是可以共享CPU的第三级缓存（L3 Cache）的。</p>
]]></content>
  </entry>
  <entry>
    <title>k8s pod 配置shareMemory</title>
    <url>/2021/03/31/k8s-pod-%E9%85%8D%E7%BD%AEshareMemory/</url>
    <content><![CDATA[<h3 id="Linux-shm-tempfs"><a href="#Linux-shm-tempfs" class="headerlink" title="Linux shm/tempfs"></a>Linux shm/tempfs</h3><p>linux默认支持 挂载tmpfs 时指定大小,如下所示：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mount tmpfs -t tmpfs &#x2F;home&#x2F;test&#x2F; -o size&#x3D;1M</span><br></pre></td></tr></table></figure>
<p>这个命令只是逻辑占用，并不会占用真实的内存空间，但是在该目录</p>
<h3 id="测试-shm-大小"><a href="#测试-shm-大小" class="headerlink" title="测试 shm 大小"></a>测试 shm 大小</h3><p>使用以下命令写入文件到目录/dev/shm ，块大小为1M，数量1024个，一共1G大小</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dd if&#x3D;&#x2F;dev&#x2F;zero of&#x3D;&#x2F;dev&#x2F;shm&#x2F;test.random  bs&#x3D;1M count&#x3D;1024</span><br></pre></td></tr></table></figure>

<p>创建shm时，会占用内存空间，可以使用free -hm 命令查看，如下所示</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@ajkqpkmajvc6q-0:&#x2F;dev&#x2F;shm# free -mh</span><br><span class="line">              total        used        free      shared  buff&#x2F;cache   available</span><br><span class="line">Mem:           172G         17G        2.8G        4.2G        152G        148G</span><br><span class="line">Swap:            0B          0B          0B</span><br><span class="line">root@ajkqpkmajvc6q-0:&#x2F;dev&#x2F;shm# dd if&#x3D;&#x2F;dev&#x2F;zero of&#x3D;&#x2F;dev&#x2F;shm&#x2F;test1.random  bs&#x3D;1M count&#x3D;4096</span><br><span class="line">4096+0 records in</span><br><span class="line">4096+0 records out</span><br><span class="line">4294967296 bytes (4.3 GB, 4.0 GiB) copied, 2.6405 s, 1.6 GB&#x2F;s</span><br><span class="line">root@ajkqpkmajvc6q-0:&#x2F;dev&#x2F;shm# free -mh</span><br><span class="line">              total        used        free      shared  buff&#x2F;cache   available</span><br><span class="line">Mem:           172G         17G        820M        8.2G        154G        144G</span><br><span class="line">Swap:            0B          0B          0B</span><br></pre></td></tr></table></figure>
<h3 id="kubernetes-Befor-1-20"><a href="#kubernetes-Befor-1-20" class="headerlink" title="kubernetes Befor 1.20"></a>kubernetes Befor 1.20</h3><p>虽然docker支持配置shm 参数，但是kubernetes并不支持该参数，社区里有基于emptyDir的方式使用，如下所示,定义emptyDir的卷，并挂载到容器的/dev/shm 目录</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">....</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: &#x2F;dev&#x2F;shm</span><br><span class="line">      name: shm</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  volumes:</span><br><span class="line">  - emptyDir:</span><br><span class="line">      medium: Memory</span><br><span class="line">      sizeLimit: 4Gi</span><br></pre></td></tr></table></figure>

<p>虽然这里有sizeLimit参数，但是其实并不生效，默认使用的大小为宿主机内存的一半，k8s代码里面进行挂载时，并未增加size参数，只是挂载tmpfs文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">k8s.io\kubernetes\pkg\volume\emptydir\empty_dir.go</span><br><span class="line">&#x2F;&#x2F; setupTmpfs creates a tmpfs mount at the specified directory.</span><br><span class="line">func (ed *emptyDir) setupTmpfs(dir string) error &#123;</span><br><span class="line">	if ed.mounter &#x3D;&#x3D; nil &#123;</span><br><span class="line">		return fmt.Errorf(&quot;memory storage requested, but mounter is nil&quot;)</span><br><span class="line">	&#125;</span><br><span class="line">	if err :&#x3D; ed.setupDir(dir); err !&#x3D; nil &#123;</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line">	&#x2F;&#x2F; Make SetUp idempotent.</span><br><span class="line">	medium, isMnt, err :&#x3D; ed.mountDetector.GetMountMedium(dir)</span><br><span class="line">	if err !&#x3D; nil &#123;</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line">	&#x2F;&#x2F; If the directory is a mountpoint with medium memory, there is no</span><br><span class="line">	&#x2F;&#x2F; work to do since we are already in the desired state.</span><br><span class="line">	if isMnt &amp;&amp; medium &#x3D;&#x3D; v1.StorageMediumMemory &#123;</span><br><span class="line">		return nil</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	klog.V(3).Infof(&quot;pod %v: mounting tmpfs for volume %v&quot;, ed.pod.UID, ed.volName)</span><br><span class="line">	return ed.mounter.Mount(&quot;tmpfs&quot;, dir, &quot;tmpfs&quot;, nil &#x2F;* options *&#x2F;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>但是这时候设置的sizeLimit：4Gi 起到了别的作用，kubelet的eviction manager会监控pod的emptyDir卷使用的空间大小，当使用空间超过该值时，会将该Pod驱逐(kubelet 可以获取到Pod对应容器的emptyDir卷空间使用信息 k8s.io\kubernetes\pkg\kubelet\server\stats)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">k8s.io\kubernetes\pkg\kubelet\eviction\eviction_manager.go</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; localStorageEviction checks the EmptyDir volume usage for each pod and determine whether it exceeds the specified limit and needs</span><br><span class="line">&#x2F;&#x2F; to be evicted. It also checks every container in the pod, if the container overlay usage exceeds the limit, the pod will be evicted too.</span><br><span class="line">func (m *managerImpl) localStorageEviction(summary *statsapi.Summary, pods []*v1.Pod) []*v1.Pod &#123;</span><br><span class="line">	statsFunc :&#x3D; cachedStatsFunc(summary.Pods)</span><br><span class="line">	evicted :&#x3D; []*v1.Pod&#123;&#125;</span><br><span class="line">	for _, pod :&#x3D; range pods &#123;</span><br><span class="line">		podStats, ok :&#x3D; statsFunc(pod)</span><br><span class="line">		if !ok &#123;</span><br><span class="line">			continue</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		if m.emptyDirLimitEviction(podStats, pod) &#123;</span><br><span class="line">			evicted &#x3D; append(evicted, pod)</span><br><span class="line">			continue</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		if m.podEphemeralStorageLimitEviction(podStats, pod) &#123;</span><br><span class="line">			evicted &#x3D; append(evicted, pod)</span><br><span class="line">			continue</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		if m.containerEphemeralStorageLimitEviction(podStats, pod) &#123;</span><br><span class="line">			evicted &#x3D; append(evicted, pod)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	return evicted</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>所以说，如果你想在低版本的k8s上使用shm，请不要设置sizeLimit</p>
<h3 id="kubernetes1-20版本"><a href="#kubernetes1-20版本" class="headerlink" title="kubernetes1.20版本"></a>kubernetes1.20版本</h3><p>1.20 版本合入了一个（PR)[<a href="https://github.com/kubernetes/kubernetes/pull/94444/commits],%E5%8F%AF%E4%BB%A5%E5%9C%A8kubelet%E8%AE%BE%E7%BD%AE%E5%BC%80%E5%90%AF%E4%B8%80%E4%B8%AAfeature" target="_blank" rel="noopener">https://github.com/kubernetes/kubernetes/pull/94444/commits],可以在kubelet设置开启一个feature</a> 特性，kubelet在创建容器时，会为Pod挂载shm，此时还是需要为Pod以挂载卷的方式实现shm</p>
<ol>
<li>当 Pod 并没有设置memory limit时，此时 shm大小为node的Allocateable Memory大小</li>
<li>当Pod 设置了Memory Limit 但是在medium的emptyDir未设置sizeLimit时，shm 大小为Pod 的memory Limit</li>
<li>当Pod的medium emptyDir设置sizeLimit时，shm大小为sizeLimit</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">func calculateEmptyDirMemorySize(nodeAllocatableMemory *resource.Quantity, spec *volume.Spec, pod *v1.Pod) *resource.Quantity &#123;</span><br><span class="line">	&#x2F;&#x2F; if feature is disabled, continue the default behavior of linux host default</span><br><span class="line">	sizeLimit :&#x3D; &amp;resource.Quantity&#123;&#125;</span><br><span class="line">	if !utilfeature.DefaultFeatureGate.Enabled(features.SizeMemoryBackedVolumes) &#123;</span><br><span class="line">		return sizeLimit</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; size limit defaults to node allocatable (pods cant consume more memory than all pods)</span><br><span class="line">	sizeLimit &#x3D; nodeAllocatableMemory</span><br><span class="line">	zero :&#x3D; resource.MustParse(&quot;0&quot;)</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; determine pod resource allocation</span><br><span class="line">	&#x2F;&#x2F; we use the same function for pod cgroup assigment to maintain consistent behavior</span><br><span class="line">	&#x2F;&#x2F; NOTE: this could be nil on systems that do not support pod memory containment (i.e. windows)</span><br><span class="line">	podResourceConfig :&#x3D; cm.ResourceConfigForPod(pod, false, uint64(100000))</span><br><span class="line">	if podResourceConfig !&#x3D; nil &amp;&amp; podResourceConfig.Memory !&#x3D; nil &#123;</span><br><span class="line">		podMemoryLimit :&#x3D; resource.NewQuantity(*(podResourceConfig.Memory), resource.BinarySI)</span><br><span class="line">		&#x2F;&#x2F; ensure 0 &lt; value &lt; size</span><br><span class="line">		if podMemoryLimit.Cmp(zero) &gt; 0 &amp;&amp; podMemoryLimit.Cmp(*sizeLimit) &lt; 1 &#123;</span><br><span class="line">			sizeLimit &#x3D; podMemoryLimit</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; volume local size is  used if and only if less than what pod could consume</span><br><span class="line">	if spec.Volume.EmptyDir.SizeLimit !&#x3D; nil &#123;</span><br><span class="line">		volumeSizeLimit :&#x3D; spec.Volume.EmptyDir.SizeLimit</span><br><span class="line">		&#x2F;&#x2F; ensure 0 &lt; value &lt; size</span><br><span class="line">		if volumeSizeLimit.Cmp(zero) &gt; 0 &amp;&amp; volumeSizeLimit.Cmp(*sizeLimit) &lt; 1 &#123;</span><br><span class="line">			sizeLimit &#x3D; volumeSizeLimit</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	return sizeLimit</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


]]></content>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>http1.0 http1.1与http2.0的区别</title>
    <url>/2021/03/30/http1-0-http1-1%E4%B8%8Ehttp2-0%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<h2 id="最重要的区别"><a href="#最重要的区别" class="headerlink" title="最重要的区别"></a>最重要的区别</h2><ol>
<li>从HTTP/1.0到HTTP/2，都是利用TCP作为底层协议进行通信的。</li>
<li>HTTP/1.1，引进了长连接(keep-alive)，减少了建立和关闭连接的消耗和延迟。</li>
<li>HTTP/2，引入了多路复用：连接共享，提高了连接的利用率，降低延迟。</li>
</ol>
<p>在Chrome浏览器里，打开chrome://net-internals/#http2，可以看到http2链接的信息</p>
<h2 id="HTTP的基本优化"><a href="#HTTP的基本优化" class="headerlink" title="HTTP的基本优化"></a>HTTP的基本优化</h2><p>影响一个 HTTP 网络请求的因素主要有两个：带宽和延迟。</p>
<ol>
<li><p>带宽，如果说我们还停留在拨号上网的阶段，带宽可能会成为一个比较严重影响请求的问题，但是现在网络基础建设已经使得带宽得到极大的提升，我们不再会担心由带宽而影响网速，那么就只剩下延迟了。</p>
</li>
<li><p>延迟，</p>
<p> 2.1 浏览器阻塞（HOL blocking）：浏览器会因为一些原因阻塞请求。浏览器对于同一个域名，同时只能有 4 个连接（这个根据浏览器内核不同可能会有所差异），超过浏览器最大连接数限制，后续请求就会被阻塞。</p>
<p> 2.2 DNS 查询（DNS Lookup）：浏览器需要知道目标服务器的 IP 才能建立连接。将域名解析为 IP 的这个系统就是 DNS。这个通常可以利用DNS缓存结果来达到减少这个时间的目的。</p>
<p> 2.3 建立连接（Initial connection）：HTTP 是基于 TCP 协议的，浏览器最快也要在第三次握手时才能捎带 HTTP 请求报文，达到真正的建立连接，但是这些连接无法复用会导致每次请求都经历三次握手和慢启动。三次握手在高延迟的场景下影响较明显，慢启动则对文件类大请求影响较大。</p>
<h2 id="HTTP1-0和HTTP1-1的一些区别"><a href="#HTTP1-0和HTTP1-1的一些区别" class="headerlink" title="HTTP1.0和HTTP1.1的一些区别"></a>HTTP1.0和HTTP1.1的一些区别</h2><p>HTTP1.0最早在网页中使用是在1996年，那个时候只是使用一些较为简单的网页上和网络请求上，而HTTP1.1则在1999年才开始广泛应用于现在的各大浏览器网络请求中，同时HTTP1.1也是当前使用最为广泛的HTTP协议。 主要区别主要体现在：</p>
</li>
<li><p>缓存处理，在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。</p>
</li>
<li><p>带宽优化及网络连接的使用，HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。</p>
</li>
<li><p>错误通知的管理，在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。</p>
</li>
<li><p>Host头处理，在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。</p>
</li>
<li><p>长连接，HTTP 1.1支持长连接（PersistentConnection）和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启Connection： keep-alive，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。</p>
</li>
</ol>
<h2 id="HTTP-2-0-和-HTTP1-1-区别"><a href="#HTTP-2-0-和-HTTP1-1-区别" class="headerlink" title="HTTP 2.0 和 HTTP1.1 区别"></a>HTTP 2.0 和 HTTP1.1 区别</h2><p>HTTP 2.0 的出现，相比于 HTTP 1.x ，大幅度的提升了 web 性能。在与 HTTP/1.1 完全语义兼容的基础上，进一步减少了网络延迟。Akamai 公司建立的一个官方的演示，用以说明 HTTP/2 相比于之前的 HTTP/1.1 在性能上的大幅度提升。 同时请求 379 张图片，从Load time 的对比可以看出 HTTP/2 在速度上的优势。<br>  <img src="http1-0-http1-1%E4%B8%8Ehttp2-0%E7%9A%84%E5%8C%BA%E5%88%AB/1.png" alt="avatar"></p>
<h3 id="多路复用"><a href="#多路复用" class="headerlink" title="多路复用"></a>多路复用</h3><p>多路复用允许单一的HTTP2连接同时发起多重的请求-响应消息，每一个request都是是用作连接共享机制的。一个request对应一个id，这样一个连接上可以有多个request，每个连接的request可以随机的混杂在一起，接收方可以根据request的 id将request再归属到各自不同的服务端请求里面。如下所示</p>
<p><img src="http1-0-http1-1%E4%B8%8Ehttp2-0%E7%9A%84%E5%8C%BA%E5%88%AB/2.png" alt="avatar"></p>
<p>整个访问流程第一次请求index.html页面,之后浏览器会去请求style.css和scripts.js的文件。左边的图是顺序加载两个个文件的，右边则是并行加载两个文件。</p>
<p>我们知道HTTP底层其实依赖的是TCP协议，那问题是在同一个连接里面同时发生两个请求响应着是怎么做到的？</p>
<p>首先你要知道，TCP连接相当于两根管道（一个用于服务器到客户端，一个用于客户端到服务器），管道里面数据传输是通过字节码传输，传输是有序的，每个字节都是一个一个来传输。</p>
<p>例如客户端要向服务器发送Hello、World两个单词，只能是先发送Hello再发送World，没办法同时发送这两个单词。不然服务器收到的可能就是HWeolrllod（注意是穿插着发过去了，但是顺序还是不会乱）。这样服务器就懵b了。</p>
<p>接上面的问题，能否同时发送Hello和World两个单词能，当然也是可以的，可以将数据拆成包，给每个包打上标签。发的时候是这样的①H ②W ①e ②o ①l ②r ①l ②l ①o ②d。这样到了服务器，服务器根据标签把两个单词区分开来。HTTP/2 可以很容易的去实现多流并行而不用依赖建立多个 TCP 连接，HTTP/2 把 HTTP 协议通信的基本单位缩小为一个一个的帧，这些帧对应着逻辑流中的消息。并行地在同一个 TCP 连接上双向交换消息。如何做到这一点呢，主要是http2 引入了二进制分帧，在不改动http1.x的语义、方法、状态码、URI以及首部字段等的情况下，关键就是在应用层http2.0和传输层tcp/udp之间增加一个二进制分帧层</p>
<p><img src="http1-0-http1-1%E4%B8%8Ehttp2-0%E7%9A%84%E5%8C%BA%E5%88%AB/3.png" alt="avatar"></p>
<p>在二进制分帧层中， HTTP/2 会将所有传输的信息分割为更小的消息和帧（frame）,并对它们采用二进制格式的编码 ，其中 HTTP1.x 的首部信息会被封装到 HEADER frame，而相应的 Request Body 则封装到 DATA frame 里面。 HTTP/2 通信都在一个连接上完成，这个连接可以承载任意数量的双向数据流。 在过去， HTTP 性能优化的关键并不在于高带宽，而是低延迟。TCP 连接会随着时间进行自我「调谐」，起初会限制连接的最大速度，如果数据成功传输，会随着时间的推移提高传输的速度。这种调谐则被称为 TCP 慢启动。由于这种原因，让原本就具有突发性和短时性的 HTTP 连接变的十分低效。</p>
<p><img src="http1-0-http1-1%E4%B8%8Ehttp2-0%E7%9A%84%E5%8C%BA%E5%88%AB/4.png" alt="avatar"></p>
<h3 id="头部压缩"><a href="#头部压缩" class="headerlink" title="头部压缩"></a>头部压缩</h3><p>在 HTTP/1 中，HTTP 请求和响应都是由「状态行、请求 / 响应头部、消息主体」三部分组成。一般而言，消息主体都会经过 gzip 压缩，或者本身传输的就是压缩过后的二进制文件（例如图片、音频），但状态行和头部却没有经过任何压缩，直接以纯文本传输。随着 Web 功能越来越复杂，每个页面产生的请求数也越来越多，导致消耗在头部的流量越来越多，尤其是每次都要传输 UserAgent、Cookie 这类不会频繁变动的内容，完全是一种浪费。</p>
<p>HTTP1.x的header带有大量信息，而且每次都要重复发送，HTTP2.0使用encoder来减少需要传输的header大小，通讯双方各自cache一份header fields表，既避免了重复header的传输，又减小了需要传输的大小。假定一个页面有100个资源需要加载（这个数量对于今天的Web而言还是挺保守的）, 而每一次请求都有1kb的消息头（这同样也并不少见，因为Cookie和引用等东西的存在）, 则至少需要多消耗100kb来获取这些消息头。HTTP2.0可以维护一个字典，差量更新HTTP头部，大大降低因头部传输产生的流量。</p>
<p><img src="http1-0-http1-1%E4%B8%8Ehttp2-0%E7%9A%84%E5%8C%BA%E5%88%AB/5.png" alt="avatar"></p>
<p>头部压缩的具体原理需要查看压缩算法HPACK 算法</p>
<p>通俗的语言解释下，压缩的原理。头部压缩需要在支持 HTTP/2 的浏览器和服务端之间:</p>
<ol>
<li>维护一份相同的静态字典（Static Table），包含常见的头部名称，以及特别常见的头部名称与值的组合；</li>
<li>维护一份相同的动态字典（Dynamic Table），可以动态的添加内容；</li>
<li>支持基于静态哈夫曼码表的哈夫曼编码（Huffman Coding）；</li>
</ol>
<p>静态字典的作用有两个：</p>
<ol>
<li>对于完全匹配的头部键值对，例如 “:method :GET”，可以直接使用一个字符表示；</li>
<li>对于头部名称可以匹配的键值对，例如 “cookie :xxxxxxx”，可以将名称使用一个字符表示。<h3 id="服务器推送"><a href="#服务器推送" class="headerlink" title="服务器推送"></a>服务器推送</h3></li>
</ol>
<p>服务端推送是一种在客户端请求之前发送数据的机制。当代网页使用了许多资源:HTML、样式表、脚本、图片等等。在HTTP/1.x中这些资源每一个都必须明确地请求。这可能是一个很慢的过程。浏览器从获取HTML开始，然后在它解析和评估页面的时候，增量地获取更多的资源。因为服务器必须等待浏览器做每一个请求，网络经常是空闲的和未充分使用的。</p>
<p>为了改善延迟，HTTP/2引入了server push，它允许服务端推送资源给浏览器，在浏览器明确地请求之前。一个服务器经常知道一个页面需要很多附加资源，在它响应浏览器第一个请求的时候，可以开始推送这些资源。这允许服务端去完全充分地利用一个可能空闲的网络，改善页面加载时间</p>
<p><img src="http1-0-http1-1%E4%B8%8Ehttp2-0%E7%9A%84%E5%8C%BA%E5%88%AB/6.png" alt="avatar"></p>
]]></content>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
</search>
